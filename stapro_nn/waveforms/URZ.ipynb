{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN cascade for URZ\n",
    "\n",
    "* Radek Hofman, Jan 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and axiliary functions and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('/','home','hofman','.dbp.txt'), 'r') as f: password = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: hofman@udb'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"oracle://hofman:%s@mycelium.ctbto.org:1521/udb\" % password\n",
    "%sql $query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>406297</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(406297,)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% sql select count(*) from ml_features where sta='LPAZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(211)\n",
    "    ax.plot(history['acc'], label='acc')\n",
    "    ax.plot(history['val_acc'], label='val_acc')\n",
    "    ax.set_ylabel('accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    ax = fig.add_subplot(212)\n",
    "    ax.plot(history['loss'], label='loss')\n",
    "    ax.plot(history['val_loss'], label='val_loss')\n",
    "    plt.legend(loc='best')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from oracle do pandas\n",
    "import cx_Oracle\n",
    "connection = cx_Oracle.connect('hofman', password, 'udb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the misclassification rate now?\n",
    "\n",
    "* #(iphase != phase) / (#automatic which are not noise) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>24018</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(24018,)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(*) from ml_features where sta='URZ' and class_phase != class_iphase and class_iphase is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n",
      "0 rows affected.\n"
     ]
    }
   ],
   "source": [
    "#select from database required numbers\n",
    "wrong_type = %sql select count(*) from ml_features where sta='URZ' and class_phase != class_iphase\n",
    "total_number = %sql select count(*) from ml_features where sta='URZ' and phase!='N' and source!='M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of misclassified initial wave types: 47.86%\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of misclassified initial wave types: %3.2f%%' % (wrong_type[0][0]/total_number[0][0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes per class phase type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select * from ml_features where sta='URZ' and class_phase='regS'\"\"\"\n",
    "df_S_all = pd.read_sql(query, con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARID</th>\n",
       "      <th>STA</th>\n",
       "      <th>TIME</th>\n",
       "      <th>IPHASE</th>\n",
       "      <th>CLASS_IPHASE</th>\n",
       "      <th>PHASE</th>\n",
       "      <th>CLASS_PHASE</th>\n",
       "      <th>RETIME</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>PER</th>\n",
       "      <th>...</th>\n",
       "      <th>HMXMN</th>\n",
       "      <th>HVRATP</th>\n",
       "      <th>HVRAT</th>\n",
       "      <th>NAB</th>\n",
       "      <th>TAB</th>\n",
       "      <th>HTOV1</th>\n",
       "      <th>HTOV2</th>\n",
       "      <th>HTOV3</th>\n",
       "      <th>HTOV4</th>\n",
       "      <th>HTOV5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25050735</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.125386e+09</td>\n",
       "      <td>Sx</td>\n",
       "      <td>regS</td>\n",
       "      <td>Sn</td>\n",
       "      <td>regS</td>\n",
       "      <td>1.000</td>\n",
       "      <td>A</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.526004</td>\n",
       "      <td>0.786459</td>\n",
       "      <td>1.174982</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>1.216724</td>\n",
       "      <td>0.363039</td>\n",
       "      <td>2.166968</td>\n",
       "      <td>1.844924</td>\n",
       "      <td>0.626604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25058004</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.125423e+09</td>\n",
       "      <td>Lg</td>\n",
       "      <td>regS</td>\n",
       "      <td>Sn</td>\n",
       "      <td>regS</td>\n",
       "      <td>1.925</td>\n",
       "      <td>A</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>2.762988</td>\n",
       "      <td>15.337161</td>\n",
       "      <td>15.337161</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.423843</td>\n",
       "      <td>1.384683</td>\n",
       "      <td>0.724611</td>\n",
       "      <td>6.547078</td>\n",
       "      <td>1.569841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25075768</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.125508e+09</td>\n",
       "      <td>Lg</td>\n",
       "      <td>regS</td>\n",
       "      <td>Sn</td>\n",
       "      <td>regS</td>\n",
       "      <td>1.050</td>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.395858</td>\n",
       "      <td>1.296030</td>\n",
       "      <td>2.398118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.713705</td>\n",
       "      <td>1.641215</td>\n",
       "      <td>0.940403</td>\n",
       "      <td>1.211333</td>\n",
       "      <td>1.909713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25092371</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.125587e+09</td>\n",
       "      <td>Sn</td>\n",
       "      <td>regS</td>\n",
       "      <td>Sn</td>\n",
       "      <td>regS</td>\n",
       "      <td>0.175</td>\n",
       "      <td>A</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.746398</td>\n",
       "      <td>5.561389</td>\n",
       "      <td>2.205452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.155050</td>\n",
       "      <td>0.646231</td>\n",
       "      <td>0.997092</td>\n",
       "      <td>1.326985</td>\n",
       "      <td>4.507104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25094351</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.125598e+09</td>\n",
       "      <td>Sn</td>\n",
       "      <td>regS</td>\n",
       "      <td>Sn</td>\n",
       "      <td>regS</td>\n",
       "      <td>1.400</td>\n",
       "      <td>A</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>2.816413</td>\n",
       "      <td>5.135686</td>\n",
       "      <td>8.557762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.682028</td>\n",
       "      <td>0.309588</td>\n",
       "      <td>2.783780</td>\n",
       "      <td>8.199625</td>\n",
       "      <td>2.007485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARID  STA          TIME IPHASE CLASS_IPHASE PHASE CLASS_PHASE  RETIME  \\\n",
       "0  25050735  URZ  1.125386e+09     Sx         regS    Sn        regS   1.000   \n",
       "1  25058004  URZ  1.125423e+09     Lg         regS    Sn        regS   1.925   \n",
       "2  25075768  URZ  1.125508e+09     Lg         regS    Sn        regS   1.050   \n",
       "3  25092371  URZ  1.125587e+09     Sn         regS    Sn        regS   0.175   \n",
       "4  25094351  URZ  1.125598e+09     Sn         regS    Sn        regS   1.400   \n",
       "\n",
       "  SOURCE       PER    ...        HMXMN     HVRATP      HVRAT  NAB   TAB  \\\n",
       "0      A  0.166667    ...     1.526004   0.786459   1.174982 -0.1 -0.27   \n",
       "1      A  0.444444    ...     2.762988  15.337161  15.337161 -0.1 -0.31   \n",
       "2      A  0.333333    ...     1.395858   1.296030   2.398118  0.0  0.00   \n",
       "3      A  0.166667    ...     1.746398   5.561389   2.205452  0.0  0.00   \n",
       "4      A  0.444444    ...     2.816413   5.135686   8.557762  0.0  0.00   \n",
       "\n",
       "      HTOV1     HTOV2     HTOV3     HTOV4     HTOV5  \n",
       "0  1.216724  0.363039  2.166968  1.844924  0.626604  \n",
       "1  0.423843  1.384683  0.724611  6.547078  1.569841  \n",
       "2  0.713705  1.641215  0.940403  1.211333  1.909713  \n",
       "3  1.155050  0.646231  0.997092  1.326985  4.507104  \n",
       "4  1.682028  0.309588  2.783780  8.199625  2.007485  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_S_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select * from ml_features where sta='URZ' and class_phase='regP'\"\"\"\n",
    "df_P_all = pd.read_sql(query, con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARID</th>\n",
       "      <th>STA</th>\n",
       "      <th>TIME</th>\n",
       "      <th>IPHASE</th>\n",
       "      <th>CLASS_IPHASE</th>\n",
       "      <th>PHASE</th>\n",
       "      <th>CLASS_PHASE</th>\n",
       "      <th>RETIME</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>PER</th>\n",
       "      <th>...</th>\n",
       "      <th>HMXMN</th>\n",
       "      <th>HVRATP</th>\n",
       "      <th>HVRAT</th>\n",
       "      <th>NAB</th>\n",
       "      <th>TAB</th>\n",
       "      <th>HTOV1</th>\n",
       "      <th>HTOV2</th>\n",
       "      <th>HTOV3</th>\n",
       "      <th>HTOV4</th>\n",
       "      <th>HTOV5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14972252</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.069735e+09</td>\n",
       "      <td>Pn</td>\n",
       "      <td>regP</td>\n",
       "      <td>Pn</td>\n",
       "      <td>regP</td>\n",
       "      <td>2.94244</td>\n",
       "      <td>A</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.542596</td>\n",
       "      <td>0.124299</td>\n",
       "      <td>0.176237</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.509125</td>\n",
       "      <td>0.983261</td>\n",
       "      <td>0.619635</td>\n",
       "      <td>0.118464</td>\n",
       "      <td>0.058735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14992929</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.070059e+09</td>\n",
       "      <td>Pn</td>\n",
       "      <td>regP</td>\n",
       "      <td>Pn</td>\n",
       "      <td>regP</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.301846</td>\n",
       "      <td>1.112025</td>\n",
       "      <td>0.258914</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>3.730434</td>\n",
       "      <td>0.738458</td>\n",
       "      <td>0.704325</td>\n",
       "      <td>0.247701</td>\n",
       "      <td>0.060989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15029724</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.070386e+09</td>\n",
       "      <td>Pn</td>\n",
       "      <td>regP</td>\n",
       "      <td>Pn</td>\n",
       "      <td>regP</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>A</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.828008</td>\n",
       "      <td>0.132138</td>\n",
       "      <td>0.192003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.629496</td>\n",
       "      <td>0.632947</td>\n",
       "      <td>0.277982</td>\n",
       "      <td>0.542543</td>\n",
       "      <td>0.041916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15031571</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.070403e+09</td>\n",
       "      <td>Pn</td>\n",
       "      <td>regP</td>\n",
       "      <td>Pn</td>\n",
       "      <td>regP</td>\n",
       "      <td>3.22500</td>\n",
       "      <td>A</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>1.375773</td>\n",
       "      <td>0.282216</td>\n",
       "      <td>0.589090</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.924411</td>\n",
       "      <td>0.941318</td>\n",
       "      <td>0.304547</td>\n",
       "      <td>0.520954</td>\n",
       "      <td>0.131296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15073977</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.070752e+09</td>\n",
       "      <td>Pg</td>\n",
       "      <td>regP</td>\n",
       "      <td>Pn</td>\n",
       "      <td>regP</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>A</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>3.529159</td>\n",
       "      <td>0.085323</td>\n",
       "      <td>0.486815</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.211185</td>\n",
       "      <td>0.225393</td>\n",
       "      <td>0.257161</td>\n",
       "      <td>0.413598</td>\n",
       "      <td>0.287086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARID  STA          TIME IPHASE CLASS_IPHASE PHASE CLASS_PHASE   RETIME  \\\n",
       "0  14972252  URZ  1.069735e+09     Pn         regP    Pn        regP  2.94244   \n",
       "1  14992929  URZ  1.070059e+09     Pn         regP    Pn        regP  0.00000   \n",
       "2  15029724  URZ  1.070386e+09     Pn         regP    Pn        regP  0.65000   \n",
       "3  15031571  URZ  1.070403e+09     Pn         regP    Pn        regP  3.22500   \n",
       "4  15073977  URZ  1.070752e+09     Pg         regP    Pn        regP  0.00000   \n",
       "\n",
       "  SOURCE       PER    ...        HMXMN    HVRATP     HVRAT  NAB    TAB  \\\n",
       "0      A  0.166667    ...     1.542596  0.124299  0.176237  0.1  0.100   \n",
       "1      A  0.333333    ...     1.301846  1.112025  0.258914  0.2  0.245   \n",
       "2      A  0.166667    ...     1.828008  0.132138  0.192003  0.2  0.375   \n",
       "3      A  0.444444    ...     1.375773  0.282216  0.589090  0.1  0.050   \n",
       "4      A  0.166667    ...     3.529159  0.085323  0.486815  0.1  0.290   \n",
       "\n",
       "      HTOV1     HTOV2     HTOV3     HTOV4     HTOV5  \n",
       "0  0.509125  0.983261  0.619635  0.118464  0.058735  \n",
       "1  3.730434  0.738458  0.704325  0.247701  0.060989  \n",
       "2  0.629496  0.632947  0.277982  0.542543  0.041916  \n",
       "3  0.924411  0.941318  0.304547  0.520954  0.131296  \n",
       "4  0.211185  0.225393  0.257161  0.413598  0.287086  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select * from ml_features where sta='URZ' and class_phase='tele'\"\"\"\n",
    "df_T_all = pd.read_sql(query, con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARID</th>\n",
       "      <th>STA</th>\n",
       "      <th>TIME</th>\n",
       "      <th>IPHASE</th>\n",
       "      <th>CLASS_IPHASE</th>\n",
       "      <th>PHASE</th>\n",
       "      <th>CLASS_PHASE</th>\n",
       "      <th>RETIME</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>PER</th>\n",
       "      <th>...</th>\n",
       "      <th>HMXMN</th>\n",
       "      <th>HVRATP</th>\n",
       "      <th>HVRAT</th>\n",
       "      <th>NAB</th>\n",
       "      <th>TAB</th>\n",
       "      <th>HTOV1</th>\n",
       "      <th>HTOV2</th>\n",
       "      <th>HTOV3</th>\n",
       "      <th>HTOV4</th>\n",
       "      <th>HTOV5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28541585</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.143123e+09</td>\n",
       "      <td>P</td>\n",
       "      <td>tele</td>\n",
       "      <td>P</td>\n",
       "      <td>tele</td>\n",
       "      <td>0.550</td>\n",
       "      <td>A</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.702892</td>\n",
       "      <td>0.042081</td>\n",
       "      <td>0.042081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.467387</td>\n",
       "      <td>0.594238</td>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.053682</td>\n",
       "      <td>0.463873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28556291</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.143197e+09</td>\n",
       "      <td>P</td>\n",
       "      <td>tele</td>\n",
       "      <td>P</td>\n",
       "      <td>tele</td>\n",
       "      <td>0.500</td>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.957241</td>\n",
       "      <td>0.223522</td>\n",
       "      <td>0.223522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.954016</td>\n",
       "      <td>0.705002</td>\n",
       "      <td>1.308694</td>\n",
       "      <td>0.193754</td>\n",
       "      <td>0.114283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28557837</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.143204e+09</td>\n",
       "      <td>P</td>\n",
       "      <td>tele</td>\n",
       "      <td>P</td>\n",
       "      <td>tele</td>\n",
       "      <td>3.100</td>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190828</td>\n",
       "      <td>0.240041</td>\n",
       "      <td>0.613747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.577677</td>\n",
       "      <td>1.020239</td>\n",
       "      <td>0.372745</td>\n",
       "      <td>0.277075</td>\n",
       "      <td>0.067225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28559193</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.143210e+09</td>\n",
       "      <td>P</td>\n",
       "      <td>tele</td>\n",
       "      <td>P</td>\n",
       "      <td>tele</td>\n",
       "      <td>0.000</td>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.531207</td>\n",
       "      <td>0.084376</td>\n",
       "      <td>0.084376</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.689514</td>\n",
       "      <td>0.333741</td>\n",
       "      <td>0.336678</td>\n",
       "      <td>0.119060</td>\n",
       "      <td>0.092935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28561877</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.143223e+09</td>\n",
       "      <td>P</td>\n",
       "      <td>tele</td>\n",
       "      <td>P</td>\n",
       "      <td>tele</td>\n",
       "      <td>0.375</td>\n",
       "      <td>A</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>2.808070</td>\n",
       "      <td>0.038871</td>\n",
       "      <td>0.097918</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.358785</td>\n",
       "      <td>0.042658</td>\n",
       "      <td>0.127151</td>\n",
       "      <td>0.064076</td>\n",
       "      <td>0.062188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARID  STA          TIME IPHASE CLASS_IPHASE PHASE CLASS_PHASE  RETIME  \\\n",
       "0  28541585  URZ  1.143123e+09      P         tele     P        tele   0.550   \n",
       "1  28556291  URZ  1.143197e+09      P         tele     P        tele   0.500   \n",
       "2  28557837  URZ  1.143204e+09      P         tele     P        tele   3.100   \n",
       "3  28559193  URZ  1.143210e+09      P         tele     P        tele   0.000   \n",
       "4  28561877  URZ  1.143223e+09      P         tele     P        tele   0.375   \n",
       "\n",
       "  SOURCE       PER    ...        HMXMN    HVRATP     HVRAT  NAB    TAB  \\\n",
       "0      A  0.666667    ...     1.702892  0.042081  0.042081  0.0  0.000   \n",
       "1      A  0.333333    ...     1.957241  0.223522  0.223522  0.0  0.000   \n",
       "2      A  0.333333    ...     1.190828  0.240041  0.613747  0.0 -0.195   \n",
       "3      A  0.333333    ...     1.531207  0.084376  0.084376  0.1  0.130   \n",
       "4      A  0.444444    ...     2.808070  0.038871  0.097918  0.1  0.205   \n",
       "\n",
       "      HTOV1     HTOV2     HTOV3     HTOV4     HTOV5  \n",
       "0  0.467387  0.594238  0.057473  0.053682  0.463873  \n",
       "1  0.954016  0.705002  1.308694  0.193754  0.114283  \n",
       "2  0.577677  1.020239  0.372745  0.277075  0.067225  \n",
       "3  0.689514  0.333741  0.336678  0.119060  0.092935  \n",
       "4  0.358785  0.042658  0.127151  0.064076  0.062188  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_T_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select * from ml_features where sta='URZ' and class_phase='N'\"\"\"\n",
    "df_N_all = pd.read_sql(query, con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARID</th>\n",
       "      <th>STA</th>\n",
       "      <th>TIME</th>\n",
       "      <th>IPHASE</th>\n",
       "      <th>CLASS_IPHASE</th>\n",
       "      <th>PHASE</th>\n",
       "      <th>CLASS_PHASE</th>\n",
       "      <th>RETIME</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>PER</th>\n",
       "      <th>...</th>\n",
       "      <th>HMXMN</th>\n",
       "      <th>HVRATP</th>\n",
       "      <th>HVRAT</th>\n",
       "      <th>NAB</th>\n",
       "      <th>TAB</th>\n",
       "      <th>HTOV1</th>\n",
       "      <th>HTOV2</th>\n",
       "      <th>HTOV3</th>\n",
       "      <th>HTOV4</th>\n",
       "      <th>HTOV5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13097443</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.055511e+09</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.948945</td>\n",
       "      <td>9.600216</td>\n",
       "      <td>9.600216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.396880</td>\n",
       "      <td>1.145887</td>\n",
       "      <td>0.421142</td>\n",
       "      <td>0.406116</td>\n",
       "      <td>1.439137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13097727</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.055513e+09</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>5.750848</td>\n",
       "      <td>9.726424</td>\n",
       "      <td>3.211865</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.628241</td>\n",
       "      <td>0.617270</td>\n",
       "      <td>0.890586</td>\n",
       "      <td>2.788352</td>\n",
       "      <td>1.279634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13097728</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.055513e+09</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.550819</td>\n",
       "      <td>0.163623</td>\n",
       "      <td>12.531935</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.625565</td>\n",
       "      <td>0.419386</td>\n",
       "      <td>0.502452</td>\n",
       "      <td>1.093746</td>\n",
       "      <td>0.228218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13097729</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.055513e+09</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>2.203439</td>\n",
       "      <td>0.328290</td>\n",
       "      <td>0.511023</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.532591</td>\n",
       "      <td>1.455946</td>\n",
       "      <td>0.672186</td>\n",
       "      <td>0.730198</td>\n",
       "      <td>0.130826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13097946</td>\n",
       "      <td>URZ</td>\n",
       "      <td>1.055517e+09</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.803004</td>\n",
       "      <td>0.827978</td>\n",
       "      <td>0.630203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.039954</td>\n",
       "      <td>0.420590</td>\n",
       "      <td>0.983108</td>\n",
       "      <td>0.450562</td>\n",
       "      <td>0.274970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARID  STA          TIME IPHASE CLASS_IPHASE PHASE CLASS_PHASE  RETIME  \\\n",
       "0  13097443  URZ  1.055511e+09      N            N  None           N     0.0   \n",
       "1  13097727  URZ  1.055513e+09      N            N  None           N     0.0   \n",
       "2  13097728  URZ  1.055513e+09      N            N  None           N     0.0   \n",
       "3  13097729  URZ  1.055513e+09      N            N  None           N     0.0   \n",
       "4  13097946  URZ  1.055517e+09      N            N  None           N     0.0   \n",
       "\n",
       "  SOURCE       PER    ...        HMXMN    HVRATP      HVRAT  NAB   TAB  \\\n",
       "0      A  0.166667    ...     2.948945  9.600216   9.600216  0.0  0.00   \n",
       "1      A  0.444444    ...     5.750848  9.726424   3.211865 -0.1 -0.04   \n",
       "2      A  1.000000    ...     1.550819  0.163623  12.531935  0.1  0.50   \n",
       "3      A  0.333333    ...     2.203439  0.328290   0.511023 -0.1 -0.50   \n",
       "4      A  1.000000    ...     2.803004  0.827978   0.630203  0.0  0.00   \n",
       "\n",
       "      HTOV1     HTOV2     HTOV3     HTOV4     HTOV5  \n",
       "0  0.396880  1.145887  0.421142  0.406116  1.439137  \n",
       "1  0.628241  0.617270  0.890586  2.788352  1.279634  \n",
       "2  2.625565  0.419386  0.502452  1.093746  0.228218  \n",
       "3  0.532591  1.455946  0.672186  0.730198  0.130826  \n",
       "4  1.039954  0.420590  0.983108  0.450562  0.274970  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_N_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "#df_ora.to_csv('URZ_pandas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regS (11204, 25)\n",
      "regP (11828, 25)\n",
      "tele (38108, 25)\n",
      "noise (308706, 25)\n"
     ]
    }
   ],
   "source": [
    "#how much data we have\n",
    "print('regS', df_S_all.shape)\n",
    "print('regP', df_P_all.shape)\n",
    "print('tele', df_T_all.shape)\n",
    "print('noise', df_N_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features count: 15\n"
     ]
    }
   ],
   "source": [
    "# columns corresponding to input\n",
    "x_indices = ['PER', 'RECT', 'PLANS', 'INANG1', 'INANG3', 'HMXMN', 'HVRATP', 'HVRAT', 'NAB', 'TAB',  \n",
    "             'HTOV1', 'HTOV2', 'HTOV3', 'HTOV4', 'HTOV5']\n",
    "print('features count:', len(x_indices))\n",
    "# columns corresponding to output\n",
    "y_indices = ['CLASS_PHASE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for first phase of the cascade: N vs TPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9202, 25) (9202, 25) (9202, 25)\n",
      "(27606, 25)\n",
      "(27606, 25)\n"
     ]
    }
   ],
   "source": [
    "#counts of all classes\n",
    "ns = df_S_all.shape[0]\n",
    "np = df_P_all.shape[0]\n",
    "nt = df_T_all.shape[0]\n",
    "nn = df_N_all.shape[0]\n",
    "\n",
    "#those from automatic\n",
    "nsa = df_S_all[df_S_all['SOURCE'] != 'M'].shape[0]\n",
    "npa = df_P_all[df_P_all['SOURCE'] != 'M'].shape[0]\n",
    "nta = df_T_all[df_T_all['SOURCE'] != 'M'].shape[0]\n",
    "nna = df_N_all[df_N_all['SOURCE'] != 'M'].shape[0]\n",
    "\n",
    "#we build a balanced datased - the same portion of regS, regP and tele\n",
    "#we have this count of phases\n",
    "samp_count = min(nsa, npa, nta)\n",
    "\n",
    "#sample TPS dataset, random_state is a seed\n",
    "ssS = df_S_all[df_S_all['SOURCE'] != 'M'].sample(samp_count, random_state=11)\n",
    "ssP = df_P_all[df_P_all['SOURCE'] != 'M'].sample(samp_count)\n",
    "ssT = df_T_all[df_T_all['SOURCE'] != 'M'].sample(samp_count)\n",
    "TPS_data = pd.concat([ssS, ssP, ssT])\n",
    "\n",
    "#sample noise phases\n",
    "N_data = df_N_all[df_N_all['SOURCE'] != 'M'].sample(3*samp_count)\n",
    "\n",
    "#lets shuffle dataset\n",
    "TPS_data = TPS_data.sample(frac=1).reset_index(drop=True)\n",
    "N_data = N_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(ssS.shape, ssP.shape, ssT.shape)\n",
    "print(TPS_data.shape)\n",
    "print(N_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The same for manually added arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dvlscratch/SHI/users/hofman/ML/env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train/test ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count= 20704 test count= 6902\n"
     ]
    }
   ],
   "source": [
    "train_test_split_ratio = 0.75\n",
    "samp_count_train = int(TPS_data.shape[0] * train_test_split_ratio)\n",
    "samp_count_test = TPS_data.shape[0] - samp_count_train\n",
    "print('train count=', samp_count_train, 'test count=', samp_count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPS train: (20704, 25) TPS test: (6902, 25)\n",
      "N train:   (20704, 25) N test:   (6902, 25)\n"
     ]
    }
   ],
   "source": [
    "TPS_train = TPS_data[:samp_count_train]\n",
    "TPS_test = TPS_data[samp_count_train:]\n",
    "\n",
    "N_train = N_data[:samp_count_train]\n",
    "N_test = N_data[samp_count_train:]\n",
    "\n",
    "print('TPS train:',TPS_train.shape,'TPS test:',TPS_test.shape)\n",
    "print('N train:  ',N_train.shape,  'N test:  ',N_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check interclass balance of TPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T in TPS train:    (6874, 25)\n",
      "regP in TPS train: (6960, 25)\n",
      "regS in TPS train: (6870, 25)\n",
      "T in TPS test:     (2328, 25)\n",
      "regP in TPS test:  (2242, 25)\n",
      "regS in TPS test:  (2332, 25)\n"
     ]
    }
   ],
   "source": [
    "print('T in TPS train:   ', TPS_train[TPS_train['CLASS_PHASE']=='tele'].shape)\n",
    "print('regP in TPS train:', TPS_train[TPS_train['CLASS_PHASE']=='regP'].shape)\n",
    "print('regS in TPS train:', TPS_train[TPS_train['CLASS_PHASE']=='regS'].shape)\n",
    "\n",
    "print('T in TPS test:    ', TPS_test[TPS_test['CLASS_PHASE']=='tele'].shape)\n",
    "print('regP in TPS test: ', TPS_test[TPS_test['CLASS_PHASE']=='regP'].shape)\n",
    "print('regS in TPS test: ', TPS_test[TPS_test['CLASS_PHASE']=='regS'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form train and test sets and shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([TPS_train, N_train]).sample(frac=1).reset_index(drop=True)\n",
    "test =  pd.concat([TPS_test, N_test]).sample(frac=1).reset_index(drop=True)\n",
    "#train.apply(pd.to_numeric, errors='ignore')\n",
    "#test.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features and class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41408, 15) (41408, 2) (13804, 15) (13804, 2)\n"
     ]
    }
   ],
   "source": [
    "train_X = train[x_indices].values.astype(float)\n",
    "train_Y = train[y_indices]\n",
    "\n",
    "test_X = test[x_indices].values.astype(float)\n",
    "test_Y = test[y_indices]\n",
    "\n",
    "train_Y_ = numpy.array(numpy.where(train_Y == 'N', 0, 1), dtype=float)\n",
    "test_Y_ = numpy.array(numpy.where(test_Y == 'N', 0, 1), dtype=float)\n",
    "\n",
    "#convert to categorical\n",
    "train_Y = keras.utils.to_categorical(train_Y_)\n",
    "test_Y = keras.utils.to_categorical(test_Y_)\n",
    "\n",
    "print(train_X.shape, train_Y.shape, test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground truth for all 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dvlscratch/SHI/users/hofman/ML/env/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 2, 0, 1, 1, 0, 0, 3, 0, 0, 2, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['N', 'regS', 'regP', 'tele'])\n",
    "test_Y_GT = le.transform(test[y_indices])\n",
    "train_Y_GT = le.transform(train[y_indices])\n",
    "test_Y_GT[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = len(x_indices)\n",
    "numpy.random.seed(11)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(n_input, input_dim=n_input, activation='sigmoid'))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=1., clipvalue=0.5)\n",
    "adam = Adam(lr=0.0001) #, clipnorm, clipvalue=0.5)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy', \n",
    "    optimizer = 'adam',  # adam, sgd\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 96        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 350\n",
      "Trainable params: 350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_keys = ('acc', 'val_acc', 'loss', 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {k : [] for k in hist_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41408 samples, validate on 13804 samples\n",
      "Epoch 1/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.6442 - acc: 0.6316 - val_loss: 0.5943 - val_acc: 0.7071\n",
      "Epoch 2/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.5479 - acc: 0.7339 - val_loss: 0.5019 - val_acc: 0.7653\n",
      "Epoch 3/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.4844 - acc: 0.7698 - val_loss: 0.4603 - val_acc: 0.7878\n",
      "Epoch 4/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.4530 - acc: 0.7893 - val_loss: 0.4416 - val_acc: 0.7985\n",
      "Epoch 5/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.4371 - acc: 0.7971 - val_loss: 0.4233 - val_acc: 0.8091\n",
      "Epoch 6/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.4293 - acc: 0.8023 - val_loss: 0.4221 - val_acc: 0.8052\n",
      "Epoch 7/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.4239 - acc: 0.8059 - val_loss: 0.4139 - val_acc: 0.8106\n",
      "Epoch 8/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.4184 - acc: 0.8086 - val_loss: 0.4081 - val_acc: 0.8151\n",
      "Epoch 9/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.4159 - acc: 0.8104 - val_loss: 0.4072 - val_acc: 0.8202\n",
      "Epoch 10/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.4133 - acc: 0.8114 - val_loss: 0.4061 - val_acc: 0.8136\n",
      "Epoch 11/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.4103 - acc: 0.8128 - val_loss: 0.4018 - val_acc: 0.8149\n",
      "Epoch 12/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.4090 - acc: 0.8125 - val_loss: 0.3989 - val_acc: 0.8167\n",
      "Epoch 13/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.4072 - acc: 0.8139 - val_loss: 0.3975 - val_acc: 0.8181\n",
      "Epoch 14/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.4049 - acc: 0.8145 - val_loss: 0.3956 - val_acc: 0.8168\n",
      "Epoch 15/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.4041 - acc: 0.8152 - val_loss: 0.3964 - val_acc: 0.8194\n",
      "Epoch 16/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.4025 - acc: 0.8166 - val_loss: 0.3915 - val_acc: 0.8199\n",
      "Epoch 17/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.4014 - acc: 0.8166 - val_loss: 0.3994 - val_acc: 0.8231\n",
      "Epoch 18/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3996 - acc: 0.8195 - val_loss: 0.3980 - val_acc: 0.8154\n",
      "Epoch 19/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3985 - acc: 0.8176 - val_loss: 0.3891 - val_acc: 0.8247\n",
      "Epoch 20/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3974 - acc: 0.8196 - val_loss: 0.3992 - val_acc: 0.8226\n",
      "Epoch 21/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3969 - acc: 0.8191 - val_loss: 0.3875 - val_acc: 0.8227\n",
      "Epoch 22/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3951 - acc: 0.8199 - val_loss: 0.3886 - val_acc: 0.8206\n",
      "Epoch 23/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3924 - acc: 0.8187 - val_loss: 0.3832 - val_acc: 0.8238\n",
      "Epoch 24/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3912 - acc: 0.8216 - val_loss: 0.3828 - val_acc: 0.8260\n",
      "Epoch 25/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3885 - acc: 0.8224 - val_loss: 0.3772 - val_acc: 0.8273\n",
      "Epoch 26/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3868 - acc: 0.8226 - val_loss: 0.3793 - val_acc: 0.8254\n",
      "Epoch 27/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3843 - acc: 0.8239 - val_loss: 0.3811 - val_acc: 0.8247\n",
      "Epoch 28/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3832 - acc: 0.8249 - val_loss: 0.3759 - val_acc: 0.8290\n",
      "Epoch 29/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3821 - acc: 0.8259 - val_loss: 0.3762 - val_acc: 0.8293\n",
      "Epoch 30/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3809 - acc: 0.8268 - val_loss: 0.3738 - val_acc: 0.8283\n",
      "Epoch 31/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3802 - acc: 0.8263 - val_loss: 0.3729 - val_acc: 0.8306\n",
      "Epoch 32/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3794 - acc: 0.8263 - val_loss: 0.3810 - val_acc: 0.8266\n",
      "Epoch 33/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3788 - acc: 0.8275 - val_loss: 0.3784 - val_acc: 0.8289\n",
      "Epoch 34/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3772 - acc: 0.8280 - val_loss: 0.3686 - val_acc: 0.8318\n",
      "Epoch 35/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3776 - acc: 0.8282 - val_loss: 0.3774 - val_acc: 0.8267\n",
      "Epoch 36/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3765 - acc: 0.8300 - val_loss: 0.3775 - val_acc: 0.8275\n",
      "Epoch 37/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3758 - acc: 0.8285 - val_loss: 0.3778 - val_acc: 0.8311\n",
      "Epoch 38/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3745 - acc: 0.8306 - val_loss: 0.3663 - val_acc: 0.8340\n",
      "Epoch 39/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3748 - acc: 0.8309 - val_loss: 0.3672 - val_acc: 0.8344\n",
      "Epoch 40/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3748 - acc: 0.8295 - val_loss: 0.3704 - val_acc: 0.8302\n",
      "Epoch 41/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3739 - acc: 0.8303 - val_loss: 0.3717 - val_acc: 0.8314\n",
      "Epoch 42/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3737 - acc: 0.8306 - val_loss: 0.3657 - val_acc: 0.8343\n",
      "Epoch 43/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3724 - acc: 0.8324 - val_loss: 0.3671 - val_acc: 0.8317\n",
      "Epoch 44/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3716 - acc: 0.8316 - val_loss: 0.3756 - val_acc: 0.8317\n",
      "Epoch 45/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3712 - acc: 0.8321 - val_loss: 0.3680 - val_acc: 0.8316\n",
      "Epoch 46/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3721 - acc: 0.8317 - val_loss: 0.3673 - val_acc: 0.8343\n",
      "Epoch 47/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3715 - acc: 0.8326 - val_loss: 0.3625 - val_acc: 0.8364\n",
      "Epoch 48/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3705 - acc: 0.8306 - val_loss: 0.3664 - val_acc: 0.8314\n",
      "Epoch 49/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3700 - acc: 0.8319 - val_loss: 0.3908 - val_acc: 0.8232\n",
      "Epoch 50/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3691 - acc: 0.8319 - val_loss: 0.3648 - val_acc: 0.8346\n",
      "Epoch 51/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3704 - acc: 0.8334 - val_loss: 0.3653 - val_acc: 0.8333\n",
      "Epoch 52/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3698 - acc: 0.8318 - val_loss: 0.3621 - val_acc: 0.8381\n",
      "Epoch 53/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3700 - acc: 0.8325 - val_loss: 0.3658 - val_acc: 0.8328\n",
      "Epoch 54/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3691 - acc: 0.8325 - val_loss: 0.3633 - val_acc: 0.8349\n",
      "Epoch 55/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3690 - acc: 0.8332 - val_loss: 0.3640 - val_acc: 0.8364\n",
      "Epoch 56/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3692 - acc: 0.8318 - val_loss: 0.3635 - val_acc: 0.8352\n",
      "Epoch 57/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3692 - acc: 0.8325 - val_loss: 0.3612 - val_acc: 0.8343\n",
      "Epoch 58/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3684 - acc: 0.8322 - val_loss: 0.3627 - val_acc: 0.8366\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3674 - acc: 0.8320 - val_loss: 0.3614 - val_acc: 0.8361\n",
      "Epoch 60/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3690 - acc: 0.8318 - val_loss: 0.3597 - val_acc: 0.8375\n",
      "Epoch 61/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3678 - acc: 0.8339 - val_loss: 0.3628 - val_acc: 0.8359\n",
      "Epoch 62/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3689 - acc: 0.8321 - val_loss: 0.3609 - val_acc: 0.8368\n",
      "Epoch 63/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3666 - acc: 0.8334 - val_loss: 0.3641 - val_acc: 0.8364\n",
      "Epoch 64/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3666 - acc: 0.8343 - val_loss: 0.3619 - val_acc: 0.8367\n",
      "Epoch 65/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3674 - acc: 0.8328 - val_loss: 0.3658 - val_acc: 0.8300\n",
      "Epoch 66/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3677 - acc: 0.8324 - val_loss: 0.3628 - val_acc: 0.8334\n",
      "Epoch 67/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3677 - acc: 0.8336 - val_loss: 0.3623 - val_acc: 0.8361\n",
      "Epoch 68/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3665 - acc: 0.8338 - val_loss: 0.3710 - val_acc: 0.8316\n",
      "Epoch 69/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3661 - acc: 0.8347 - val_loss: 0.3605 - val_acc: 0.8378\n",
      "Epoch 70/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3664 - acc: 0.8332 - val_loss: 0.3672 - val_acc: 0.8342\n",
      "Epoch 71/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3656 - acc: 0.8333 - val_loss: 0.3603 - val_acc: 0.8378\n",
      "Epoch 72/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3661 - acc: 0.8337 - val_loss: 0.3650 - val_acc: 0.8320\n",
      "Epoch 73/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3664 - acc: 0.8335 - val_loss: 0.3698 - val_acc: 0.8336\n",
      "Epoch 74/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3664 - acc: 0.8325 - val_loss: 0.3626 - val_acc: 0.8355\n",
      "Epoch 75/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3654 - acc: 0.8332 - val_loss: 0.3591 - val_acc: 0.8374\n",
      "Epoch 76/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3661 - acc: 0.8339 - val_loss: 0.3588 - val_acc: 0.8373\n",
      "Epoch 77/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3645 - acc: 0.8337 - val_loss: 0.3603 - val_acc: 0.8353\n",
      "Epoch 78/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3659 - acc: 0.8329 - val_loss: 0.3600 - val_acc: 0.8363\n",
      "Epoch 79/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3650 - acc: 0.8340 - val_loss: 0.3632 - val_acc: 0.8353\n",
      "Epoch 80/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3652 - acc: 0.8347 - val_loss: 0.3587 - val_acc: 0.8382\n",
      "Epoch 81/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3656 - acc: 0.8343 - val_loss: 0.3616 - val_acc: 0.8329\n",
      "Epoch 82/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3658 - acc: 0.8335 - val_loss: 0.3601 - val_acc: 0.8359\n",
      "Epoch 83/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3649 - acc: 0.8341 - val_loss: 0.3607 - val_acc: 0.8382\n",
      "Epoch 84/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3655 - acc: 0.8335 - val_loss: 0.3669 - val_acc: 0.8350\n",
      "Epoch 85/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3644 - acc: 0.8346 - val_loss: 0.3550 - val_acc: 0.8390\n",
      "Epoch 86/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3645 - acc: 0.8345 - val_loss: 0.3610 - val_acc: 0.8375\n",
      "Epoch 87/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3637 - acc: 0.8338 - val_loss: 0.3612 - val_acc: 0.8343\n",
      "Epoch 88/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3650 - acc: 0.8354 - val_loss: 0.3690 - val_acc: 0.8299\n",
      "Epoch 89/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3648 - acc: 0.8344 - val_loss: 0.3591 - val_acc: 0.8387\n",
      "Epoch 90/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3645 - acc: 0.8342 - val_loss: 0.3575 - val_acc: 0.8395\n",
      "Epoch 91/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3641 - acc: 0.8359 - val_loss: 0.3626 - val_acc: 0.8373\n",
      "Epoch 92/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3644 - acc: 0.8337 - val_loss: 0.3562 - val_acc: 0.8401\n",
      "Epoch 93/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3641 - acc: 0.8347 - val_loss: 0.3745 - val_acc: 0.8260\n",
      "Epoch 94/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3643 - acc: 0.8355 - val_loss: 0.3554 - val_acc: 0.8394\n",
      "Epoch 95/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3639 - acc: 0.8352 - val_loss: 0.3602 - val_acc: 0.8344\n",
      "Epoch 96/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3633 - acc: 0.8342 - val_loss: 0.3614 - val_acc: 0.8380\n",
      "Epoch 97/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3642 - acc: 0.8339 - val_loss: 0.3576 - val_acc: 0.8379\n",
      "Epoch 98/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3639 - acc: 0.8342 - val_loss: 0.3597 - val_acc: 0.8356\n",
      "Epoch 99/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3634 - acc: 0.8349 - val_loss: 0.3651 - val_acc: 0.8339\n",
      "Epoch 100/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3637 - acc: 0.8347 - val_loss: 0.3583 - val_acc: 0.8376\n",
      "Epoch 101/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3627 - acc: 0.8344 - val_loss: 0.3590 - val_acc: 0.8362\n",
      "Epoch 102/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3627 - acc: 0.8358 - val_loss: 0.3577 - val_acc: 0.8374\n",
      "Epoch 103/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3643 - acc: 0.8346 - val_loss: 0.3573 - val_acc: 0.8379\n",
      "Epoch 104/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3634 - acc: 0.8351 - val_loss: 0.3588 - val_acc: 0.8370\n",
      "Epoch 105/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3642 - acc: 0.8334 - val_loss: 0.3577 - val_acc: 0.8387\n",
      "Epoch 106/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3629 - acc: 0.8343 - val_loss: 0.3578 - val_acc: 0.8382\n",
      "Epoch 107/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3626 - acc: 0.8359 - val_loss: 0.3604 - val_acc: 0.8370\n",
      "Epoch 108/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3631 - acc: 0.8343 - val_loss: 0.3607 - val_acc: 0.8364\n",
      "Epoch 109/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3622 - acc: 0.8349 - val_loss: 0.3592 - val_acc: 0.8378\n",
      "Epoch 110/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3622 - acc: 0.8363 - val_loss: 0.3574 - val_acc: 0.8377\n",
      "Epoch 111/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3623 - acc: 0.8346 - val_loss: 0.3573 - val_acc: 0.8397\n",
      "Epoch 112/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3628 - acc: 0.8352 - val_loss: 0.3630 - val_acc: 0.8337\n",
      "Epoch 113/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3622 - acc: 0.8351 - val_loss: 0.3579 - val_acc: 0.8372\n",
      "Epoch 114/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3621 - acc: 0.8349 - val_loss: 0.3568 - val_acc: 0.8360\n",
      "Epoch 115/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3627 - acc: 0.8354 - val_loss: 0.3583 - val_acc: 0.8405\n",
      "Epoch 116/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3616 - acc: 0.8361 - val_loss: 0.3567 - val_acc: 0.8390\n",
      "Epoch 117/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3611 - acc: 0.8369 - val_loss: 0.3619 - val_acc: 0.8344\n",
      "Epoch 118/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3616 - acc: 0.8352 - val_loss: 0.3555 - val_acc: 0.8402\n",
      "Epoch 119/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3624 - acc: 0.8347 - val_loss: 0.3573 - val_acc: 0.8409\n",
      "Epoch 120/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3614 - acc: 0.8354 - val_loss: 0.3536 - val_acc: 0.8404\n",
      "Epoch 121/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3609 - acc: 0.8358 - val_loss: 0.3556 - val_acc: 0.8409\n",
      "Epoch 122/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3616 - acc: 0.8358 - val_loss: 0.3583 - val_acc: 0.8383\n",
      "Epoch 123/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3611 - acc: 0.8358 - val_loss: 0.3560 - val_acc: 0.8401\n",
      "Epoch 124/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3615 - acc: 0.8357 - val_loss: 0.3566 - val_acc: 0.8377\n",
      "Epoch 125/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3630 - acc: 0.8355 - val_loss: 0.3558 - val_acc: 0.8390\n",
      "Epoch 126/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3618 - acc: 0.8349 - val_loss: 0.3541 - val_acc: 0.8390\n",
      "Epoch 127/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3616 - acc: 0.8359 - val_loss: 0.3554 - val_acc: 0.8408\n",
      "Epoch 128/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3619 - acc: 0.8352 - val_loss: 0.3554 - val_acc: 0.8407\n",
      "Epoch 129/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3614 - acc: 0.8363 - val_loss: 0.3637 - val_acc: 0.8331\n",
      "Epoch 130/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3616 - acc: 0.8354 - val_loss: 0.3623 - val_acc: 0.8331\n",
      "Epoch 131/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3605 - acc: 0.8361 - val_loss: 0.3567 - val_acc: 0.8386\n",
      "Epoch 132/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3606 - acc: 0.8357 - val_loss: 0.3538 - val_acc: 0.8398\n",
      "Epoch 133/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3606 - acc: 0.8366 - val_loss: 0.3572 - val_acc: 0.8356\n",
      "Epoch 134/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3605 - acc: 0.8353 - val_loss: 0.3651 - val_acc: 0.8324\n",
      "Epoch 135/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3618 - acc: 0.8351 - val_loss: 0.3554 - val_acc: 0.8392\n",
      "Epoch 136/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3608 - acc: 0.8364 - val_loss: 0.3566 - val_acc: 0.8408\n",
      "Epoch 137/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3615 - acc: 0.8345 - val_loss: 0.3549 - val_acc: 0.8404\n",
      "Epoch 138/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3613 - acc: 0.8359 - val_loss: 0.3708 - val_acc: 0.8320\n",
      "Epoch 139/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3614 - acc: 0.8357 - val_loss: 0.3553 - val_acc: 0.8419\n",
      "Epoch 140/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3602 - acc: 0.8363 - val_loss: 0.3560 - val_acc: 0.8385\n",
      "Epoch 141/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3607 - acc: 0.8356 - val_loss: 0.3580 - val_acc: 0.8382\n",
      "Epoch 142/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3603 - acc: 0.8359 - val_loss: 0.3555 - val_acc: 0.8395\n",
      "Epoch 143/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3604 - acc: 0.8372 - val_loss: 0.3543 - val_acc: 0.8394\n",
      "Epoch 144/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3608 - acc: 0.8364 - val_loss: 0.3589 - val_acc: 0.8375\n",
      "Epoch 145/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3604 - acc: 0.8366 - val_loss: 0.3565 - val_acc: 0.8380\n",
      "Epoch 146/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3608 - acc: 0.8352 - val_loss: 0.3544 - val_acc: 0.8412\n",
      "Epoch 147/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3600 - acc: 0.8355 - val_loss: 0.3552 - val_acc: 0.8391\n",
      "Epoch 148/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3596 - acc: 0.8372 - val_loss: 0.3585 - val_acc: 0.8365\n",
      "Epoch 149/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3598 - acc: 0.8368 - val_loss: 0.3530 - val_acc: 0.8407\n",
      "Epoch 150/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3605 - acc: 0.8359 - val_loss: 0.3554 - val_acc: 0.8407\n",
      "Epoch 151/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3590 - acc: 0.8376 - val_loss: 0.3537 - val_acc: 0.8420\n",
      "Epoch 152/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3594 - acc: 0.8363 - val_loss: 0.3540 - val_acc: 0.8400\n",
      "Epoch 153/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3594 - acc: 0.8372 - val_loss: 0.3558 - val_acc: 0.8385\n",
      "Epoch 154/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3591 - acc: 0.8374 - val_loss: 0.3656 - val_acc: 0.8360\n",
      "Epoch 155/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3594 - acc: 0.8373 - val_loss: 0.3545 - val_acc: 0.8410\n",
      "Epoch 156/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3597 - acc: 0.8367 - val_loss: 0.3584 - val_acc: 0.8349\n",
      "Epoch 157/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3597 - acc: 0.8376 - val_loss: 0.3538 - val_acc: 0.8425\n",
      "Epoch 158/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3596 - acc: 0.8365 - val_loss: 0.3543 - val_acc: 0.8394\n",
      "Epoch 159/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3589 - acc: 0.8391 - val_loss: 0.3588 - val_acc: 0.8398\n",
      "Epoch 160/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3589 - acc: 0.8378 - val_loss: 0.3550 - val_acc: 0.8411\n",
      "Epoch 161/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3577 - acc: 0.8386 - val_loss: 0.3550 - val_acc: 0.8405\n",
      "Epoch 162/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3581 - acc: 0.8372 - val_loss: 0.3545 - val_acc: 0.8399\n",
      "Epoch 163/2000\n",
      "41408/41408 [==============================] - 1s 26us/step - loss: 0.3583 - acc: 0.8381 - val_loss: 0.3636 - val_acc: 0.8380\n",
      "Epoch 164/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3589 - acc: 0.8376 - val_loss: 0.3544 - val_acc: 0.8411\n",
      "Epoch 165/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3584 - acc: 0.8377 - val_loss: 0.3538 - val_acc: 0.8417\n",
      "Epoch 166/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3581 - acc: 0.8380 - val_loss: 0.3536 - val_acc: 0.8413\n",
      "Epoch 167/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3588 - acc: 0.8368 - val_loss: 0.3542 - val_acc: 0.8414\n",
      "Epoch 168/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3585 - acc: 0.8377 - val_loss: 0.3562 - val_acc: 0.8412\n",
      "Epoch 169/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3588 - acc: 0.8372 - val_loss: 0.3526 - val_acc: 0.8415\n",
      "Epoch 170/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3584 - acc: 0.8372 - val_loss: 0.3739 - val_acc: 0.8303\n",
      "Epoch 171/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3580 - acc: 0.8388 - val_loss: 0.3538 - val_acc: 0.8396\n",
      "Epoch 172/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3578 - acc: 0.8374 - val_loss: 0.3533 - val_acc: 0.8419\n",
      "Epoch 173/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3581 - acc: 0.8385 - val_loss: 0.3523 - val_acc: 0.8430\n",
      "Epoch 174/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3578 - acc: 0.8379 - val_loss: 0.3598 - val_acc: 0.8394\n",
      "Epoch 175/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3579 - acc: 0.8371 - val_loss: 0.3548 - val_acc: 0.8415\n",
      "Epoch 176/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3583 - acc: 0.8369 - val_loss: 0.3565 - val_acc: 0.8378\n",
      "Epoch 177/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3572 - acc: 0.8371 - val_loss: 0.3522 - val_acc: 0.8435\n",
      "Epoch 178/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3582 - acc: 0.8376 - val_loss: 0.3537 - val_acc: 0.8426\n",
      "Epoch 179/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3581 - acc: 0.8380 - val_loss: 0.3599 - val_acc: 0.8387\n",
      "Epoch 180/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3575 - acc: 0.8390 - val_loss: 0.3628 - val_acc: 0.8370\n",
      "Epoch 181/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3575 - acc: 0.8374 - val_loss: 0.3607 - val_acc: 0.8374\n",
      "Epoch 182/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3573 - acc: 0.8381 - val_loss: 0.3563 - val_acc: 0.8383\n",
      "Epoch 183/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3574 - acc: 0.8377 - val_loss: 0.3576 - val_acc: 0.8387\n",
      "Epoch 184/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3570 - acc: 0.8371 - val_loss: 0.3518 - val_acc: 0.8427\n",
      "Epoch 185/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3575 - acc: 0.8380 - val_loss: 0.3530 - val_acc: 0.8432\n",
      "Epoch 186/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3568 - acc: 0.8380 - val_loss: 0.3549 - val_acc: 0.8386\n",
      "Epoch 187/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3566 - acc: 0.8379 - val_loss: 0.3592 - val_acc: 0.8352\n",
      "Epoch 188/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3566 - acc: 0.8395 - val_loss: 0.3648 - val_acc: 0.8339\n",
      "Epoch 189/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3564 - acc: 0.8379 - val_loss: 0.3575 - val_acc: 0.8365\n",
      "Epoch 190/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3563 - acc: 0.8393 - val_loss: 0.3531 - val_acc: 0.8410\n",
      "Epoch 191/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3567 - acc: 0.8385 - val_loss: 0.3540 - val_acc: 0.8392\n",
      "Epoch 192/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3564 - acc: 0.8388 - val_loss: 0.3546 - val_acc: 0.8402\n",
      "Epoch 193/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3570 - acc: 0.8380 - val_loss: 0.3536 - val_acc: 0.8420\n",
      "Epoch 194/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3560 - acc: 0.8388 - val_loss: 0.3551 - val_acc: 0.8406\n",
      "Epoch 195/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3553 - acc: 0.8391 - val_loss: 0.3571 - val_acc: 0.8395\n",
      "Epoch 196/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3557 - acc: 0.8389 - val_loss: 0.3543 - val_acc: 0.8393\n",
      "Epoch 197/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3561 - acc: 0.8389 - val_loss: 0.3552 - val_acc: 0.8377\n",
      "Epoch 198/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3559 - acc: 0.8390 - val_loss: 0.3542 - val_acc: 0.8398\n",
      "Epoch 199/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3559 - acc: 0.8392 - val_loss: 0.3575 - val_acc: 0.8384\n",
      "Epoch 200/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3572 - acc: 0.8392 - val_loss: 0.3758 - val_acc: 0.8323\n",
      "Epoch 201/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3566 - acc: 0.8381 - val_loss: 0.3549 - val_acc: 0.8402\n",
      "Epoch 202/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3560 - acc: 0.8391 - val_loss: 0.3554 - val_acc: 0.8383\n",
      "Epoch 203/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3559 - acc: 0.8387 - val_loss: 0.3541 - val_acc: 0.8411\n",
      "Epoch 204/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3558 - acc: 0.8393 - val_loss: 0.3557 - val_acc: 0.8392\n",
      "Epoch 205/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3560 - acc: 0.8383 - val_loss: 0.3540 - val_acc: 0.8407\n",
      "Epoch 206/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3556 - acc: 0.8390 - val_loss: 0.3568 - val_acc: 0.8411\n",
      "Epoch 207/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3553 - acc: 0.8381 - val_loss: 0.3502 - val_acc: 0.8431\n",
      "Epoch 208/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3551 - acc: 0.8391 - val_loss: 0.3550 - val_acc: 0.8415\n",
      "Epoch 209/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3551 - acc: 0.8396 - val_loss: 0.3541 - val_acc: 0.8402\n",
      "Epoch 210/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3557 - acc: 0.8391 - val_loss: 0.3513 - val_acc: 0.8429\n",
      "Epoch 211/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3554 - acc: 0.8393 - val_loss: 0.3566 - val_acc: 0.8385\n",
      "Epoch 212/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3553 - acc: 0.8397 - val_loss: 0.3518 - val_acc: 0.8425\n",
      "Epoch 213/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3550 - acc: 0.8393 - val_loss: 0.3535 - val_acc: 0.8418\n",
      "Epoch 214/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3544 - acc: 0.8396 - val_loss: 0.3560 - val_acc: 0.8410\n",
      "Epoch 215/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3543 - acc: 0.8393 - val_loss: 0.3614 - val_acc: 0.8385\n",
      "Epoch 216/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3540 - acc: 0.8390 - val_loss: 0.3549 - val_acc: 0.8418\n",
      "Epoch 217/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3547 - acc: 0.8382 - val_loss: 0.3515 - val_acc: 0.8415\n",
      "Epoch 218/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3552 - acc: 0.8388 - val_loss: 0.3543 - val_acc: 0.8404\n",
      "Epoch 219/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3538 - acc: 0.8412 - val_loss: 0.3530 - val_acc: 0.8419\n",
      "Epoch 220/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3544 - acc: 0.8394 - val_loss: 0.3518 - val_acc: 0.8422\n",
      "Epoch 221/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3536 - acc: 0.8399 - val_loss: 0.3568 - val_acc: 0.8400\n",
      "Epoch 222/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3546 - acc: 0.8383 - val_loss: 0.3577 - val_acc: 0.8395\n",
      "Epoch 223/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3550 - acc: 0.8402 - val_loss: 0.3540 - val_acc: 0.8420\n",
      "Epoch 224/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3554 - acc: 0.8396 - val_loss: 0.3569 - val_acc: 0.8399\n",
      "Epoch 225/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3545 - acc: 0.8404 - val_loss: 0.3508 - val_acc: 0.8429\n",
      "Epoch 226/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3553 - acc: 0.8388 - val_loss: 0.3513 - val_acc: 0.8419\n",
      "Epoch 227/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3552 - acc: 0.8396 - val_loss: 0.3517 - val_acc: 0.8413\n",
      "Epoch 228/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3544 - acc: 0.8385 - val_loss: 0.3535 - val_acc: 0.8423\n",
      "Epoch 229/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3547 - acc: 0.8393 - val_loss: 0.3513 - val_acc: 0.8434\n",
      "Epoch 230/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3542 - acc: 0.8389 - val_loss: 0.3528 - val_acc: 0.8416\n",
      "Epoch 231/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3545 - acc: 0.8399 - val_loss: 0.3522 - val_acc: 0.8410\n",
      "Epoch 232/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3540 - acc: 0.8410 - val_loss: 0.3502 - val_acc: 0.8429\n",
      "Epoch 233/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3541 - acc: 0.8402 - val_loss: 0.3516 - val_acc: 0.8440\n",
      "Epoch 234/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3546 - acc: 0.8393 - val_loss: 0.3504 - val_acc: 0.8421\n",
      "Epoch 235/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3541 - acc: 0.8408 - val_loss: 0.3540 - val_acc: 0.8405\n",
      "Epoch 236/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3539 - acc: 0.8397 - val_loss: 0.3533 - val_acc: 0.8421\n",
      "Epoch 237/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3535 - acc: 0.8396 - val_loss: 0.3519 - val_acc: 0.8424\n",
      "Epoch 238/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3537 - acc: 0.8398 - val_loss: 0.3545 - val_acc: 0.8395\n",
      "Epoch 239/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3542 - acc: 0.8403 - val_loss: 0.3580 - val_acc: 0.8388\n",
      "Epoch 240/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3543 - acc: 0.8387 - val_loss: 0.3518 - val_acc: 0.8428\n",
      "Epoch 241/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3542 - acc: 0.8393 - val_loss: 0.3503 - val_acc: 0.8440\n",
      "Epoch 242/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3538 - acc: 0.8401 - val_loss: 0.3555 - val_acc: 0.8405\n",
      "Epoch 243/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3537 - acc: 0.8396 - val_loss: 0.3538 - val_acc: 0.8413\n",
      "Epoch 244/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3531 - acc: 0.8410 - val_loss: 0.3579 - val_acc: 0.8392\n",
      "Epoch 245/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3543 - acc: 0.8395 - val_loss: 0.3532 - val_acc: 0.8421\n",
      "Epoch 246/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3540 - acc: 0.8394 - val_loss: 0.3565 - val_acc: 0.8413\n",
      "Epoch 247/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3538 - acc: 0.8396 - val_loss: 0.3523 - val_acc: 0.8415\n",
      "Epoch 248/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3537 - acc: 0.8398 - val_loss: 0.3522 - val_acc: 0.8395\n",
      "Epoch 249/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3531 - acc: 0.8397 - val_loss: 0.3512 - val_acc: 0.8417\n",
      "Epoch 250/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3532 - acc: 0.8406 - val_loss: 0.3568 - val_acc: 0.8374\n",
      "Epoch 251/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3538 - acc: 0.8401 - val_loss: 0.3553 - val_acc: 0.8379\n",
      "Epoch 252/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3543 - acc: 0.8400 - val_loss: 0.3516 - val_acc: 0.8414\n",
      "Epoch 253/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3542 - acc: 0.8392 - val_loss: 0.3505 - val_acc: 0.8425\n",
      "Epoch 254/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3535 - acc: 0.8410 - val_loss: 0.3539 - val_acc: 0.8393\n",
      "Epoch 255/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3538 - acc: 0.8394 - val_loss: 0.3538 - val_acc: 0.8402\n",
      "Epoch 256/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3532 - acc: 0.8406 - val_loss: 0.3580 - val_acc: 0.8397\n",
      "Epoch 257/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3534 - acc: 0.8399 - val_loss: 0.3526 - val_acc: 0.8408\n",
      "Epoch 258/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3537 - acc: 0.8401 - val_loss: 0.3505 - val_acc: 0.8400\n",
      "Epoch 259/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3535 - acc: 0.8400 - val_loss: 0.3571 - val_acc: 0.8363\n",
      "Epoch 260/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3542 - acc: 0.8390 - val_loss: 0.3531 - val_acc: 0.8421\n",
      "Epoch 261/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3539 - acc: 0.8386 - val_loss: 0.3515 - val_acc: 0.8398\n",
      "Epoch 262/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3540 - acc: 0.8402 - val_loss: 0.3527 - val_acc: 0.8425\n",
      "Epoch 263/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3532 - acc: 0.8397 - val_loss: 0.3690 - val_acc: 0.8333\n",
      "Epoch 264/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3526 - acc: 0.8415 - val_loss: 0.3504 - val_acc: 0.8423\n",
      "Epoch 265/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3531 - acc: 0.8406 - val_loss: 0.3520 - val_acc: 0.8420\n",
      "Epoch 266/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3536 - acc: 0.8397 - val_loss: 0.3512 - val_acc: 0.8437\n",
      "Epoch 267/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3537 - acc: 0.8402 - val_loss: 0.3515 - val_acc: 0.8418\n",
      "Epoch 268/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3534 - acc: 0.8412 - val_loss: 0.3523 - val_acc: 0.8428\n",
      "Epoch 269/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3541 - acc: 0.8398 - val_loss: 0.3533 - val_acc: 0.8419\n",
      "Epoch 270/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3533 - acc: 0.8406 - val_loss: 0.3569 - val_acc: 0.8397\n",
      "Epoch 271/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3540 - acc: 0.8396 - val_loss: 0.3524 - val_acc: 0.8439\n",
      "Epoch 272/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3540 - acc: 0.8404 - val_loss: 0.3516 - val_acc: 0.8437\n",
      "Epoch 273/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3529 - acc: 0.8410 - val_loss: 0.3527 - val_acc: 0.8419\n",
      "Epoch 274/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3529 - acc: 0.8397 - val_loss: 0.3540 - val_acc: 0.8414\n",
      "Epoch 275/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3524 - acc: 0.8396 - val_loss: 0.3507 - val_acc: 0.8445\n",
      "Epoch 276/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3525 - acc: 0.8407 - val_loss: 0.3510 - val_acc: 0.8441\n",
      "Epoch 277/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3523 - acc: 0.8409 - val_loss: 0.3499 - val_acc: 0.8418\n",
      "Epoch 278/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3526 - acc: 0.8415 - val_loss: 0.3518 - val_acc: 0.8421\n",
      "Epoch 279/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3521 - acc: 0.8403 - val_loss: 0.3533 - val_acc: 0.8423\n",
      "Epoch 280/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3522 - acc: 0.8421 - val_loss: 0.3517 - val_acc: 0.8427\n",
      "Epoch 281/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3521 - acc: 0.8407 - val_loss: 0.3523 - val_acc: 0.8426\n",
      "Epoch 282/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3518 - acc: 0.8417 - val_loss: 0.3497 - val_acc: 0.8440\n",
      "Epoch 283/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3516 - acc: 0.8413 - val_loss: 0.3536 - val_acc: 0.8389\n",
      "Epoch 284/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3519 - acc: 0.8418 - val_loss: 0.3520 - val_acc: 0.8427\n",
      "Epoch 285/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3516 - acc: 0.8421 - val_loss: 0.3503 - val_acc: 0.8426\n",
      "Epoch 286/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3514 - acc: 0.8404 - val_loss: 0.3578 - val_acc: 0.8364\n",
      "Epoch 287/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3517 - acc: 0.8405 - val_loss: 0.3482 - val_acc: 0.8456\n",
      "Epoch 288/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3512 - acc: 0.8417 - val_loss: 0.3483 - val_acc: 0.8443\n",
      "Epoch 289/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3524 - acc: 0.8400 - val_loss: 0.3520 - val_acc: 0.8419\n",
      "Epoch 290/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3520 - acc: 0.8405 - val_loss: 0.3530 - val_acc: 0.8417\n",
      "Epoch 291/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3512 - acc: 0.8422 - val_loss: 0.3528 - val_acc: 0.8415\n",
      "Epoch 292/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3517 - acc: 0.8415 - val_loss: 0.3522 - val_acc: 0.8428\n",
      "Epoch 293/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3517 - acc: 0.8403 - val_loss: 0.3593 - val_acc: 0.8371\n",
      "Epoch 294/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3519 - acc: 0.8412 - val_loss: 0.3516 - val_acc: 0.8425\n",
      "Epoch 295/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3514 - acc: 0.8410 - val_loss: 0.3511 - val_acc: 0.8428\n",
      "Epoch 296/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3513 - acc: 0.8416 - val_loss: 0.3541 - val_acc: 0.8398\n",
      "Epoch 297/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3515 - acc: 0.8408 - val_loss: 0.3555 - val_acc: 0.8416\n",
      "Epoch 298/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3511 - acc: 0.8408 - val_loss: 0.3524 - val_acc: 0.8427\n",
      "Epoch 299/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3517 - acc: 0.8408 - val_loss: 0.3529 - val_acc: 0.8428\n",
      "Epoch 300/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3504 - acc: 0.8425 - val_loss: 0.3526 - val_acc: 0.8423\n",
      "Epoch 301/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3509 - acc: 0.8423 - val_loss: 0.3501 - val_acc: 0.8437\n",
      "Epoch 302/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3514 - acc: 0.8415 - val_loss: 0.3558 - val_acc: 0.8411\n",
      "Epoch 303/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3510 - acc: 0.8414 - val_loss: 0.3529 - val_acc: 0.8409\n",
      "Epoch 304/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3508 - acc: 0.8414 - val_loss: 0.3504 - val_acc: 0.8429\n",
      "Epoch 305/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3514 - acc: 0.8420 - val_loss: 0.3505 - val_acc: 0.8443\n",
      "Epoch 306/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3505 - acc: 0.8418 - val_loss: 0.3521 - val_acc: 0.8428\n",
      "Epoch 307/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3517 - acc: 0.8409 - val_loss: 0.3522 - val_acc: 0.8429\n",
      "Epoch 308/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3518 - acc: 0.8401 - val_loss: 0.3570 - val_acc: 0.8418\n",
      "Epoch 309/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3510 - acc: 0.8415 - val_loss: 0.3646 - val_acc: 0.8318\n",
      "Epoch 310/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3509 - acc: 0.8423 - val_loss: 0.3522 - val_acc: 0.8437\n",
      "Epoch 311/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3505 - acc: 0.8422 - val_loss: 0.3515 - val_acc: 0.8437\n",
      "Epoch 312/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3507 - acc: 0.8408 - val_loss: 0.3617 - val_acc: 0.8368\n",
      "Epoch 313/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3508 - acc: 0.8415 - val_loss: 0.3508 - val_acc: 0.8440\n",
      "Epoch 314/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3509 - acc: 0.8421 - val_loss: 0.3570 - val_acc: 0.8385\n",
      "Epoch 315/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3506 - acc: 0.8418 - val_loss: 0.3515 - val_acc: 0.8442\n",
      "Epoch 316/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3507 - acc: 0.8418 - val_loss: 0.3543 - val_acc: 0.8415\n",
      "Epoch 317/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3506 - acc: 0.8420 - val_loss: 0.3496 - val_acc: 0.8443\n",
      "Epoch 318/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3507 - acc: 0.8416 - val_loss: 0.3547 - val_acc: 0.8381\n",
      "Epoch 319/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3509 - acc: 0.8420 - val_loss: 0.3490 - val_acc: 0.8436\n",
      "Epoch 320/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3500 - acc: 0.8421 - val_loss: 0.3530 - val_acc: 0.8425\n",
      "Epoch 321/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3504 - acc: 0.8426 - val_loss: 0.3492 - val_acc: 0.8440\n",
      "Epoch 322/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3501 - acc: 0.8416 - val_loss: 0.3491 - val_acc: 0.8456\n",
      "Epoch 323/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3508 - acc: 0.8415 - val_loss: 0.3522 - val_acc: 0.8445\n",
      "Epoch 324/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3503 - acc: 0.8425 - val_loss: 0.3504 - val_acc: 0.8437\n",
      "Epoch 325/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3510 - acc: 0.8420 - val_loss: 0.3500 - val_acc: 0.8451\n",
      "Epoch 326/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3513 - acc: 0.8414 - val_loss: 0.3481 - val_acc: 0.8433\n",
      "Epoch 327/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3503 - acc: 0.8415 - val_loss: 0.3510 - val_acc: 0.8428\n",
      "Epoch 328/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3507 - acc: 0.8418 - val_loss: 0.3490 - val_acc: 0.8449\n",
      "Epoch 329/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3503 - acc: 0.8416 - val_loss: 0.3518 - val_acc: 0.8415\n",
      "Epoch 330/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3514 - acc: 0.8409 - val_loss: 0.3521 - val_acc: 0.8427\n",
      "Epoch 331/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3500 - acc: 0.8427 - val_loss: 0.3495 - val_acc: 0.8444\n",
      "Epoch 332/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3506 - acc: 0.8433 - val_loss: 0.3556 - val_acc: 0.8403\n",
      "Epoch 333/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3501 - acc: 0.8417 - val_loss: 0.3518 - val_acc: 0.8398\n",
      "Epoch 334/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3499 - acc: 0.8412 - val_loss: 0.3529 - val_acc: 0.8417\n",
      "Epoch 335/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3500 - acc: 0.8422 - val_loss: 0.3491 - val_acc: 0.8437\n",
      "Epoch 336/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3498 - acc: 0.8427 - val_loss: 0.3508 - val_acc: 0.8425\n",
      "Epoch 337/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3498 - acc: 0.8423 - val_loss: 0.3494 - val_acc: 0.8438\n",
      "Epoch 338/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3502 - acc: 0.8426 - val_loss: 0.3597 - val_acc: 0.8409\n",
      "Epoch 339/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3501 - acc: 0.8424 - val_loss: 0.3501 - val_acc: 0.8432\n",
      "Epoch 340/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3503 - acc: 0.8403 - val_loss: 0.3510 - val_acc: 0.8431\n",
      "Epoch 341/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3500 - acc: 0.8429 - val_loss: 0.3491 - val_acc: 0.8444\n",
      "Epoch 342/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3498 - acc: 0.8423 - val_loss: 0.3593 - val_acc: 0.8396\n",
      "Epoch 343/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3506 - acc: 0.8423 - val_loss: 0.3506 - val_acc: 0.8447\n",
      "Epoch 344/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3492 - acc: 0.8440 - val_loss: 0.3503 - val_acc: 0.8441\n",
      "Epoch 345/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3502 - acc: 0.8419 - val_loss: 0.3512 - val_acc: 0.8436\n",
      "Epoch 346/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3505 - acc: 0.8429 - val_loss: 0.3542 - val_acc: 0.8413\n",
      "Epoch 347/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3502 - acc: 0.8422 - val_loss: 0.3471 - val_acc: 0.8459\n",
      "Epoch 348/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3494 - acc: 0.8424 - val_loss: 0.3490 - val_acc: 0.8429\n",
      "Epoch 349/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3501 - acc: 0.8424 - val_loss: 0.3541 - val_acc: 0.8411\n",
      "Epoch 350/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3500 - acc: 0.8413 - val_loss: 0.3490 - val_acc: 0.8450\n",
      "Epoch 351/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3504 - acc: 0.8414 - val_loss: 0.3511 - val_acc: 0.8421\n",
      "Epoch 352/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3499 - acc: 0.8427 - val_loss: 0.3536 - val_acc: 0.8420\n",
      "Epoch 353/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3497 - acc: 0.8418 - val_loss: 0.3509 - val_acc: 0.8444\n",
      "Epoch 354/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3504 - acc: 0.8432 - val_loss: 0.3539 - val_acc: 0.8413\n",
      "Epoch 355/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3496 - acc: 0.8411 - val_loss: 0.3539 - val_acc: 0.8417\n",
      "Epoch 356/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3490 - acc: 0.8424 - val_loss: 0.3498 - val_acc: 0.8431\n",
      "Epoch 357/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3502 - acc: 0.8433 - val_loss: 0.3519 - val_acc: 0.8411\n",
      "Epoch 358/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3500 - acc: 0.8425 - val_loss: 0.3499 - val_acc: 0.8425\n",
      "Epoch 359/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3493 - acc: 0.8429 - val_loss: 0.3493 - val_acc: 0.8424\n",
      "Epoch 360/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3490 - acc: 0.8430 - val_loss: 0.3529 - val_acc: 0.8417\n",
      "Epoch 361/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3491 - acc: 0.8421 - val_loss: 0.3488 - val_acc: 0.8435\n",
      "Epoch 362/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3497 - acc: 0.8429 - val_loss: 0.3482 - val_acc: 0.8459\n",
      "Epoch 363/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3495 - acc: 0.8436 - val_loss: 0.3479 - val_acc: 0.8448\n",
      "Epoch 364/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3495 - acc: 0.8440 - val_loss: 0.3511 - val_acc: 0.8421\n",
      "Epoch 365/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3496 - acc: 0.8438 - val_loss: 0.3495 - val_acc: 0.8444\n",
      "Epoch 366/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3499 - acc: 0.8423 - val_loss: 0.3479 - val_acc: 0.8443\n",
      "Epoch 367/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3495 - acc: 0.8422 - val_loss: 0.3486 - val_acc: 0.8455\n",
      "Epoch 368/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3503 - acc: 0.8420 - val_loss: 0.3487 - val_acc: 0.8455\n",
      "Epoch 369/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3494 - acc: 0.8437 - val_loss: 0.3511 - val_acc: 0.8413\n",
      "Epoch 370/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3491 - acc: 0.8419 - val_loss: 0.3509 - val_acc: 0.8440\n",
      "Epoch 371/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3492 - acc: 0.8431 - val_loss: 0.3628 - val_acc: 0.8356\n",
      "Epoch 372/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3500 - acc: 0.8421 - val_loss: 0.3513 - val_acc: 0.8431\n",
      "Epoch 373/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3491 - acc: 0.8432 - val_loss: 0.3552 - val_acc: 0.8385\n",
      "Epoch 374/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3494 - acc: 0.8422 - val_loss: 0.3493 - val_acc: 0.8433\n",
      "Epoch 375/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3495 - acc: 0.8429 - val_loss: 0.3526 - val_acc: 0.8412\n",
      "Epoch 376/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3492 - acc: 0.8432 - val_loss: 0.3499 - val_acc: 0.8446\n",
      "Epoch 377/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3489 - acc: 0.8440 - val_loss: 0.3526 - val_acc: 0.8387\n",
      "Epoch 378/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3500 - acc: 0.8429 - val_loss: 0.3509 - val_acc: 0.8410\n",
      "Epoch 379/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3495 - acc: 0.8433 - val_loss: 0.3493 - val_acc: 0.8441\n",
      "Epoch 380/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3487 - acc: 0.8433 - val_loss: 0.3526 - val_acc: 0.8399\n",
      "Epoch 381/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3490 - acc: 0.8431 - val_loss: 0.3485 - val_acc: 0.8455\n",
      "Epoch 382/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3504 - acc: 0.8412 - val_loss: 0.3546 - val_acc: 0.8399\n",
      "Epoch 383/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3489 - acc: 0.8427 - val_loss: 0.3484 - val_acc: 0.8455\n",
      "Epoch 384/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3497 - acc: 0.8433 - val_loss: 0.3569 - val_acc: 0.8410\n",
      "Epoch 385/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3494 - acc: 0.8427 - val_loss: 0.3497 - val_acc: 0.8431\n",
      "Epoch 386/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3493 - acc: 0.8426 - val_loss: 0.3494 - val_acc: 0.8427\n",
      "Epoch 387/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3488 - acc: 0.8433 - val_loss: 0.3480 - val_acc: 0.8436\n",
      "Epoch 388/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3489 - acc: 0.8433 - val_loss: 0.3495 - val_acc: 0.8439\n",
      "Epoch 389/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3488 - acc: 0.8431 - val_loss: 0.3481 - val_acc: 0.8439\n",
      "Epoch 390/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3488 - acc: 0.8423 - val_loss: 0.3518 - val_acc: 0.8439\n",
      "Epoch 391/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3487 - acc: 0.8432 - val_loss: 0.3518 - val_acc: 0.8422\n",
      "Epoch 392/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3487 - acc: 0.8437 - val_loss: 0.3489 - val_acc: 0.8440\n",
      "Epoch 393/2000\n",
      "41408/41408 [==============================] - 1s 21us/step - loss: 0.3494 - acc: 0.8420 - val_loss: 0.3522 - val_acc: 0.8413\n",
      "Epoch 394/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3486 - acc: 0.8435 - val_loss: 0.3496 - val_acc: 0.8431\n",
      "Epoch 395/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3488 - acc: 0.8435 - val_loss: 0.3488 - val_acc: 0.8443\n",
      "Epoch 396/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3490 - acc: 0.8435 - val_loss: 0.3532 - val_acc: 0.8413\n",
      "Epoch 397/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3498 - acc: 0.8433 - val_loss: 0.3516 - val_acc: 0.8416\n",
      "Epoch 398/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3497 - acc: 0.8422 - val_loss: 0.3485 - val_acc: 0.8443\n",
      "Epoch 399/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3497 - acc: 0.8430 - val_loss: 0.3525 - val_acc: 0.8426\n",
      "Epoch 400/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3487 - acc: 0.8431 - val_loss: 0.3497 - val_acc: 0.8413\n",
      "Epoch 401/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3482 - acc: 0.8431 - val_loss: 0.3496 - val_acc: 0.8426\n",
      "Epoch 402/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3486 - acc: 0.8428 - val_loss: 0.3479 - val_acc: 0.8452\n",
      "Epoch 403/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3490 - acc: 0.8421 - val_loss: 0.3530 - val_acc: 0.8403\n",
      "Epoch 404/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3489 - acc: 0.8418 - val_loss: 0.3495 - val_acc: 0.8437\n",
      "Epoch 405/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3489 - acc: 0.8444 - val_loss: 0.3494 - val_acc: 0.8451\n",
      "Epoch 406/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3489 - acc: 0.8423 - val_loss: 0.3545 - val_acc: 0.8420\n",
      "Epoch 407/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3482 - acc: 0.8429 - val_loss: 0.3493 - val_acc: 0.8443\n",
      "Epoch 408/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3488 - acc: 0.8429 - val_loss: 0.3520 - val_acc: 0.8430\n",
      "Epoch 409/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3480 - acc: 0.8447 - val_loss: 0.3506 - val_acc: 0.8435\n",
      "Epoch 410/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3489 - acc: 0.8432 - val_loss: 0.3490 - val_acc: 0.8441\n",
      "Epoch 411/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3488 - acc: 0.8437 - val_loss: 0.3475 - val_acc: 0.8457\n",
      "Epoch 412/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3488 - acc: 0.8429 - val_loss: 0.3483 - val_acc: 0.8448\n",
      "Epoch 413/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3486 - acc: 0.8448 - val_loss: 0.3518 - val_acc: 0.8415\n",
      "Epoch 414/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3486 - acc: 0.8429 - val_loss: 0.3531 - val_acc: 0.8423\n",
      "Epoch 415/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3490 - acc: 0.8418 - val_loss: 0.3585 - val_acc: 0.8361\n",
      "Epoch 416/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3490 - acc: 0.8428 - val_loss: 0.3504 - val_acc: 0.8432\n",
      "Epoch 417/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3493 - acc: 0.8439 - val_loss: 0.3572 - val_acc: 0.8403\n",
      "Epoch 418/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3486 - acc: 0.8421 - val_loss: 0.3509 - val_acc: 0.8448\n",
      "Epoch 419/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3491 - acc: 0.8437 - val_loss: 0.3539 - val_acc: 0.8416\n",
      "Epoch 420/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3483 - acc: 0.8423 - val_loss: 0.3488 - val_acc: 0.8449\n",
      "Epoch 421/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3488 - acc: 0.8428 - val_loss: 0.3522 - val_acc: 0.8427\n",
      "Epoch 422/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3486 - acc: 0.8441 - val_loss: 0.3526 - val_acc: 0.8426\n",
      "Epoch 423/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3486 - acc: 0.8440 - val_loss: 0.3511 - val_acc: 0.8422\n",
      "Epoch 424/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3484 - acc: 0.8439 - val_loss: 0.3522 - val_acc: 0.8431\n",
      "Epoch 425/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3493 - acc: 0.8428 - val_loss: 0.3507 - val_acc: 0.8440\n",
      "Epoch 426/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3487 - acc: 0.8429 - val_loss: 0.3508 - val_acc: 0.8430\n",
      "Epoch 427/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3484 - acc: 0.8438 - val_loss: 0.3525 - val_acc: 0.8407\n",
      "Epoch 428/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3482 - acc: 0.8443 - val_loss: 0.3512 - val_acc: 0.8436\n",
      "Epoch 429/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3483 - acc: 0.8431 - val_loss: 0.3602 - val_acc: 0.8385\n",
      "Epoch 430/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3487 - acc: 0.8427 - val_loss: 0.3496 - val_acc: 0.8430\n",
      "Epoch 431/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3488 - acc: 0.8414 - val_loss: 0.3522 - val_acc: 0.8431\n",
      "Epoch 432/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3485 - acc: 0.8426 - val_loss: 0.3483 - val_acc: 0.8448\n",
      "Epoch 433/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3485 - acc: 0.8432 - val_loss: 0.3510 - val_acc: 0.8431\n",
      "Epoch 434/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3487 - acc: 0.8440 - val_loss: 0.3524 - val_acc: 0.8400\n",
      "Epoch 435/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3480 - acc: 0.8435 - val_loss: 0.3504 - val_acc: 0.8418\n",
      "Epoch 436/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3489 - acc: 0.8420 - val_loss: 0.3492 - val_acc: 0.8432\n",
      "Epoch 437/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3485 - acc: 0.8427 - val_loss: 0.3529 - val_acc: 0.8411\n",
      "Epoch 438/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3491 - acc: 0.8437 - val_loss: 0.3566 - val_acc: 0.8416\n",
      "Epoch 439/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3483 - acc: 0.8441 - val_loss: 0.3478 - val_acc: 0.8453\n",
      "Epoch 440/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3492 - acc: 0.8438 - val_loss: 0.3497 - val_acc: 0.8420\n",
      "Epoch 441/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3486 - acc: 0.8426 - val_loss: 0.3509 - val_acc: 0.8424\n",
      "Epoch 442/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3483 - acc: 0.8429 - val_loss: 0.3533 - val_acc: 0.8410\n",
      "Epoch 443/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3485 - acc: 0.8434 - val_loss: 0.3524 - val_acc: 0.8414\n",
      "Epoch 444/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3485 - acc: 0.8436 - val_loss: 0.3519 - val_acc: 0.8410\n",
      "Epoch 445/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3490 - acc: 0.8429 - val_loss: 0.3504 - val_acc: 0.8447\n",
      "Epoch 446/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3484 - acc: 0.8440 - val_loss: 0.3493 - val_acc: 0.8432\n",
      "Epoch 447/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8445 - val_loss: 0.3490 - val_acc: 0.8435\n",
      "Epoch 448/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3487 - acc: 0.8436 - val_loss: 0.3508 - val_acc: 0.8422\n",
      "Epoch 449/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3480 - acc: 0.8437 - val_loss: 0.3499 - val_acc: 0.8438\n",
      "Epoch 450/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3484 - acc: 0.8435 - val_loss: 0.3488 - val_acc: 0.8447\n",
      "Epoch 451/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3482 - acc: 0.8438 - val_loss: 0.3511 - val_acc: 0.8424\n",
      "Epoch 452/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3486 - acc: 0.8435 - val_loss: 0.3519 - val_acc: 0.8424\n",
      "Epoch 453/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3483 - acc: 0.8426 - val_loss: 0.3515 - val_acc: 0.8435\n",
      "Epoch 454/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3478 - acc: 0.8440 - val_loss: 0.3548 - val_acc: 0.8421\n",
      "Epoch 455/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3486 - acc: 0.8427 - val_loss: 0.3502 - val_acc: 0.8440\n",
      "Epoch 456/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3480 - acc: 0.8423 - val_loss: 0.3527 - val_acc: 0.8437\n",
      "Epoch 457/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3484 - acc: 0.8444 - val_loss: 0.3526 - val_acc: 0.8436\n",
      "Epoch 458/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3477 - acc: 0.8435 - val_loss: 0.3515 - val_acc: 0.8438\n",
      "Epoch 459/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3483 - acc: 0.8433 - val_loss: 0.3478 - val_acc: 0.8450\n",
      "Epoch 460/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3475 - acc: 0.8445 - val_loss: 0.3562 - val_acc: 0.8403\n",
      "Epoch 461/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3481 - acc: 0.8439 - val_loss: 0.3518 - val_acc: 0.8433\n",
      "Epoch 462/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3484 - acc: 0.8438 - val_loss: 0.3475 - val_acc: 0.8460\n",
      "Epoch 463/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3481 - acc: 0.8426 - val_loss: 0.3485 - val_acc: 0.8444\n",
      "Epoch 464/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3483 - acc: 0.8432 - val_loss: 0.3486 - val_acc: 0.8439\n",
      "Epoch 465/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3478 - acc: 0.8434 - val_loss: 0.3670 - val_acc: 0.8347\n",
      "Epoch 466/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3482 - acc: 0.8439 - val_loss: 0.3502 - val_acc: 0.8427\n",
      "Epoch 467/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3479 - acc: 0.8428 - val_loss: 0.3518 - val_acc: 0.8416\n",
      "Epoch 468/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3481 - acc: 0.8434 - val_loss: 0.3496 - val_acc: 0.8435\n",
      "Epoch 469/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8436 - val_loss: 0.3473 - val_acc: 0.8432\n",
      "Epoch 470/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3479 - acc: 0.8448 - val_loss: 0.3513 - val_acc: 0.8425\n",
      "Epoch 471/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3476 - acc: 0.8428 - val_loss: 0.3504 - val_acc: 0.8419\n",
      "Epoch 472/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3480 - acc: 0.8446 - val_loss: 0.3489 - val_acc: 0.8441\n",
      "Epoch 473/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8441 - val_loss: 0.3491 - val_acc: 0.8445\n",
      "Epoch 474/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3482 - acc: 0.8441 - val_loss: 0.3504 - val_acc: 0.8418\n",
      "Epoch 475/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3481 - acc: 0.8440 - val_loss: 0.3527 - val_acc: 0.8398\n",
      "Epoch 476/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3478 - acc: 0.8432 - val_loss: 0.3484 - val_acc: 0.8445\n",
      "Epoch 477/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3480 - acc: 0.8429 - val_loss: 0.3513 - val_acc: 0.8418\n",
      "Epoch 478/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3478 - acc: 0.8436 - val_loss: 0.3501 - val_acc: 0.8438\n",
      "Epoch 479/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3486 - acc: 0.8426 - val_loss: 0.3544 - val_acc: 0.8406\n",
      "Epoch 480/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3487 - acc: 0.8429 - val_loss: 0.3484 - val_acc: 0.8436\n",
      "Epoch 481/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3482 - acc: 0.8426 - val_loss: 0.3560 - val_acc: 0.8396\n",
      "Epoch 482/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3480 - acc: 0.8430 - val_loss: 0.3509 - val_acc: 0.8428\n",
      "Epoch 483/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3483 - acc: 0.8432 - val_loss: 0.3490 - val_acc: 0.8417\n",
      "Epoch 484/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3485 - acc: 0.8428 - val_loss: 0.3492 - val_acc: 0.8438\n",
      "Epoch 485/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3483 - acc: 0.8437 - val_loss: 0.3485 - val_acc: 0.8453\n",
      "Epoch 486/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3480 - acc: 0.8441 - val_loss: 0.3482 - val_acc: 0.8458\n",
      "Epoch 487/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3474 - acc: 0.8441 - val_loss: 0.3530 - val_acc: 0.8409\n",
      "Epoch 488/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3480 - acc: 0.8436 - val_loss: 0.3520 - val_acc: 0.8421\n",
      "Epoch 489/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8440 - val_loss: 0.3520 - val_acc: 0.8431\n",
      "Epoch 490/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3479 - acc: 0.8432 - val_loss: 0.3510 - val_acc: 0.8445\n",
      "Epoch 491/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8433 - val_loss: 0.3497 - val_acc: 0.8440\n",
      "Epoch 492/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8445 - val_loss: 0.3512 - val_acc: 0.8429\n",
      "Epoch 493/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3474 - acc: 0.8436 - val_loss: 0.3485 - val_acc: 0.8460\n",
      "Epoch 494/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3480 - acc: 0.8438 - val_loss: 0.3475 - val_acc: 0.8455\n",
      "Epoch 495/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3479 - acc: 0.8441 - val_loss: 0.3487 - val_acc: 0.8443\n",
      "Epoch 496/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8446 - val_loss: 0.3478 - val_acc: 0.8454\n",
      "Epoch 497/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3483 - acc: 0.8457 - val_loss: 0.3541 - val_acc: 0.8392\n",
      "Epoch 498/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3472 - acc: 0.8440 - val_loss: 0.3502 - val_acc: 0.8436\n",
      "Epoch 499/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3482 - acc: 0.8451 - val_loss: 0.3571 - val_acc: 0.8416\n",
      "Epoch 500/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3475 - acc: 0.8435 - val_loss: 0.3495 - val_acc: 0.8429\n",
      "Epoch 501/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3483 - acc: 0.8419 - val_loss: 0.3507 - val_acc: 0.8437\n",
      "Epoch 502/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3476 - acc: 0.8439 - val_loss: 0.3486 - val_acc: 0.8440\n",
      "Epoch 503/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3480 - acc: 0.8440 - val_loss: 0.3520 - val_acc: 0.8419\n",
      "Epoch 504/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3476 - acc: 0.8433 - val_loss: 0.3527 - val_acc: 0.8435\n",
      "Epoch 505/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8436 - val_loss: 0.3473 - val_acc: 0.8450\n",
      "Epoch 506/2000\n",
      "41408/41408 [==============================] - 1s 26us/step - loss: 0.3476 - acc: 0.8433 - val_loss: 0.3491 - val_acc: 0.8450\n",
      "Epoch 507/2000\n",
      "41408/41408 [==============================] - 1s 27us/step - loss: 0.3478 - acc: 0.8437 - val_loss: 0.3530 - val_acc: 0.8398\n",
      "Epoch 508/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3475 - acc: 0.8447 - val_loss: 0.3519 - val_acc: 0.8433\n",
      "Epoch 509/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3473 - acc: 0.8444 - val_loss: 0.3507 - val_acc: 0.8440\n",
      "Epoch 510/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3472 - acc: 0.8438 - val_loss: 0.3507 - val_acc: 0.8437\n",
      "Epoch 511/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3477 - acc: 0.8438 - val_loss: 0.3561 - val_acc: 0.8375\n",
      "Epoch 512/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3471 - acc: 0.8440 - val_loss: 0.3525 - val_acc: 0.8420\n",
      "Epoch 513/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3468 - acc: 0.8447 - val_loss: 0.3527 - val_acc: 0.8423\n",
      "Epoch 514/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3483 - acc: 0.8443 - val_loss: 0.3496 - val_acc: 0.8433\n",
      "Epoch 515/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8444 - val_loss: 0.3475 - val_acc: 0.8454\n",
      "Epoch 516/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3468 - acc: 0.8442 - val_loss: 0.3509 - val_acc: 0.8408\n",
      "Epoch 517/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3483 - acc: 0.8436 - val_loss: 0.3472 - val_acc: 0.8456\n",
      "Epoch 518/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3477 - acc: 0.8435 - val_loss: 0.3501 - val_acc: 0.8414\n",
      "Epoch 519/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3471 - acc: 0.8436 - val_loss: 0.3522 - val_acc: 0.8427\n",
      "Epoch 520/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3477 - acc: 0.8443 - val_loss: 0.3488 - val_acc: 0.8449\n",
      "Epoch 521/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3472 - acc: 0.8441 - val_loss: 0.3501 - val_acc: 0.8419\n",
      "Epoch 522/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3475 - acc: 0.8439 - val_loss: 0.3534 - val_acc: 0.8406\n",
      "Epoch 523/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3472 - acc: 0.8450 - val_loss: 0.3512 - val_acc: 0.8436\n",
      "Epoch 524/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3473 - acc: 0.8447 - val_loss: 0.3478 - val_acc: 0.8447\n",
      "Epoch 525/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3469 - acc: 0.8433 - val_loss: 0.3580 - val_acc: 0.8392\n",
      "Epoch 526/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3475 - acc: 0.8445 - val_loss: 0.3513 - val_acc: 0.8425\n",
      "Epoch 527/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3470 - acc: 0.8447 - val_loss: 0.3495 - val_acc: 0.8427\n",
      "Epoch 528/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3481 - acc: 0.8445 - val_loss: 0.3485 - val_acc: 0.8446\n",
      "Epoch 529/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3485 - acc: 0.8436 - val_loss: 0.3502 - val_acc: 0.8429\n",
      "Epoch 530/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3484 - acc: 0.8436 - val_loss: 0.3498 - val_acc: 0.8436\n",
      "Epoch 531/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3473 - acc: 0.8447 - val_loss: 0.3489 - val_acc: 0.8450\n",
      "Epoch 532/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3474 - acc: 0.8446 - val_loss: 0.3520 - val_acc: 0.8442\n",
      "Epoch 533/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3472 - acc: 0.8449 - val_loss: 0.3502 - val_acc: 0.8440\n",
      "Epoch 534/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3474 - acc: 0.8441 - val_loss: 0.3471 - val_acc: 0.8456\n",
      "Epoch 535/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3473 - acc: 0.8453 - val_loss: 0.3483 - val_acc: 0.8425\n",
      "Epoch 536/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3476 - acc: 0.8433 - val_loss: 0.3524 - val_acc: 0.8403\n",
      "Epoch 537/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3480 - acc: 0.8443 - val_loss: 0.3500 - val_acc: 0.8424\n",
      "Epoch 538/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3480 - acc: 0.8439 - val_loss: 0.3497 - val_acc: 0.8437\n",
      "Epoch 539/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3473 - acc: 0.8436 - val_loss: 0.3501 - val_acc: 0.8440\n",
      "Epoch 540/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8444 - val_loss: 0.3526 - val_acc: 0.8427\n",
      "Epoch 541/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3466 - acc: 0.8435 - val_loss: 0.3477 - val_acc: 0.8457\n",
      "Epoch 542/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3474 - acc: 0.8447 - val_loss: 0.3475 - val_acc: 0.8451\n",
      "Epoch 543/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3470 - acc: 0.8439 - val_loss: 0.3531 - val_acc: 0.8401\n",
      "Epoch 544/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3485 - acc: 0.8449 - val_loss: 0.3519 - val_acc: 0.8439\n",
      "Epoch 545/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3479 - acc: 0.8440 - val_loss: 0.3517 - val_acc: 0.8435\n",
      "Epoch 546/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3473 - acc: 0.8435 - val_loss: 0.3479 - val_acc: 0.8442\n",
      "Epoch 547/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3478 - acc: 0.8438 - val_loss: 0.3519 - val_acc: 0.8433\n",
      "Epoch 548/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3474 - acc: 0.8439 - val_loss: 0.3489 - val_acc: 0.8426\n",
      "Epoch 549/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3472 - acc: 0.8445 - val_loss: 0.3463 - val_acc: 0.8450\n",
      "Epoch 550/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3467 - acc: 0.8446 - val_loss: 0.3481 - val_acc: 0.8455\n",
      "Epoch 551/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3465 - acc: 0.8448 - val_loss: 0.3545 - val_acc: 0.8405\n",
      "Epoch 552/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3470 - acc: 0.8436 - val_loss: 0.3493 - val_acc: 0.8431\n",
      "Epoch 553/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3468 - acc: 0.8442 - val_loss: 0.3513 - val_acc: 0.8398\n",
      "Epoch 554/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3468 - acc: 0.8441 - val_loss: 0.3513 - val_acc: 0.8406\n",
      "Epoch 555/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3466 - acc: 0.8446 - val_loss: 0.3467 - val_acc: 0.8466\n",
      "Epoch 556/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3466 - acc: 0.8448 - val_loss: 0.3463 - val_acc: 0.8468\n",
      "Epoch 557/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3463 - acc: 0.8437 - val_loss: 0.3532 - val_acc: 0.8426\n",
      "Epoch 558/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3469 - acc: 0.8446 - val_loss: 0.3489 - val_acc: 0.8453\n",
      "Epoch 559/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3470 - acc: 0.8441 - val_loss: 0.3510 - val_acc: 0.8417\n",
      "Epoch 560/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3471 - acc: 0.8441 - val_loss: 0.3455 - val_acc: 0.8465\n",
      "Epoch 561/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3476 - acc: 0.8432 - val_loss: 0.3457 - val_acc: 0.8475\n",
      "Epoch 562/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3470 - acc: 0.8448 - val_loss: 0.3476 - val_acc: 0.8456\n",
      "Epoch 563/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3466 - acc: 0.8443 - val_loss: 0.3496 - val_acc: 0.8418\n",
      "Epoch 564/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3465 - acc: 0.8443 - val_loss: 0.3498 - val_acc: 0.8438\n",
      "Epoch 565/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3466 - acc: 0.8431 - val_loss: 0.3493 - val_acc: 0.8448\n",
      "Epoch 566/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3466 - acc: 0.8452 - val_loss: 0.3482 - val_acc: 0.8447\n",
      "Epoch 567/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3474 - acc: 0.8436 - val_loss: 0.3542 - val_acc: 0.8418\n",
      "Epoch 568/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3469 - acc: 0.8421 - val_loss: 0.3475 - val_acc: 0.8453\n",
      "Epoch 569/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3471 - acc: 0.8433 - val_loss: 0.3487 - val_acc: 0.8455\n",
      "Epoch 570/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3471 - acc: 0.8456 - val_loss: 0.3482 - val_acc: 0.8437\n",
      "Epoch 571/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3469 - acc: 0.8451 - val_loss: 0.3561 - val_acc: 0.8382\n",
      "Epoch 572/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3465 - acc: 0.8457 - val_loss: 0.3519 - val_acc: 0.8416\n",
      "Epoch 573/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3465 - acc: 0.8441 - val_loss: 0.3497 - val_acc: 0.8441\n",
      "Epoch 574/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3474 - acc: 0.8435 - val_loss: 0.3473 - val_acc: 0.8436\n",
      "Epoch 575/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3468 - acc: 0.8448 - val_loss: 0.3476 - val_acc: 0.8452\n",
      "Epoch 576/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3471 - acc: 0.8436 - val_loss: 0.3476 - val_acc: 0.8455\n",
      "Epoch 577/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3474 - acc: 0.8430 - val_loss: 0.3460 - val_acc: 0.8468\n",
      "Epoch 578/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3466 - acc: 0.8435 - val_loss: 0.3516 - val_acc: 0.8420\n",
      "Epoch 579/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3466 - acc: 0.8431 - val_loss: 0.3530 - val_acc: 0.8427\n",
      "Epoch 580/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3466 - acc: 0.8442 - val_loss: 0.3470 - val_acc: 0.8444\n",
      "Epoch 581/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3462 - acc: 0.8451 - val_loss: 0.3483 - val_acc: 0.8438\n",
      "Epoch 582/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3471 - acc: 0.8438 - val_loss: 0.3466 - val_acc: 0.8431\n",
      "Epoch 583/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3462 - acc: 0.8439 - val_loss: 0.3460 - val_acc: 0.8456\n",
      "Epoch 584/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3465 - acc: 0.8437 - val_loss: 0.3478 - val_acc: 0.8441\n",
      "Epoch 585/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3465 - acc: 0.8448 - val_loss: 0.3458 - val_acc: 0.8463\n",
      "Epoch 586/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3460 - acc: 0.8457 - val_loss: 0.3454 - val_acc: 0.8468\n",
      "Epoch 587/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3468 - acc: 0.8434 - val_loss: 0.3474 - val_acc: 0.8451\n",
      "Epoch 588/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3468 - acc: 0.8441 - val_loss: 0.3472 - val_acc: 0.8450\n",
      "Epoch 589/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3461 - acc: 0.8454 - val_loss: 0.3467 - val_acc: 0.8427\n",
      "Epoch 590/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3462 - acc: 0.8440 - val_loss: 0.3466 - val_acc: 0.8458\n",
      "Epoch 591/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3462 - acc: 0.8451 - val_loss: 0.3477 - val_acc: 0.8440\n",
      "Epoch 592/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3472 - acc: 0.8451 - val_loss: 0.3481 - val_acc: 0.8459\n",
      "Epoch 593/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3465 - acc: 0.8448 - val_loss: 0.3481 - val_acc: 0.8469\n",
      "Epoch 594/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3462 - acc: 0.8443 - val_loss: 0.3478 - val_acc: 0.8456\n",
      "Epoch 595/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3455 - acc: 0.8436 - val_loss: 0.3457 - val_acc: 0.8462\n",
      "Epoch 596/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8452 - val_loss: 0.3489 - val_acc: 0.8459\n",
      "Epoch 597/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3465 - acc: 0.8447 - val_loss: 0.3548 - val_acc: 0.8424\n",
      "Epoch 598/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3465 - acc: 0.8452 - val_loss: 0.3476 - val_acc: 0.8442\n",
      "Epoch 599/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3468 - acc: 0.8445 - val_loss: 0.3454 - val_acc: 0.8466\n",
      "Epoch 600/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3471 - acc: 0.8454 - val_loss: 0.3522 - val_acc: 0.8427\n",
      "Epoch 601/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3461 - acc: 0.8457 - val_loss: 0.3470 - val_acc: 0.8472\n",
      "Epoch 602/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3465 - acc: 0.8448 - val_loss: 0.3479 - val_acc: 0.8479\n",
      "Epoch 603/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3461 - acc: 0.8453 - val_loss: 0.3468 - val_acc: 0.8461\n",
      "Epoch 604/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3452 - acc: 0.8440 - val_loss: 0.3486 - val_acc: 0.8461\n",
      "Epoch 605/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3467 - acc: 0.8456 - val_loss: 0.3491 - val_acc: 0.8438\n",
      "Epoch 606/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8448 - val_loss: 0.3535 - val_acc: 0.8407\n",
      "Epoch 607/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3467 - acc: 0.8439 - val_loss: 0.3440 - val_acc: 0.8461\n",
      "Epoch 608/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3457 - acc: 0.8445 - val_loss: 0.3479 - val_acc: 0.8452\n",
      "Epoch 609/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3468 - acc: 0.8443 - val_loss: 0.3474 - val_acc: 0.8445\n",
      "Epoch 610/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3460 - acc: 0.8450 - val_loss: 0.3470 - val_acc: 0.8465\n",
      "Epoch 611/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3462 - acc: 0.8451 - val_loss: 0.3461 - val_acc: 0.8468\n",
      "Epoch 612/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3464 - acc: 0.8450 - val_loss: 0.3457 - val_acc: 0.8460\n",
      "Epoch 613/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3462 - acc: 0.8449 - val_loss: 0.3478 - val_acc: 0.8469\n",
      "Epoch 614/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3460 - acc: 0.8443 - val_loss: 0.3482 - val_acc: 0.8480\n",
      "Epoch 615/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8448 - val_loss: 0.3500 - val_acc: 0.8419\n",
      "Epoch 616/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3460 - acc: 0.8445 - val_loss: 0.3477 - val_acc: 0.8457\n",
      "Epoch 617/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3459 - acc: 0.8443 - val_loss: 0.3456 - val_acc: 0.8464\n",
      "Epoch 618/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8455 - val_loss: 0.3469 - val_acc: 0.8435\n",
      "Epoch 619/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8450 - val_loss: 0.3494 - val_acc: 0.8429\n",
      "Epoch 620/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3457 - acc: 0.8448 - val_loss: 0.3461 - val_acc: 0.8471\n",
      "Epoch 621/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3454 - acc: 0.8438 - val_loss: 0.3492 - val_acc: 0.8432\n",
      "Epoch 622/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8446 - val_loss: 0.3501 - val_acc: 0.8437\n",
      "Epoch 623/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3459 - acc: 0.8455 - val_loss: 0.3478 - val_acc: 0.8458\n",
      "Epoch 624/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3455 - acc: 0.8450 - val_loss: 0.3480 - val_acc: 0.8438\n",
      "Epoch 625/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8452 - val_loss: 0.3467 - val_acc: 0.8448\n",
      "Epoch 626/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3457 - acc: 0.8440 - val_loss: 0.3474 - val_acc: 0.8468\n",
      "Epoch 627/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3463 - acc: 0.8449 - val_loss: 0.3463 - val_acc: 0.8461\n",
      "Epoch 628/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8454 - val_loss: 0.3483 - val_acc: 0.8450\n",
      "Epoch 629/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3465 - acc: 0.8449 - val_loss: 0.3519 - val_acc: 0.8403\n",
      "Epoch 630/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3460 - acc: 0.8440 - val_loss: 0.3477 - val_acc: 0.8467\n",
      "Epoch 631/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3453 - acc: 0.8447 - val_loss: 0.3528 - val_acc: 0.8437\n",
      "Epoch 632/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3454 - acc: 0.8458 - val_loss: 0.3485 - val_acc: 0.8463\n",
      "Epoch 633/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3451 - acc: 0.8447 - val_loss: 0.3464 - val_acc: 0.8441\n",
      "Epoch 634/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3460 - acc: 0.8448 - val_loss: 0.3483 - val_acc: 0.8453\n",
      "Epoch 635/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3455 - acc: 0.8440 - val_loss: 0.3481 - val_acc: 0.8470\n",
      "Epoch 636/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3456 - acc: 0.8442 - val_loss: 0.3461 - val_acc: 0.8474\n",
      "Epoch 637/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3457 - acc: 0.8447 - val_loss: 0.3478 - val_acc: 0.8436\n",
      "Epoch 638/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8448 - val_loss: 0.3461 - val_acc: 0.8464\n",
      "Epoch 639/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3460 - acc: 0.8446 - val_loss: 0.3592 - val_acc: 0.8376\n",
      "Epoch 640/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3460 - acc: 0.8450 - val_loss: 0.3490 - val_acc: 0.8452\n",
      "Epoch 641/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3452 - acc: 0.8448 - val_loss: 0.3516 - val_acc: 0.8414\n",
      "Epoch 642/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3455 - acc: 0.8429 - val_loss: 0.3442 - val_acc: 0.8474\n",
      "Epoch 643/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3454 - acc: 0.8441 - val_loss: 0.3468 - val_acc: 0.8459\n",
      "Epoch 644/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3454 - acc: 0.8444 - val_loss: 0.3473 - val_acc: 0.8453\n",
      "Epoch 645/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3453 - acc: 0.8444 - val_loss: 0.3476 - val_acc: 0.8456\n",
      "Epoch 646/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3455 - acc: 0.8448 - val_loss: 0.3458 - val_acc: 0.8471\n",
      "Epoch 647/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3464 - acc: 0.8440 - val_loss: 0.3506 - val_acc: 0.8436\n",
      "Epoch 648/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3458 - acc: 0.8432 - val_loss: 0.3480 - val_acc: 0.8461\n",
      "Epoch 649/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3452 - acc: 0.8446 - val_loss: 0.3480 - val_acc: 0.8466\n",
      "Epoch 650/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3451 - acc: 0.8446 - val_loss: 0.3462 - val_acc: 0.8467\n",
      "Epoch 651/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3456 - acc: 0.8446 - val_loss: 0.3501 - val_acc: 0.8424\n",
      "Epoch 652/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3452 - acc: 0.8451 - val_loss: 0.3504 - val_acc: 0.8396\n",
      "Epoch 653/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3451 - acc: 0.8455 - val_loss: 0.3464 - val_acc: 0.8440\n",
      "Epoch 654/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3460 - acc: 0.8439 - val_loss: 0.3525 - val_acc: 0.8421\n",
      "Epoch 655/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3453 - acc: 0.8462 - val_loss: 0.3501 - val_acc: 0.8421\n",
      "Epoch 656/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3449 - acc: 0.8457 - val_loss: 0.3468 - val_acc: 0.8455\n",
      "Epoch 657/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3456 - acc: 0.8444 - val_loss: 0.3481 - val_acc: 0.8437\n",
      "Epoch 658/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3453 - acc: 0.8443 - val_loss: 0.3496 - val_acc: 0.8456\n",
      "Epoch 659/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8453 - val_loss: 0.3493 - val_acc: 0.8427\n",
      "Epoch 660/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3463 - acc: 0.8445 - val_loss: 0.3487 - val_acc: 0.8426\n",
      "Epoch 661/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3449 - acc: 0.8451 - val_loss: 0.3465 - val_acc: 0.8461\n",
      "Epoch 662/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3458 - acc: 0.8452 - val_loss: 0.3482 - val_acc: 0.8435\n",
      "Epoch 663/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3448 - acc: 0.8446 - val_loss: 0.3469 - val_acc: 0.8455\n",
      "Epoch 664/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3450 - acc: 0.8446 - val_loss: 0.3482 - val_acc: 0.8448\n",
      "Epoch 665/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3453 - acc: 0.8445 - val_loss: 0.3479 - val_acc: 0.8459\n",
      "Epoch 666/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3448 - acc: 0.8453 - val_loss: 0.3484 - val_acc: 0.8456\n",
      "Epoch 667/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3447 - acc: 0.8442 - val_loss: 0.3591 - val_acc: 0.8412\n",
      "Epoch 668/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3449 - acc: 0.8454 - val_loss: 0.3526 - val_acc: 0.8405\n",
      "Epoch 669/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3453 - acc: 0.8436 - val_loss: 0.3524 - val_acc: 0.8410\n",
      "Epoch 670/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3449 - acc: 0.8457 - val_loss: 0.3481 - val_acc: 0.8449\n",
      "Epoch 671/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3448 - acc: 0.8442 - val_loss: 0.3506 - val_acc: 0.8424\n",
      "Epoch 672/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3456 - acc: 0.8441 - val_loss: 0.3476 - val_acc: 0.8457\n",
      "Epoch 673/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3449 - acc: 0.8441 - val_loss: 0.3458 - val_acc: 0.8460\n",
      "Epoch 674/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3447 - acc: 0.8453 - val_loss: 0.3448 - val_acc: 0.8469\n",
      "Epoch 675/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3452 - acc: 0.8465 - val_loss: 0.3460 - val_acc: 0.8457\n",
      "Epoch 676/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3449 - acc: 0.8438 - val_loss: 0.3482 - val_acc: 0.8436\n",
      "Epoch 677/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3438 - acc: 0.8446 - val_loss: 0.3505 - val_acc: 0.8424\n",
      "Epoch 678/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3448 - acc: 0.8446 - val_loss: 0.3471 - val_acc: 0.8447\n",
      "Epoch 679/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3459 - acc: 0.8447 - val_loss: 0.3471 - val_acc: 0.8458\n",
      "Epoch 680/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3458 - acc: 0.8445 - val_loss: 0.3509 - val_acc: 0.8440\n",
      "Epoch 681/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3448 - acc: 0.8446 - val_loss: 0.3503 - val_acc: 0.8449\n",
      "Epoch 682/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3449 - acc: 0.8456 - val_loss: 0.3479 - val_acc: 0.8463\n",
      "Epoch 683/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3440 - acc: 0.8453 - val_loss: 0.3489 - val_acc: 0.8441\n",
      "Epoch 684/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3457 - acc: 0.8443 - val_loss: 0.3461 - val_acc: 0.8456\n",
      "Epoch 685/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3447 - acc: 0.8463 - val_loss: 0.3499 - val_acc: 0.8435\n",
      "Epoch 686/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3453 - acc: 0.8452 - val_loss: 0.3457 - val_acc: 0.8477\n",
      "Epoch 687/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3448 - acc: 0.8447 - val_loss: 0.3468 - val_acc: 0.8461\n",
      "Epoch 688/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3444 - acc: 0.8445 - val_loss: 0.3477 - val_acc: 0.8454\n",
      "Epoch 689/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3446 - acc: 0.8456 - val_loss: 0.3471 - val_acc: 0.8462\n",
      "Epoch 690/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3445 - acc: 0.8448 - val_loss: 0.3504 - val_acc: 0.8429\n",
      "Epoch 691/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3445 - acc: 0.8450 - val_loss: 0.3468 - val_acc: 0.8451\n",
      "Epoch 692/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3446 - acc: 0.8447 - val_loss: 0.3476 - val_acc: 0.8445\n",
      "Epoch 693/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3442 - acc: 0.8448 - val_loss: 0.3500 - val_acc: 0.8445\n",
      "Epoch 694/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3445 - acc: 0.8454 - val_loss: 0.3477 - val_acc: 0.8456\n",
      "Epoch 695/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3447 - acc: 0.8450 - val_loss: 0.3474 - val_acc: 0.8437\n",
      "Epoch 696/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3446 - acc: 0.8460 - val_loss: 0.3490 - val_acc: 0.8447\n",
      "Epoch 697/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3451 - acc: 0.8436 - val_loss: 0.3514 - val_acc: 0.8426\n",
      "Epoch 698/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3444 - acc: 0.8444 - val_loss: 0.3472 - val_acc: 0.8456\n",
      "Epoch 699/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3441 - acc: 0.8446 - val_loss: 0.3530 - val_acc: 0.8408\n",
      "Epoch 700/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3442 - acc: 0.8443 - val_loss: 0.3469 - val_acc: 0.8450\n",
      "Epoch 701/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3443 - acc: 0.8455 - val_loss: 0.3483 - val_acc: 0.8434\n",
      "Epoch 702/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3442 - acc: 0.8452 - val_loss: 0.3508 - val_acc: 0.8440\n",
      "Epoch 703/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3443 - acc: 0.8455 - val_loss: 0.3478 - val_acc: 0.8454\n",
      "Epoch 704/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3444 - acc: 0.8450 - val_loss: 0.3477 - val_acc: 0.8466\n",
      "Epoch 705/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3439 - acc: 0.8464 - val_loss: 0.3476 - val_acc: 0.8461\n",
      "Epoch 706/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3439 - acc: 0.8451 - val_loss: 0.3501 - val_acc: 0.8426\n",
      "Epoch 707/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3446 - acc: 0.8438 - val_loss: 0.3471 - val_acc: 0.8445\n",
      "Epoch 708/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3445 - acc: 0.8451 - val_loss: 0.3501 - val_acc: 0.8448\n",
      "Epoch 709/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3449 - acc: 0.8450 - val_loss: 0.3482 - val_acc: 0.8446\n",
      "Epoch 710/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3449 - acc: 0.8445 - val_loss: 0.3466 - val_acc: 0.8465\n",
      "Epoch 711/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3444 - acc: 0.8444 - val_loss: 0.3484 - val_acc: 0.8453\n",
      "Epoch 712/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3447 - acc: 0.8454 - val_loss: 0.3520 - val_acc: 0.8419\n",
      "Epoch 713/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3443 - acc: 0.8451 - val_loss: 0.3457 - val_acc: 0.8480\n",
      "Epoch 714/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3451 - acc: 0.8446 - val_loss: 0.3513 - val_acc: 0.8440\n",
      "Epoch 715/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3445 - acc: 0.8458 - val_loss: 0.3484 - val_acc: 0.8442\n",
      "Epoch 716/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3450 - acc: 0.8447 - val_loss: 0.3465 - val_acc: 0.8477\n",
      "Epoch 717/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3443 - acc: 0.8441 - val_loss: 0.3461 - val_acc: 0.8462\n",
      "Epoch 718/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3446 - acc: 0.8444 - val_loss: 0.3537 - val_acc: 0.8384\n",
      "Epoch 719/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3443 - acc: 0.8454 - val_loss: 0.3454 - val_acc: 0.8469\n",
      "Epoch 720/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3448 - acc: 0.8455 - val_loss: 0.3477 - val_acc: 0.8458\n",
      "Epoch 721/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3440 - acc: 0.8455 - val_loss: 0.3459 - val_acc: 0.8469\n",
      "Epoch 722/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3450 - acc: 0.8462 - val_loss: 0.3469 - val_acc: 0.8448\n",
      "Epoch 723/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3439 - acc: 0.8451 - val_loss: 0.3455 - val_acc: 0.8461\n",
      "Epoch 724/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3437 - acc: 0.8456 - val_loss: 0.3483 - val_acc: 0.8439\n",
      "Epoch 725/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3442 - acc: 0.8441 - val_loss: 0.3547 - val_acc: 0.8406\n",
      "Epoch 726/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3438 - acc: 0.8446 - val_loss: 0.3464 - val_acc: 0.8440\n",
      "Epoch 727/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3441 - acc: 0.8455 - val_loss: 0.3467 - val_acc: 0.8461\n",
      "Epoch 728/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3446 - acc: 0.8439 - val_loss: 0.3489 - val_acc: 0.8436\n",
      "Epoch 729/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3437 - acc: 0.8459 - val_loss: 0.3466 - val_acc: 0.8461\n",
      "Epoch 730/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3439 - acc: 0.8461 - val_loss: 0.3463 - val_acc: 0.8442\n",
      "Epoch 731/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3444 - acc: 0.8456 - val_loss: 0.3510 - val_acc: 0.8435\n",
      "Epoch 732/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3446 - acc: 0.8436 - val_loss: 0.3452 - val_acc: 0.8465\n",
      "Epoch 733/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3447 - acc: 0.8447 - val_loss: 0.3451 - val_acc: 0.8463\n",
      "Epoch 734/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3439 - acc: 0.8464 - val_loss: 0.3492 - val_acc: 0.8435\n",
      "Epoch 735/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3440 - acc: 0.8460 - val_loss: 0.3536 - val_acc: 0.8411\n",
      "Epoch 736/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3442 - acc: 0.8452 - val_loss: 0.3446 - val_acc: 0.8465\n",
      "Epoch 737/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3437 - acc: 0.8437 - val_loss: 0.3472 - val_acc: 0.8445\n",
      "Epoch 738/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3437 - acc: 0.8448 - val_loss: 0.3462 - val_acc: 0.8456\n",
      "Epoch 739/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3441 - acc: 0.8452 - val_loss: 0.3457 - val_acc: 0.8456\n",
      "Epoch 740/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3445 - acc: 0.8450 - val_loss: 0.3513 - val_acc: 0.8423\n",
      "Epoch 741/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3444 - acc: 0.8452 - val_loss: 0.3487 - val_acc: 0.8448\n",
      "Epoch 742/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3442 - acc: 0.8461 - val_loss: 0.3466 - val_acc: 0.8437\n",
      "Epoch 743/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3438 - acc: 0.8457 - val_loss: 0.3490 - val_acc: 0.8450\n",
      "Epoch 744/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3443 - acc: 0.8454 - val_loss: 0.3482 - val_acc: 0.8438\n",
      "Epoch 745/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3439 - acc: 0.8445 - val_loss: 0.3477 - val_acc: 0.8429\n",
      "Epoch 746/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3434 - acc: 0.8461 - val_loss: 0.3462 - val_acc: 0.8448\n",
      "Epoch 747/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3435 - acc: 0.8449 - val_loss: 0.3452 - val_acc: 0.8458\n",
      "Epoch 748/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3441 - acc: 0.8443 - val_loss: 0.3486 - val_acc: 0.8444\n",
      "Epoch 749/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3445 - acc: 0.8457 - val_loss: 0.3489 - val_acc: 0.8431\n",
      "Epoch 750/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3439 - acc: 0.8448 - val_loss: 0.3468 - val_acc: 0.8452\n",
      "Epoch 751/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3437 - acc: 0.8447 - val_loss: 0.3440 - val_acc: 0.8451\n",
      "Epoch 752/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3437 - acc: 0.8456 - val_loss: 0.3464 - val_acc: 0.8453\n",
      "Epoch 753/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3445 - acc: 0.8450 - val_loss: 0.3475 - val_acc: 0.8448\n",
      "Epoch 754/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3444 - acc: 0.8458 - val_loss: 0.3469 - val_acc: 0.8436\n",
      "Epoch 755/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3441 - acc: 0.8456 - val_loss: 0.3461 - val_acc: 0.8448\n",
      "Epoch 756/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3441 - acc: 0.8460 - val_loss: 0.3441 - val_acc: 0.8460\n",
      "Epoch 757/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3446 - acc: 0.8450 - val_loss: 0.3518 - val_acc: 0.8432\n",
      "Epoch 758/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3441 - acc: 0.8463 - val_loss: 0.3446 - val_acc: 0.8474\n",
      "Epoch 759/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3438 - acc: 0.8445 - val_loss: 0.3516 - val_acc: 0.8419\n",
      "Epoch 760/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3437 - acc: 0.8451 - val_loss: 0.3491 - val_acc: 0.8438\n",
      "Epoch 761/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3437 - acc: 0.8460 - val_loss: 0.3459 - val_acc: 0.8457\n",
      "Epoch 762/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3437 - acc: 0.8447 - val_loss: 0.3478 - val_acc: 0.8445\n",
      "Epoch 763/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3448 - acc: 0.8450 - val_loss: 0.3501 - val_acc: 0.8429\n",
      "Epoch 764/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3438 - acc: 0.8459 - val_loss: 0.3493 - val_acc: 0.8446\n",
      "Epoch 765/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3440 - acc: 0.8465 - val_loss: 0.3461 - val_acc: 0.8461\n",
      "Epoch 766/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3436 - acc: 0.8456 - val_loss: 0.3462 - val_acc: 0.8457\n",
      "Epoch 767/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3433 - acc: 0.8459 - val_loss: 0.3494 - val_acc: 0.8414\n",
      "Epoch 768/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3447 - acc: 0.8452 - val_loss: 0.3491 - val_acc: 0.8453\n",
      "Epoch 769/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3449 - acc: 0.8447 - val_loss: 0.3459 - val_acc: 0.8477\n",
      "Epoch 770/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3444 - acc: 0.8452 - val_loss: 0.3446 - val_acc: 0.8476\n",
      "Epoch 771/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3440 - acc: 0.8460 - val_loss: 0.3440 - val_acc: 0.8465\n",
      "Epoch 772/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3437 - acc: 0.8458 - val_loss: 0.3468 - val_acc: 0.8455\n",
      "Epoch 773/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3437 - acc: 0.8460 - val_loss: 0.3456 - val_acc: 0.8448\n",
      "Epoch 774/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3439 - acc: 0.8459 - val_loss: 0.3464 - val_acc: 0.8443\n",
      "Epoch 775/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3434 - acc: 0.8465 - val_loss: 0.3457 - val_acc: 0.8463\n",
      "Epoch 776/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3448 - acc: 0.8450 - val_loss: 0.3487 - val_acc: 0.8443\n",
      "Epoch 777/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3442 - acc: 0.8454 - val_loss: 0.3444 - val_acc: 0.8469\n",
      "Epoch 778/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3437 - acc: 0.8448 - val_loss: 0.3468 - val_acc: 0.8448\n",
      "Epoch 779/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3437 - acc: 0.8450 - val_loss: 0.3491 - val_acc: 0.8437\n",
      "Epoch 780/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3440 - acc: 0.8451 - val_loss: 0.3480 - val_acc: 0.8445\n",
      "Epoch 781/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3443 - acc: 0.8447 - val_loss: 0.3587 - val_acc: 0.8354\n",
      "Epoch 782/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3438 - acc: 0.8468 - val_loss: 0.3470 - val_acc: 0.8458\n",
      "Epoch 783/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3440 - acc: 0.8452 - val_loss: 0.3467 - val_acc: 0.8455\n",
      "Epoch 784/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3441 - acc: 0.8448 - val_loss: 0.3472 - val_acc: 0.8447\n",
      "Epoch 785/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3432 - acc: 0.8451 - val_loss: 0.3484 - val_acc: 0.8447\n",
      "Epoch 786/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3436 - acc: 0.8449 - val_loss: 0.3456 - val_acc: 0.8459\n",
      "Epoch 787/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3437 - acc: 0.8456 - val_loss: 0.3576 - val_acc: 0.8370\n",
      "Epoch 788/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3442 - acc: 0.8457 - val_loss: 0.3462 - val_acc: 0.8447\n",
      "Epoch 789/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3434 - acc: 0.8450 - val_loss: 0.3478 - val_acc: 0.8454\n",
      "Epoch 790/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3436 - acc: 0.8445 - val_loss: 0.3468 - val_acc: 0.8457\n",
      "Epoch 791/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3438 - acc: 0.8447 - val_loss: 0.3458 - val_acc: 0.8449\n",
      "Epoch 792/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3434 - acc: 0.8452 - val_loss: 0.3458 - val_acc: 0.8463\n",
      "Epoch 793/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3433 - acc: 0.8452 - val_loss: 0.3464 - val_acc: 0.8471\n",
      "Epoch 794/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3442 - acc: 0.8449 - val_loss: 0.3510 - val_acc: 0.8414\n",
      "Epoch 795/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3448 - acc: 0.8459 - val_loss: 0.3453 - val_acc: 0.8474\n",
      "Epoch 796/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3439 - acc: 0.8452 - val_loss: 0.3509 - val_acc: 0.8436\n",
      "Epoch 797/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3438 - acc: 0.8454 - val_loss: 0.3498 - val_acc: 0.8410\n",
      "Epoch 798/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3437 - acc: 0.8459 - val_loss: 0.3491 - val_acc: 0.8422\n",
      "Epoch 799/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3430 - acc: 0.8450 - val_loss: 0.3486 - val_acc: 0.8435\n",
      "Epoch 800/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3435 - acc: 0.8453 - val_loss: 0.3492 - val_acc: 0.8439\n",
      "Epoch 801/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3431 - acc: 0.8457 - val_loss: 0.3484 - val_acc: 0.8438\n",
      "Epoch 802/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3429 - acc: 0.8460 - val_loss: 0.3477 - val_acc: 0.8474\n",
      "Epoch 803/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3441 - acc: 0.8460 - val_loss: 0.3467 - val_acc: 0.8453\n",
      "Epoch 804/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3439 - acc: 0.8450 - val_loss: 0.3453 - val_acc: 0.8458\n",
      "Epoch 805/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3431 - acc: 0.8452 - val_loss: 0.3454 - val_acc: 0.8475\n",
      "Epoch 806/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3435 - acc: 0.8450 - val_loss: 0.3479 - val_acc: 0.8424\n",
      "Epoch 807/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3434 - acc: 0.8447 - val_loss: 0.3534 - val_acc: 0.8414\n",
      "Epoch 808/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3438 - acc: 0.8446 - val_loss: 0.3466 - val_acc: 0.8453\n",
      "Epoch 809/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3432 - acc: 0.8454 - val_loss: 0.3475 - val_acc: 0.8444\n",
      "Epoch 810/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3433 - acc: 0.8452 - val_loss: 0.3450 - val_acc: 0.8465\n",
      "Epoch 811/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3435 - acc: 0.8454 - val_loss: 0.3474 - val_acc: 0.8441\n",
      "Epoch 812/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3435 - acc: 0.8457 - val_loss: 0.3508 - val_acc: 0.8415\n",
      "Epoch 813/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3435 - acc: 0.8445 - val_loss: 0.3455 - val_acc: 0.8454\n",
      "Epoch 814/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3440 - acc: 0.8457 - val_loss: 0.3483 - val_acc: 0.8444\n",
      "Epoch 815/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3435 - acc: 0.8446 - val_loss: 0.3479 - val_acc: 0.8427\n",
      "Epoch 816/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3432 - acc: 0.8462 - val_loss: 0.3461 - val_acc: 0.8475\n",
      "Epoch 817/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3437 - acc: 0.8460 - val_loss: 0.3455 - val_acc: 0.8469\n",
      "Epoch 818/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3438 - acc: 0.8452 - val_loss: 0.3487 - val_acc: 0.8450\n",
      "Epoch 819/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3435 - acc: 0.8452 - val_loss: 0.3453 - val_acc: 0.8467\n",
      "Epoch 820/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3440 - acc: 0.8459 - val_loss: 0.3459 - val_acc: 0.8428\n",
      "Epoch 821/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3430 - acc: 0.8456 - val_loss: 0.3485 - val_acc: 0.8447\n",
      "Epoch 822/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3432 - acc: 0.8468 - val_loss: 0.3505 - val_acc: 0.8445\n",
      "Epoch 823/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3436 - acc: 0.8446 - val_loss: 0.3436 - val_acc: 0.8470\n",
      "Epoch 824/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3440 - acc: 0.8438 - val_loss: 0.3499 - val_acc: 0.8411\n",
      "Epoch 825/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3449 - acc: 0.8431 - val_loss: 0.3465 - val_acc: 0.8471\n",
      "Epoch 826/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3434 - acc: 0.8450 - val_loss: 0.3500 - val_acc: 0.8441\n",
      "Epoch 827/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3440 - acc: 0.8448 - val_loss: 0.3448 - val_acc: 0.8463\n",
      "Epoch 828/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3432 - acc: 0.8455 - val_loss: 0.3449 - val_acc: 0.8481\n",
      "Epoch 829/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3426 - acc: 0.8459 - val_loss: 0.3446 - val_acc: 0.8468\n",
      "Epoch 830/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3433 - acc: 0.8450 - val_loss: 0.3466 - val_acc: 0.8446\n",
      "Epoch 831/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3437 - acc: 0.8452 - val_loss: 0.3460 - val_acc: 0.8459\n",
      "Epoch 832/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3429 - acc: 0.8450 - val_loss: 0.3441 - val_acc: 0.8481\n",
      "Epoch 833/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3436 - acc: 0.8456 - val_loss: 0.3462 - val_acc: 0.8485\n",
      "Epoch 834/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3432 - acc: 0.8466 - val_loss: 0.3462 - val_acc: 0.8451\n",
      "Epoch 835/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3435 - acc: 0.8456 - val_loss: 0.3456 - val_acc: 0.8451\n",
      "Epoch 836/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3433 - acc: 0.8446 - val_loss: 0.3463 - val_acc: 0.8472\n",
      "Epoch 837/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3427 - acc: 0.8470 - val_loss: 0.3454 - val_acc: 0.8446\n",
      "Epoch 838/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3439 - acc: 0.8450 - val_loss: 0.3453 - val_acc: 0.8478\n",
      "Epoch 839/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3435 - acc: 0.8452 - val_loss: 0.3450 - val_acc: 0.8464\n",
      "Epoch 840/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3431 - acc: 0.8464 - val_loss: 0.3456 - val_acc: 0.8458\n",
      "Epoch 841/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3431 - acc: 0.8454 - val_loss: 0.3442 - val_acc: 0.8482\n",
      "Epoch 842/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3439 - acc: 0.8460 - val_loss: 0.3452 - val_acc: 0.8477\n",
      "Epoch 843/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3436 - acc: 0.8449 - val_loss: 0.3531 - val_acc: 0.8427\n",
      "Epoch 844/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3432 - acc: 0.8458 - val_loss: 0.3480 - val_acc: 0.8445\n",
      "Epoch 845/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3426 - acc: 0.8462 - val_loss: 0.3445 - val_acc: 0.8460\n",
      "Epoch 846/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3430 - acc: 0.8449 - val_loss: 0.3478 - val_acc: 0.8442\n",
      "Epoch 847/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3429 - acc: 0.8452 - val_loss: 0.3440 - val_acc: 0.8455\n",
      "Epoch 848/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3428 - acc: 0.8450 - val_loss: 0.3496 - val_acc: 0.8427\n",
      "Epoch 849/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3434 - acc: 0.8457 - val_loss: 0.3460 - val_acc: 0.8455\n",
      "Epoch 850/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3434 - acc: 0.8463 - val_loss: 0.3465 - val_acc: 0.8461\n",
      "Epoch 851/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3427 - acc: 0.8456 - val_loss: 0.3481 - val_acc: 0.8469\n",
      "Epoch 852/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3436 - acc: 0.8453 - val_loss: 0.3469 - val_acc: 0.8461\n",
      "Epoch 853/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3432 - acc: 0.8449 - val_loss: 0.3449 - val_acc: 0.8470\n",
      "Epoch 854/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3436 - acc: 0.8442 - val_loss: 0.3468 - val_acc: 0.8447\n",
      "Epoch 855/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3432 - acc: 0.8448 - val_loss: 0.3472 - val_acc: 0.8446\n",
      "Epoch 856/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3432 - acc: 0.8455 - val_loss: 0.3449 - val_acc: 0.8463\n",
      "Epoch 857/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3427 - acc: 0.8465 - val_loss: 0.3461 - val_acc: 0.8457\n",
      "Epoch 858/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3432 - acc: 0.8462 - val_loss: 0.3482 - val_acc: 0.8465\n",
      "Epoch 859/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3428 - acc: 0.8452 - val_loss: 0.3452 - val_acc: 0.8479\n",
      "Epoch 860/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3426 - acc: 0.8455 - val_loss: 0.3467 - val_acc: 0.8452\n",
      "Epoch 861/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3427 - acc: 0.8457 - val_loss: 0.3507 - val_acc: 0.8429\n",
      "Epoch 862/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3424 - acc: 0.8459 - val_loss: 0.3472 - val_acc: 0.8451\n",
      "Epoch 863/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3433 - acc: 0.8456 - val_loss: 0.3448 - val_acc: 0.8474\n",
      "Epoch 864/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3428 - acc: 0.8455 - val_loss: 0.3479 - val_acc: 0.8462\n",
      "Epoch 865/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3426 - acc: 0.8461 - val_loss: 0.3447 - val_acc: 0.8484\n",
      "Epoch 866/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3428 - acc: 0.8463 - val_loss: 0.3468 - val_acc: 0.8460\n",
      "Epoch 867/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8464 - val_loss: 0.3471 - val_acc: 0.8467\n",
      "Epoch 868/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3425 - acc: 0.8468 - val_loss: 0.3441 - val_acc: 0.8474\n",
      "Epoch 869/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8460 - val_loss: 0.3468 - val_acc: 0.8442\n",
      "Epoch 870/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3424 - acc: 0.8466 - val_loss: 0.3507 - val_acc: 0.8445\n",
      "Epoch 871/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3426 - acc: 0.8467 - val_loss: 0.3475 - val_acc: 0.8444\n",
      "Epoch 872/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3429 - acc: 0.8456 - val_loss: 0.3468 - val_acc: 0.8446\n",
      "Epoch 873/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8473 - val_loss: 0.3477 - val_acc: 0.8454\n",
      "Epoch 874/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3430 - acc: 0.8457 - val_loss: 0.3456 - val_acc: 0.8471\n",
      "Epoch 875/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3429 - acc: 0.8469 - val_loss: 0.3439 - val_acc: 0.8489\n",
      "Epoch 876/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8472 - val_loss: 0.3474 - val_acc: 0.8468\n",
      "Epoch 877/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3420 - acc: 0.8466 - val_loss: 0.3458 - val_acc: 0.8460\n",
      "Epoch 878/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3423 - acc: 0.8468 - val_loss: 0.3454 - val_acc: 0.8461\n",
      "Epoch 879/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3428 - acc: 0.8461 - val_loss: 0.3486 - val_acc: 0.8426\n",
      "Epoch 880/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3429 - acc: 0.8457 - val_loss: 0.3452 - val_acc: 0.8470\n",
      "Epoch 881/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8466 - val_loss: 0.3457 - val_acc: 0.8471\n",
      "Epoch 882/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3424 - acc: 0.8455 - val_loss: 0.3465 - val_acc: 0.8472\n",
      "Epoch 883/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3427 - acc: 0.8460 - val_loss: 0.3451 - val_acc: 0.8474\n",
      "Epoch 884/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3423 - acc: 0.8472 - val_loss: 0.3476 - val_acc: 0.8450\n",
      "Epoch 885/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3429 - acc: 0.8450 - val_loss: 0.3444 - val_acc: 0.8485\n",
      "Epoch 886/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3425 - acc: 0.8466 - val_loss: 0.3464 - val_acc: 0.8435\n",
      "Epoch 887/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3424 - acc: 0.8454 - val_loss: 0.3450 - val_acc: 0.8464\n",
      "Epoch 888/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3423 - acc: 0.8462 - val_loss: 0.3483 - val_acc: 0.8430\n",
      "Epoch 889/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3427 - acc: 0.8462 - val_loss: 0.3461 - val_acc: 0.8459\n",
      "Epoch 890/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3427 - acc: 0.8465 - val_loss: 0.3463 - val_acc: 0.8442\n",
      "Epoch 891/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3424 - acc: 0.8450 - val_loss: 0.3502 - val_acc: 0.8420\n",
      "Epoch 892/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3426 - acc: 0.8454 - val_loss: 0.3453 - val_acc: 0.8469\n",
      "Epoch 893/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3426 - acc: 0.8456 - val_loss: 0.3457 - val_acc: 0.8470\n",
      "Epoch 894/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3422 - acc: 0.8462 - val_loss: 0.3472 - val_acc: 0.8457\n",
      "Epoch 895/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3426 - acc: 0.8453 - val_loss: 0.3462 - val_acc: 0.8456\n",
      "Epoch 896/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3429 - acc: 0.8461 - val_loss: 0.3467 - val_acc: 0.8442\n",
      "Epoch 897/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3430 - acc: 0.8458 - val_loss: 0.3448 - val_acc: 0.8459\n",
      "Epoch 898/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3426 - acc: 0.8454 - val_loss: 0.3462 - val_acc: 0.8464\n",
      "Epoch 899/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3424 - acc: 0.8467 - val_loss: 0.3461 - val_acc: 0.8437\n",
      "Epoch 900/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3430 - acc: 0.8439 - val_loss: 0.3467 - val_acc: 0.8446\n",
      "Epoch 901/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3427 - acc: 0.8447 - val_loss: 0.3491 - val_acc: 0.8451\n",
      "Epoch 902/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3423 - acc: 0.8456 - val_loss: 0.3465 - val_acc: 0.8470\n",
      "Epoch 903/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3420 - acc: 0.8452 - val_loss: 0.3473 - val_acc: 0.8441\n",
      "Epoch 904/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3431 - acc: 0.8445 - val_loss: 0.3441 - val_acc: 0.8482\n",
      "Epoch 905/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8467 - val_loss: 0.3460 - val_acc: 0.8470\n",
      "Epoch 906/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3430 - acc: 0.8468 - val_loss: 0.3457 - val_acc: 0.8459\n",
      "Epoch 907/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3427 - acc: 0.8466 - val_loss: 0.3447 - val_acc: 0.8474\n",
      "Epoch 908/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3433 - acc: 0.8472 - val_loss: 0.3456 - val_acc: 0.8465\n",
      "Epoch 909/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3430 - acc: 0.8468 - val_loss: 0.3464 - val_acc: 0.8455\n",
      "Epoch 910/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8478 - val_loss: 0.3471 - val_acc: 0.8444\n",
      "Epoch 911/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8460 - val_loss: 0.3473 - val_acc: 0.8477\n",
      "Epoch 912/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8467 - val_loss: 0.3584 - val_acc: 0.8400\n",
      "Epoch 913/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3433 - acc: 0.8461 - val_loss: 0.3475 - val_acc: 0.8454\n",
      "Epoch 914/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3431 - acc: 0.8458 - val_loss: 0.3490 - val_acc: 0.8464\n",
      "Epoch 915/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3430 - acc: 0.8457 - val_loss: 0.3463 - val_acc: 0.8436\n",
      "Epoch 916/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8461 - val_loss: 0.3465 - val_acc: 0.8453\n",
      "Epoch 917/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3425 - acc: 0.8456 - val_loss: 0.3456 - val_acc: 0.8465\n",
      "Epoch 918/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8470 - val_loss: 0.3470 - val_acc: 0.8472\n",
      "Epoch 919/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8466 - val_loss: 0.3458 - val_acc: 0.8463\n",
      "Epoch 920/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3430 - acc: 0.8465 - val_loss: 0.3451 - val_acc: 0.8482\n",
      "Epoch 921/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3425 - acc: 0.8457 - val_loss: 0.3461 - val_acc: 0.8469\n",
      "Epoch 922/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8464 - val_loss: 0.3467 - val_acc: 0.8444\n",
      "Epoch 923/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8460 - val_loss: 0.3453 - val_acc: 0.8487\n",
      "Epoch 924/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3429 - acc: 0.8462 - val_loss: 0.3454 - val_acc: 0.8472\n",
      "Epoch 925/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8468 - val_loss: 0.3483 - val_acc: 0.8450\n",
      "Epoch 926/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8466 - val_loss: 0.3461 - val_acc: 0.8469\n",
      "Epoch 927/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3427 - acc: 0.8455 - val_loss: 0.3459 - val_acc: 0.8463\n",
      "Epoch 928/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3428 - acc: 0.8457 - val_loss: 0.3476 - val_acc: 0.8464\n",
      "Epoch 929/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3426 - acc: 0.8460 - val_loss: 0.3510 - val_acc: 0.8422\n",
      "Epoch 930/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8471 - val_loss: 0.3503 - val_acc: 0.8448\n",
      "Epoch 931/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8462 - val_loss: 0.3459 - val_acc: 0.8476\n",
      "Epoch 932/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8463 - val_loss: 0.3467 - val_acc: 0.8457\n",
      "Epoch 933/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8473 - val_loss: 0.3477 - val_acc: 0.8446\n",
      "Epoch 934/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8468 - val_loss: 0.3459 - val_acc: 0.8477\n",
      "Epoch 935/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8470 - val_loss: 0.3464 - val_acc: 0.8456\n",
      "Epoch 936/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8458 - val_loss: 0.3474 - val_acc: 0.8450\n",
      "Epoch 937/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8460 - val_loss: 0.3459 - val_acc: 0.8469\n",
      "Epoch 938/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3425 - acc: 0.8454 - val_loss: 0.3460 - val_acc: 0.8456\n",
      "Epoch 939/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3426 - acc: 0.8464 - val_loss: 0.3449 - val_acc: 0.8477\n",
      "Epoch 940/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3430 - acc: 0.8466 - val_loss: 0.3473 - val_acc: 0.8471\n",
      "Epoch 941/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3427 - acc: 0.8467 - val_loss: 0.3479 - val_acc: 0.8448\n",
      "Epoch 942/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8464 - val_loss: 0.3454 - val_acc: 0.8466\n",
      "Epoch 943/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8460 - val_loss: 0.3519 - val_acc: 0.8423\n",
      "Epoch 944/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3430 - acc: 0.8457 - val_loss: 0.3444 - val_acc: 0.8476\n",
      "Epoch 945/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3425 - acc: 0.8466 - val_loss: 0.3449 - val_acc: 0.8481\n",
      "Epoch 946/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8455 - val_loss: 0.3452 - val_acc: 0.8477\n",
      "Epoch 947/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8473 - val_loss: 0.3456 - val_acc: 0.8487\n",
      "Epoch 948/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3429 - acc: 0.8463 - val_loss: 0.3501 - val_acc: 0.8443\n",
      "Epoch 949/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3426 - acc: 0.8458 - val_loss: 0.3493 - val_acc: 0.8467\n",
      "Epoch 950/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3425 - acc: 0.8465 - val_loss: 0.3466 - val_acc: 0.8481\n",
      "Epoch 951/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8474 - val_loss: 0.3455 - val_acc: 0.8448\n",
      "Epoch 952/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3429 - acc: 0.8457 - val_loss: 0.3519 - val_acc: 0.8407\n",
      "Epoch 953/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3427 - acc: 0.8459 - val_loss: 0.3486 - val_acc: 0.8442\n",
      "Epoch 954/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8475 - val_loss: 0.3445 - val_acc: 0.8481\n",
      "Epoch 955/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8464 - val_loss: 0.3474 - val_acc: 0.8445\n",
      "Epoch 956/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8469 - val_loss: 0.3452 - val_acc: 0.8477\n",
      "Epoch 957/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3419 - acc: 0.8464 - val_loss: 0.3454 - val_acc: 0.8457\n",
      "Epoch 958/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8463 - val_loss: 0.3452 - val_acc: 0.8463\n",
      "Epoch 959/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8457 - val_loss: 0.3497 - val_acc: 0.8454\n",
      "Epoch 960/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8461 - val_loss: 0.3461 - val_acc: 0.8479\n",
      "Epoch 961/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8455 - val_loss: 0.3461 - val_acc: 0.8463\n",
      "Epoch 962/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8471 - val_loss: 0.3466 - val_acc: 0.8463\n",
      "Epoch 963/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8463 - val_loss: 0.3446 - val_acc: 0.8466\n",
      "Epoch 964/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8471 - val_loss: 0.3448 - val_acc: 0.8471\n",
      "Epoch 965/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8465 - val_loss: 0.3475 - val_acc: 0.8469\n",
      "Epoch 966/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8460 - val_loss: 0.3445 - val_acc: 0.8471\n",
      "Epoch 967/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3416 - acc: 0.8462 - val_loss: 0.3467 - val_acc: 0.8437\n",
      "Epoch 968/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3415 - acc: 0.8458 - val_loss: 0.3501 - val_acc: 0.8440\n",
      "Epoch 969/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3420 - acc: 0.8460 - val_loss: 0.3475 - val_acc: 0.8458\n",
      "Epoch 970/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3420 - acc: 0.8474 - val_loss: 0.3450 - val_acc: 0.8482\n",
      "Epoch 971/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8465 - val_loss: 0.3456 - val_acc: 0.8448\n",
      "Epoch 972/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3417 - acc: 0.8467 - val_loss: 0.3491 - val_acc: 0.8457\n",
      "Epoch 973/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3421 - acc: 0.8469 - val_loss: 0.3467 - val_acc: 0.8463\n",
      "Epoch 974/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3423 - acc: 0.8461 - val_loss: 0.3466 - val_acc: 0.8468\n",
      "Epoch 975/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8466 - val_loss: 0.3460 - val_acc: 0.8492\n",
      "Epoch 976/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8469 - val_loss: 0.3482 - val_acc: 0.8442\n",
      "Epoch 977/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3424 - acc: 0.8459 - val_loss: 0.3440 - val_acc: 0.8470\n",
      "Epoch 978/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3428 - acc: 0.8466 - val_loss: 0.3469 - val_acc: 0.8471\n",
      "Epoch 979/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8472 - val_loss: 0.3499 - val_acc: 0.8432\n",
      "Epoch 980/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3421 - acc: 0.8461 - val_loss: 0.3474 - val_acc: 0.8437\n",
      "Epoch 981/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3424 - acc: 0.8463 - val_loss: 0.3455 - val_acc: 0.8466\n",
      "Epoch 982/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3427 - acc: 0.8453 - val_loss: 0.3506 - val_acc: 0.8422\n",
      "Epoch 983/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8471 - val_loss: 0.3503 - val_acc: 0.8413\n",
      "Epoch 984/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3421 - acc: 0.8461 - val_loss: 0.3439 - val_acc: 0.8477\n",
      "Epoch 985/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8464 - val_loss: 0.3493 - val_acc: 0.8461\n",
      "Epoch 986/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3424 - acc: 0.8452 - val_loss: 0.3449 - val_acc: 0.8474\n",
      "Epoch 987/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8466 - val_loss: 0.3463 - val_acc: 0.8471\n",
      "Epoch 988/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8466 - val_loss: 0.3459 - val_acc: 0.8474\n",
      "Epoch 989/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8468 - val_loss: 0.3499 - val_acc: 0.8456\n",
      "Epoch 990/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3426 - acc: 0.8466 - val_loss: 0.3452 - val_acc: 0.8458\n",
      "Epoch 991/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3428 - acc: 0.8459 - val_loss: 0.3468 - val_acc: 0.8453\n",
      "Epoch 992/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8458 - val_loss: 0.3487 - val_acc: 0.8450\n",
      "Epoch 993/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8465 - val_loss: 0.3484 - val_acc: 0.8464\n",
      "Epoch 994/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3425 - acc: 0.8458 - val_loss: 0.3469 - val_acc: 0.8463\n",
      "Epoch 995/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8460 - val_loss: 0.3470 - val_acc: 0.8447\n",
      "Epoch 996/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8480 - val_loss: 0.3462 - val_acc: 0.8478\n",
      "Epoch 997/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8460 - val_loss: 0.3454 - val_acc: 0.8471\n",
      "Epoch 998/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8483 - val_loss: 0.3472 - val_acc: 0.8479\n",
      "Epoch 999/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8459 - val_loss: 0.3493 - val_acc: 0.8462\n",
      "Epoch 1000/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8470 - val_loss: 0.3495 - val_acc: 0.8441\n",
      "Epoch 1001/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8457 - val_loss: 0.3442 - val_acc: 0.8482\n",
      "Epoch 1002/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8470 - val_loss: 0.3487 - val_acc: 0.8464\n",
      "Epoch 1003/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8470 - val_loss: 0.3467 - val_acc: 0.8458\n",
      "Epoch 1004/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8468 - val_loss: 0.3465 - val_acc: 0.8479\n",
      "Epoch 1005/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8469 - val_loss: 0.3483 - val_acc: 0.8467\n",
      "Epoch 1006/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8464 - val_loss: 0.3461 - val_acc: 0.8459\n",
      "Epoch 1007/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8461 - val_loss: 0.3468 - val_acc: 0.8456\n",
      "Epoch 1008/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8466 - val_loss: 0.3467 - val_acc: 0.8446\n",
      "Epoch 1009/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8470 - val_loss: 0.3463 - val_acc: 0.8482\n",
      "Epoch 1010/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8472 - val_loss: 0.3471 - val_acc: 0.8463\n",
      "Epoch 1011/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8464 - val_loss: 0.3493 - val_acc: 0.8450\n",
      "Epoch 1012/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8456 - val_loss: 0.3453 - val_acc: 0.8464\n",
      "Epoch 1013/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3428 - acc: 0.8469 - val_loss: 0.3487 - val_acc: 0.8461\n",
      "Epoch 1014/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8458 - val_loss: 0.3459 - val_acc: 0.8459\n",
      "Epoch 1015/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3423 - acc: 0.8455 - val_loss: 0.3502 - val_acc: 0.8411\n",
      "Epoch 1016/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3422 - acc: 0.8469 - val_loss: 0.3486 - val_acc: 0.8440\n",
      "Epoch 1017/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3416 - acc: 0.8469 - val_loss: 0.3476 - val_acc: 0.8456\n",
      "Epoch 1018/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3415 - acc: 0.8465 - val_loss: 0.3489 - val_acc: 0.8437\n",
      "Epoch 1019/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3420 - acc: 0.8467 - val_loss: 0.3473 - val_acc: 0.8463\n",
      "Epoch 1020/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3415 - acc: 0.8461 - val_loss: 0.3469 - val_acc: 0.8469\n",
      "Epoch 1021/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3419 - acc: 0.8465 - val_loss: 0.3451 - val_acc: 0.8472\n",
      "Epoch 1022/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8473 - val_loss: 0.3481 - val_acc: 0.8455\n",
      "Epoch 1023/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8477 - val_loss: 0.3456 - val_acc: 0.8461\n",
      "Epoch 1024/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8480 - val_loss: 0.3501 - val_acc: 0.8432\n",
      "Epoch 1025/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8464 - val_loss: 0.3468 - val_acc: 0.8466\n",
      "Epoch 1026/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3418 - acc: 0.8462 - val_loss: 0.3456 - val_acc: 0.8462\n",
      "Epoch 1027/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8471 - val_loss: 0.3489 - val_acc: 0.8438\n",
      "Epoch 1028/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8476 - val_loss: 0.3470 - val_acc: 0.8466\n",
      "Epoch 1029/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8469 - val_loss: 0.3439 - val_acc: 0.8483\n",
      "Epoch 1030/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3426 - acc: 0.8471 - val_loss: 0.3463 - val_acc: 0.8440\n",
      "Epoch 1031/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3424 - acc: 0.8471 - val_loss: 0.3506 - val_acc: 0.8454\n",
      "Epoch 1032/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3425 - acc: 0.8458 - val_loss: 0.3484 - val_acc: 0.8458\n",
      "Epoch 1033/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3429 - acc: 0.8453 - val_loss: 0.3440 - val_acc: 0.8476\n",
      "Epoch 1034/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3419 - acc: 0.8478 - val_loss: 0.3445 - val_acc: 0.8482\n",
      "Epoch 1035/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8473 - val_loss: 0.3462 - val_acc: 0.8455\n",
      "Epoch 1036/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8456 - val_loss: 0.3447 - val_acc: 0.8471\n",
      "Epoch 1037/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8476 - val_loss: 0.3451 - val_acc: 0.8477\n",
      "Epoch 1038/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8457 - val_loss: 0.3478 - val_acc: 0.8449\n",
      "Epoch 1039/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8470 - val_loss: 0.3470 - val_acc: 0.8463\n",
      "Epoch 1040/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3420 - acc: 0.8471 - val_loss: 0.3445 - val_acc: 0.8482\n",
      "Epoch 1041/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8470 - val_loss: 0.3510 - val_acc: 0.8450\n",
      "Epoch 1042/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8468 - val_loss: 0.3503 - val_acc: 0.8437\n",
      "Epoch 1043/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3423 - acc: 0.8465 - val_loss: 0.3480 - val_acc: 0.8443\n",
      "Epoch 1044/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8471 - val_loss: 0.3504 - val_acc: 0.8445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1045/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3422 - acc: 0.8467 - val_loss: 0.3464 - val_acc: 0.8454\n",
      "Epoch 1046/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3417 - acc: 0.8455 - val_loss: 0.3483 - val_acc: 0.8435\n",
      "Epoch 1047/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3417 - acc: 0.8478 - val_loss: 0.3460 - val_acc: 0.8471\n",
      "Epoch 1048/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3419 - acc: 0.8460 - val_loss: 0.3463 - val_acc: 0.8471\n",
      "Epoch 1049/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8460 - val_loss: 0.3438 - val_acc: 0.8473\n",
      "Epoch 1050/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3413 - acc: 0.8461 - val_loss: 0.3466 - val_acc: 0.8445\n",
      "Epoch 1051/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8467 - val_loss: 0.3459 - val_acc: 0.8477\n",
      "Epoch 1052/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3423 - acc: 0.8470 - val_loss: 0.3461 - val_acc: 0.8477\n",
      "Epoch 1053/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3418 - acc: 0.8464 - val_loss: 0.3536 - val_acc: 0.8407\n",
      "Epoch 1054/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3425 - acc: 0.8459 - val_loss: 0.3446 - val_acc: 0.8486\n",
      "Epoch 1055/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8476 - val_loss: 0.3483 - val_acc: 0.8465\n",
      "Epoch 1056/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8476 - val_loss: 0.3472 - val_acc: 0.8418\n",
      "Epoch 1057/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8469 - val_loss: 0.3494 - val_acc: 0.8475\n",
      "Epoch 1058/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8472 - val_loss: 0.3447 - val_acc: 0.8471\n",
      "Epoch 1059/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3417 - acc: 0.8477 - val_loss: 0.3463 - val_acc: 0.8458\n",
      "Epoch 1060/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3418 - acc: 0.8473 - val_loss: 0.3462 - val_acc: 0.8454\n",
      "Epoch 1061/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3413 - acc: 0.8468 - val_loss: 0.3459 - val_acc: 0.8462\n",
      "Epoch 1062/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3421 - acc: 0.8462 - val_loss: 0.3502 - val_acc: 0.8426\n",
      "Epoch 1063/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3416 - acc: 0.8469 - val_loss: 0.3476 - val_acc: 0.8460\n",
      "Epoch 1064/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3415 - acc: 0.8469 - val_loss: 0.3465 - val_acc: 0.8469\n",
      "Epoch 1065/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8455 - val_loss: 0.3465 - val_acc: 0.8471\n",
      "Epoch 1066/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3415 - acc: 0.8469 - val_loss: 0.3449 - val_acc: 0.8480\n",
      "Epoch 1067/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3419 - acc: 0.8466 - val_loss: 0.3515 - val_acc: 0.8385\n",
      "Epoch 1068/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3412 - acc: 0.8463 - val_loss: 0.3492 - val_acc: 0.8456\n",
      "Epoch 1069/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3417 - acc: 0.8464 - val_loss: 0.3466 - val_acc: 0.8448\n",
      "Epoch 1070/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3419 - acc: 0.8456 - val_loss: 0.3452 - val_acc: 0.8450\n",
      "Epoch 1071/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3420 - acc: 0.8461 - val_loss: 0.3453 - val_acc: 0.8477\n",
      "Epoch 1072/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3415 - acc: 0.8474 - val_loss: 0.3459 - val_acc: 0.8461\n",
      "Epoch 1073/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8470 - val_loss: 0.3434 - val_acc: 0.8479\n",
      "Epoch 1074/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8473 - val_loss: 0.3441 - val_acc: 0.8469\n",
      "Epoch 1075/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8460 - val_loss: 0.3533 - val_acc: 0.8424\n",
      "Epoch 1076/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8475 - val_loss: 0.3517 - val_acc: 0.8437\n",
      "Epoch 1077/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3422 - acc: 0.8461 - val_loss: 0.3450 - val_acc: 0.8474\n",
      "Epoch 1078/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8466 - val_loss: 0.3445 - val_acc: 0.8455\n",
      "Epoch 1079/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3414 - acc: 0.8468 - val_loss: 0.3461 - val_acc: 0.8469\n",
      "Epoch 1080/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8469 - val_loss: 0.3434 - val_acc: 0.8484\n",
      "Epoch 1081/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8463 - val_loss: 0.3475 - val_acc: 0.8464\n",
      "Epoch 1082/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3413 - acc: 0.8467 - val_loss: 0.3471 - val_acc: 0.8463\n",
      "Epoch 1083/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3420 - acc: 0.8474 - val_loss: 0.3462 - val_acc: 0.8462\n",
      "Epoch 1084/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8470 - val_loss: 0.3466 - val_acc: 0.8458\n",
      "Epoch 1085/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3414 - acc: 0.8465 - val_loss: 0.3493 - val_acc: 0.8448\n",
      "Epoch 1086/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3408 - acc: 0.8480 - val_loss: 0.3466 - val_acc: 0.8492\n",
      "Epoch 1087/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3409 - acc: 0.8488 - val_loss: 0.3470 - val_acc: 0.8482\n",
      "Epoch 1088/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3424 - acc: 0.8467 - val_loss: 0.3466 - val_acc: 0.8456\n",
      "Epoch 1089/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8471 - val_loss: 0.3461 - val_acc: 0.8454\n",
      "Epoch 1090/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8472 - val_loss: 0.3522 - val_acc: 0.8428\n",
      "Epoch 1091/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8462 - val_loss: 0.3461 - val_acc: 0.8460\n",
      "Epoch 1092/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8457 - val_loss: 0.3490 - val_acc: 0.8453\n",
      "Epoch 1093/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8474 - val_loss: 0.3485 - val_acc: 0.8441\n",
      "Epoch 1094/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8469 - val_loss: 0.3524 - val_acc: 0.8434\n",
      "Epoch 1095/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8469 - val_loss: 0.3449 - val_acc: 0.8471\n",
      "Epoch 1096/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8466 - val_loss: 0.3449 - val_acc: 0.8468\n",
      "Epoch 1097/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8473 - val_loss: 0.3456 - val_acc: 0.8487\n",
      "Epoch 1098/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8455 - val_loss: 0.3463 - val_acc: 0.8451\n",
      "Epoch 1099/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8465 - val_loss: 0.3463 - val_acc: 0.8481\n",
      "Epoch 1100/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8483 - val_loss: 0.3448 - val_acc: 0.8455\n",
      "Epoch 1101/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8467 - val_loss: 0.3478 - val_acc: 0.8471\n",
      "Epoch 1102/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8469 - val_loss: 0.3486 - val_acc: 0.8474\n",
      "Epoch 1103/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8482 - val_loss: 0.3477 - val_acc: 0.8470\n",
      "Epoch 1104/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8466 - val_loss: 0.3466 - val_acc: 0.8466\n",
      "Epoch 1105/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3407 - acc: 0.8469 - val_loss: 0.3454 - val_acc: 0.8469\n",
      "Epoch 1106/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8481 - val_loss: 0.3511 - val_acc: 0.8431\n",
      "Epoch 1107/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3419 - acc: 0.8469 - val_loss: 0.3443 - val_acc: 0.8477\n",
      "Epoch 1108/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3414 - acc: 0.8462 - val_loss: 0.3444 - val_acc: 0.8469\n",
      "Epoch 1109/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3413 - acc: 0.8467 - val_loss: 0.3458 - val_acc: 0.8448\n",
      "Epoch 1110/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3417 - acc: 0.8455 - val_loss: 0.3487 - val_acc: 0.8444\n",
      "Epoch 1111/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3412 - acc: 0.8469 - val_loss: 0.3477 - val_acc: 0.8444\n",
      "Epoch 1112/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3414 - acc: 0.8476 - val_loss: 0.3453 - val_acc: 0.8480\n",
      "Epoch 1113/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3421 - acc: 0.8468 - val_loss: 0.3469 - val_acc: 0.8481\n",
      "Epoch 1114/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3416 - acc: 0.8480 - val_loss: 0.3525 - val_acc: 0.8408\n",
      "Epoch 1115/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8467 - val_loss: 0.3475 - val_acc: 0.8463\n",
      "Epoch 1116/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3421 - acc: 0.8465 - val_loss: 0.3460 - val_acc: 0.8474\n",
      "Epoch 1117/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8470 - val_loss: 0.3453 - val_acc: 0.8476\n",
      "Epoch 1118/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8472 - val_loss: 0.3470 - val_acc: 0.8464\n",
      "Epoch 1119/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8466 - val_loss: 0.3449 - val_acc: 0.8475\n",
      "Epoch 1120/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8465 - val_loss: 0.3473 - val_acc: 0.8450\n",
      "Epoch 1121/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8466 - val_loss: 0.3477 - val_acc: 0.8444\n",
      "Epoch 1122/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8481 - val_loss: 0.3478 - val_acc: 0.8440\n",
      "Epoch 1123/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8465 - val_loss: 0.3476 - val_acc: 0.8466\n",
      "Epoch 1124/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8468 - val_loss: 0.3460 - val_acc: 0.8470\n",
      "Epoch 1125/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8466 - val_loss: 0.3466 - val_acc: 0.8475\n",
      "Epoch 1126/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3407 - acc: 0.8477 - val_loss: 0.3465 - val_acc: 0.8464\n",
      "Epoch 1127/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8473 - val_loss: 0.3504 - val_acc: 0.8413\n",
      "Epoch 1128/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8481 - val_loss: 0.3466 - val_acc: 0.8458\n",
      "Epoch 1129/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3412 - acc: 0.8467 - val_loss: 0.3462 - val_acc: 0.8441\n",
      "Epoch 1130/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3407 - acc: 0.8467 - val_loss: 0.3477 - val_acc: 0.8458\n",
      "Epoch 1131/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8462 - val_loss: 0.3477 - val_acc: 0.8421\n",
      "Epoch 1132/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8463 - val_loss: 0.3472 - val_acc: 0.8463\n",
      "Epoch 1133/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8464 - val_loss: 0.3469 - val_acc: 0.8454\n",
      "Epoch 1134/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8451 - val_loss: 0.3474 - val_acc: 0.8444\n",
      "Epoch 1135/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8461 - val_loss: 0.3468 - val_acc: 0.8450\n",
      "Epoch 1136/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8468 - val_loss: 0.3452 - val_acc: 0.8466\n",
      "Epoch 1137/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8466 - val_loss: 0.3451 - val_acc: 0.8472\n",
      "Epoch 1138/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8465 - val_loss: 0.3454 - val_acc: 0.8477\n",
      "Epoch 1139/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8470 - val_loss: 0.3451 - val_acc: 0.8473\n",
      "Epoch 1140/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3414 - acc: 0.8467 - val_loss: 0.3463 - val_acc: 0.8453\n",
      "Epoch 1141/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8466 - val_loss: 0.3462 - val_acc: 0.8478\n",
      "Epoch 1142/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3415 - acc: 0.8465 - val_loss: 0.3449 - val_acc: 0.8479\n",
      "Epoch 1143/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8459 - val_loss: 0.3494 - val_acc: 0.8450\n",
      "Epoch 1144/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3423 - acc: 0.8459 - val_loss: 0.3447 - val_acc: 0.8466\n",
      "Epoch 1145/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8474 - val_loss: 0.3520 - val_acc: 0.8412\n",
      "Epoch 1146/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3412 - acc: 0.8473 - val_loss: 0.3445 - val_acc: 0.8452\n",
      "Epoch 1147/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8471 - val_loss: 0.3449 - val_acc: 0.8490\n",
      "Epoch 1148/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8472 - val_loss: 0.3484 - val_acc: 0.8447\n",
      "Epoch 1149/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3415 - acc: 0.8477 - val_loss: 0.3458 - val_acc: 0.8472\n",
      "Epoch 1150/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8471 - val_loss: 0.3466 - val_acc: 0.8463\n",
      "Epoch 1151/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8464 - val_loss: 0.3445 - val_acc: 0.8484\n",
      "Epoch 1152/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3414 - acc: 0.8469 - val_loss: 0.3442 - val_acc: 0.8482\n",
      "Epoch 1153/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8468 - val_loss: 0.3496 - val_acc: 0.8458\n",
      "Epoch 1154/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8467 - val_loss: 0.3454 - val_acc: 0.8479\n",
      "Epoch 1155/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8461 - val_loss: 0.3461 - val_acc: 0.8446\n",
      "Epoch 1156/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.8447 - val_loss: 0.3477 - val_acc: 0.8456\n",
      "Epoch 1157/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8472 - val_loss: 0.3467 - val_acc: 0.8474\n",
      "Epoch 1158/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8468 - val_loss: 0.3471 - val_acc: 0.8458\n",
      "Epoch 1159/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8475 - val_loss: 0.3484 - val_acc: 0.8447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1160/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3422 - acc: 0.8466 - val_loss: 0.3471 - val_acc: 0.8460\n",
      "Epoch 1161/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8470 - val_loss: 0.3451 - val_acc: 0.8479\n",
      "Epoch 1162/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8467 - val_loss: 0.3433 - val_acc: 0.8476\n",
      "Epoch 1163/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3419 - acc: 0.8463 - val_loss: 0.3466 - val_acc: 0.8444\n",
      "Epoch 1164/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8461 - val_loss: 0.3488 - val_acc: 0.8424\n",
      "Epoch 1165/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8455 - val_loss: 0.3455 - val_acc: 0.8450\n",
      "Epoch 1166/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3414 - acc: 0.8458 - val_loss: 0.3475 - val_acc: 0.8447\n",
      "Epoch 1167/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8468 - val_loss: 0.3478 - val_acc: 0.8488\n",
      "Epoch 1168/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8466 - val_loss: 0.3460 - val_acc: 0.8466\n",
      "Epoch 1169/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8484 - val_loss: 0.3431 - val_acc: 0.8479\n",
      "Epoch 1170/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8471 - val_loss: 0.3480 - val_acc: 0.8458\n",
      "Epoch 1171/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8464 - val_loss: 0.3450 - val_acc: 0.8482\n",
      "Epoch 1172/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8471 - val_loss: 0.3451 - val_acc: 0.8473\n",
      "Epoch 1173/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3423 - acc: 0.8467 - val_loss: 0.3457 - val_acc: 0.8453\n",
      "Epoch 1174/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3416 - acc: 0.8466 - val_loss: 0.3469 - val_acc: 0.8466\n",
      "Epoch 1175/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3414 - acc: 0.8459 - val_loss: 0.3449 - val_acc: 0.8472\n",
      "Epoch 1176/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8467 - val_loss: 0.3457 - val_acc: 0.8477\n",
      "Epoch 1177/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3416 - acc: 0.8475 - val_loss: 0.3470 - val_acc: 0.8450\n",
      "Epoch 1178/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8485 - val_loss: 0.3508 - val_acc: 0.8440\n",
      "Epoch 1179/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8474 - val_loss: 0.3455 - val_acc: 0.8471\n",
      "Epoch 1180/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8467 - val_loss: 0.3471 - val_acc: 0.8453\n",
      "Epoch 1181/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8466 - val_loss: 0.3443 - val_acc: 0.8475\n",
      "Epoch 1182/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8465 - val_loss: 0.3466 - val_acc: 0.8461\n",
      "Epoch 1183/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3413 - acc: 0.8469 - val_loss: 0.3459 - val_acc: 0.8467\n",
      "Epoch 1184/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8470 - val_loss: 0.3456 - val_acc: 0.8473\n",
      "Epoch 1185/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8464 - val_loss: 0.3423 - val_acc: 0.8474\n",
      "Epoch 1186/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3417 - acc: 0.8459 - val_loss: 0.3461 - val_acc: 0.8460\n",
      "Epoch 1187/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3411 - acc: 0.8480 - val_loss: 0.3447 - val_acc: 0.8475\n",
      "Epoch 1188/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.8465 - val_loss: 0.3448 - val_acc: 0.8461\n",
      "Epoch 1189/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8464 - val_loss: 0.3435 - val_acc: 0.8476\n",
      "Epoch 1190/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8470 - val_loss: 0.3469 - val_acc: 0.8459\n",
      "Epoch 1191/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3406 - acc: 0.8468 - val_loss: 0.3529 - val_acc: 0.8429\n",
      "Epoch 1192/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3409 - acc: 0.8476 - val_loss: 0.3458 - val_acc: 0.8466\n",
      "Epoch 1193/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3410 - acc: 0.8469 - val_loss: 0.3467 - val_acc: 0.8435\n",
      "Epoch 1194/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8472 - val_loss: 0.3553 - val_acc: 0.8414\n",
      "Epoch 1195/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8482 - val_loss: 0.3526 - val_acc: 0.8442\n",
      "Epoch 1196/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3426 - acc: 0.8471 - val_loss: 0.3456 - val_acc: 0.8472\n",
      "Epoch 1197/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8477 - val_loss: 0.3460 - val_acc: 0.8470\n",
      "Epoch 1198/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3418 - acc: 0.8471 - val_loss: 0.3449 - val_acc: 0.8458\n",
      "Epoch 1199/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8469 - val_loss: 0.3445 - val_acc: 0.8492\n",
      "Epoch 1200/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3412 - acc: 0.8471 - val_loss: 0.3450 - val_acc: 0.8458\n",
      "Epoch 1201/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3421 - acc: 0.8467 - val_loss: 0.3450 - val_acc: 0.8471\n",
      "Epoch 1202/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3413 - acc: 0.8472 - val_loss: 0.3454 - val_acc: 0.8465\n",
      "Epoch 1203/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8471 - val_loss: 0.3452 - val_acc: 0.8458\n",
      "Epoch 1204/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8483 - val_loss: 0.3457 - val_acc: 0.8490\n",
      "Epoch 1205/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3417 - acc: 0.8477 - val_loss: 0.3450 - val_acc: 0.8457\n",
      "Epoch 1206/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8462 - val_loss: 0.3449 - val_acc: 0.8466\n",
      "Epoch 1207/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3412 - acc: 0.8462 - val_loss: 0.3454 - val_acc: 0.8464\n",
      "Epoch 1208/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8472 - val_loss: 0.3442 - val_acc: 0.8468\n",
      "Epoch 1209/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3417 - acc: 0.8472 - val_loss: 0.3472 - val_acc: 0.8461\n",
      "Epoch 1210/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3411 - acc: 0.8474 - val_loss: 0.3492 - val_acc: 0.8424\n",
      "Epoch 1211/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8478 - val_loss: 0.3458 - val_acc: 0.8474\n",
      "Epoch 1212/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8479 - val_loss: 0.3528 - val_acc: 0.8393\n",
      "Epoch 1213/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8465 - val_loss: 0.3493 - val_acc: 0.8459\n",
      "Epoch 1214/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3407 - acc: 0.8480 - val_loss: 0.3443 - val_acc: 0.8482\n",
      "Epoch 1215/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8468 - val_loss: 0.3457 - val_acc: 0.8460\n",
      "Epoch 1216/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8478 - val_loss: 0.3497 - val_acc: 0.8428\n",
      "Epoch 1217/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8471 - val_loss: 0.3470 - val_acc: 0.8466\n",
      "Epoch 1218/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8472 - val_loss: 0.3465 - val_acc: 0.8473\n",
      "Epoch 1219/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8460 - val_loss: 0.3457 - val_acc: 0.8485\n",
      "Epoch 1220/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3410 - acc: 0.8478 - val_loss: 0.3441 - val_acc: 0.8490\n",
      "Epoch 1221/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8469 - val_loss: 0.3452 - val_acc: 0.8440\n",
      "Epoch 1222/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8479 - val_loss: 0.3514 - val_acc: 0.8453\n",
      "Epoch 1223/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8465 - val_loss: 0.3442 - val_acc: 0.8480\n",
      "Epoch 1224/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8461 - val_loss: 0.3497 - val_acc: 0.8420\n",
      "Epoch 1225/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3417 - acc: 0.8471 - val_loss: 0.3448 - val_acc: 0.8466\n",
      "Epoch 1226/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8468 - val_loss: 0.3484 - val_acc: 0.8437\n",
      "Epoch 1227/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8468 - val_loss: 0.3459 - val_acc: 0.8458\n",
      "Epoch 1228/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3409 - acc: 0.8461 - val_loss: 0.3445 - val_acc: 0.8471\n",
      "Epoch 1229/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3408 - acc: 0.8464 - val_loss: 0.3446 - val_acc: 0.8472\n",
      "Epoch 1230/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8466 - val_loss: 0.3418 - val_acc: 0.8493\n",
      "Epoch 1231/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8482 - val_loss: 0.3511 - val_acc: 0.8398\n",
      "Epoch 1232/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8464 - val_loss: 0.3448 - val_acc: 0.8479\n",
      "Epoch 1233/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8468 - val_loss: 0.3431 - val_acc: 0.8478\n",
      "Epoch 1234/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8467 - val_loss: 0.3449 - val_acc: 0.8474\n",
      "Epoch 1235/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8470 - val_loss: 0.3465 - val_acc: 0.8448\n",
      "Epoch 1236/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8468 - val_loss: 0.3422 - val_acc: 0.8490\n",
      "Epoch 1237/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8463 - val_loss: 0.3459 - val_acc: 0.8481\n",
      "Epoch 1238/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8473 - val_loss: 0.3489 - val_acc: 0.8448\n",
      "Epoch 1239/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8459 - val_loss: 0.3459 - val_acc: 0.8474\n",
      "Epoch 1240/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8466 - val_loss: 0.3463 - val_acc: 0.8487\n",
      "Epoch 1241/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3409 - acc: 0.8471 - val_loss: 0.3447 - val_acc: 0.8478\n",
      "Epoch 1242/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3404 - acc: 0.8466 - val_loss: 0.3519 - val_acc: 0.8431\n",
      "Epoch 1243/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3400 - acc: 0.8485 - val_loss: 0.3459 - val_acc: 0.8440\n",
      "Epoch 1244/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3418 - acc: 0.8464 - val_loss: 0.3445 - val_acc: 0.8474\n",
      "Epoch 1245/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3404 - acc: 0.8476 - val_loss: 0.3464 - val_acc: 0.8463\n",
      "Epoch 1246/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8469 - val_loss: 0.3442 - val_acc: 0.8471\n",
      "Epoch 1247/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8468 - val_loss: 0.3446 - val_acc: 0.8474\n",
      "Epoch 1248/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8461 - val_loss: 0.3469 - val_acc: 0.8453\n",
      "Epoch 1249/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8470 - val_loss: 0.3440 - val_acc: 0.8495\n",
      "Epoch 1250/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8453 - val_loss: 0.3452 - val_acc: 0.8472\n",
      "Epoch 1251/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8479 - val_loss: 0.3450 - val_acc: 0.8468\n",
      "Epoch 1252/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8470 - val_loss: 0.3443 - val_acc: 0.8471\n",
      "Epoch 1253/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8472 - val_loss: 0.3453 - val_acc: 0.8465\n",
      "Epoch 1254/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8456 - val_loss: 0.3453 - val_acc: 0.8469\n",
      "Epoch 1255/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8469 - val_loss: 0.3463 - val_acc: 0.8459\n",
      "Epoch 1256/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8476 - val_loss: 0.3449 - val_acc: 0.8465\n",
      "Epoch 1257/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8466 - val_loss: 0.3447 - val_acc: 0.8474\n",
      "Epoch 1258/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8473 - val_loss: 0.3479 - val_acc: 0.8440\n",
      "Epoch 1259/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8464 - val_loss: 0.3452 - val_acc: 0.8469\n",
      "Epoch 1260/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8473 - val_loss: 0.3460 - val_acc: 0.8476\n",
      "Epoch 1261/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8466 - val_loss: 0.3431 - val_acc: 0.8481\n",
      "Epoch 1262/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8464 - val_loss: 0.3468 - val_acc: 0.8441\n",
      "Epoch 1263/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8466 - val_loss: 0.3450 - val_acc: 0.8457\n",
      "Epoch 1264/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8473 - val_loss: 0.3468 - val_acc: 0.8458\n",
      "Epoch 1265/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8472 - val_loss: 0.3460 - val_acc: 0.8457\n",
      "Epoch 1266/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8467 - val_loss: 0.3486 - val_acc: 0.8435\n",
      "Epoch 1267/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8478 - val_loss: 0.3461 - val_acc: 0.8471\n",
      "Epoch 1268/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8472 - val_loss: 0.3462 - val_acc: 0.8470\n",
      "Epoch 1269/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8467 - val_loss: 0.3473 - val_acc: 0.8461\n",
      "Epoch 1270/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8474 - val_loss: 0.3512 - val_acc: 0.8429\n",
      "Epoch 1271/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8467 - val_loss: 0.3465 - val_acc: 0.8473\n",
      "Epoch 1272/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8467 - val_loss: 0.3450 - val_acc: 0.8455\n",
      "Epoch 1273/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8457 - val_loss: 0.3458 - val_acc: 0.8470\n",
      "Epoch 1274/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8464 - val_loss: 0.3516 - val_acc: 0.8422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1275/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8469 - val_loss: 0.3507 - val_acc: 0.8411\n",
      "Epoch 1276/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8470 - val_loss: 0.3464 - val_acc: 0.8461\n",
      "Epoch 1277/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8465 - val_loss: 0.3449 - val_acc: 0.8476\n",
      "Epoch 1278/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8463 - val_loss: 0.3446 - val_acc: 0.8474\n",
      "Epoch 1279/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8466 - val_loss: 0.3471 - val_acc: 0.8462\n",
      "Epoch 1280/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8488 - val_loss: 0.3467 - val_acc: 0.8451\n",
      "Epoch 1281/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8469 - val_loss: 0.3513 - val_acc: 0.8426\n",
      "Epoch 1282/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8477 - val_loss: 0.3465 - val_acc: 0.8466\n",
      "Epoch 1283/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8475 - val_loss: 0.3454 - val_acc: 0.8464\n",
      "Epoch 1284/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8463 - val_loss: 0.3449 - val_acc: 0.8466\n",
      "Epoch 1285/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8465 - val_loss: 0.3523 - val_acc: 0.8425\n",
      "Epoch 1286/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8478 - val_loss: 0.3443 - val_acc: 0.8467\n",
      "Epoch 1287/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8465 - val_loss: 0.3448 - val_acc: 0.8474\n",
      "Epoch 1288/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8470 - val_loss: 0.3462 - val_acc: 0.8451\n",
      "Epoch 1289/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8466 - val_loss: 0.3491 - val_acc: 0.8460\n",
      "Epoch 1290/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8474 - val_loss: 0.3459 - val_acc: 0.8470\n",
      "Epoch 1291/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8466 - val_loss: 0.3460 - val_acc: 0.8470\n",
      "Epoch 1292/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8468 - val_loss: 0.3458 - val_acc: 0.8456\n",
      "Epoch 1293/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8462 - val_loss: 0.3487 - val_acc: 0.8427\n",
      "Epoch 1294/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8460 - val_loss: 0.3464 - val_acc: 0.8463\n",
      "Epoch 1295/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8478 - val_loss: 0.3490 - val_acc: 0.8466\n",
      "Epoch 1296/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8470 - val_loss: 0.3449 - val_acc: 0.8476\n",
      "Epoch 1297/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8465 - val_loss: 0.3462 - val_acc: 0.8463\n",
      "Epoch 1298/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8469 - val_loss: 0.3479 - val_acc: 0.8464\n",
      "Epoch 1299/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3405 - acc: 0.8469 - val_loss: 0.3494 - val_acc: 0.8445\n",
      "Epoch 1300/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8468 - val_loss: 0.3436 - val_acc: 0.8482\n",
      "Epoch 1301/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8469 - val_loss: 0.3484 - val_acc: 0.8458\n",
      "Epoch 1302/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8462 - val_loss: 0.3451 - val_acc: 0.8462\n",
      "Epoch 1303/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8465 - val_loss: 0.3466 - val_acc: 0.8453\n",
      "Epoch 1304/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8467 - val_loss: 0.3486 - val_acc: 0.8461\n",
      "Epoch 1305/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8469 - val_loss: 0.3448 - val_acc: 0.8482\n",
      "Epoch 1306/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3415 - acc: 0.8461 - val_loss: 0.3448 - val_acc: 0.8477\n",
      "Epoch 1307/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8475 - val_loss: 0.3471 - val_acc: 0.8448\n",
      "Epoch 1308/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8464 - val_loss: 0.3519 - val_acc: 0.8396\n",
      "Epoch 1309/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8466 - val_loss: 0.3452 - val_acc: 0.8468\n",
      "Epoch 1310/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8468 - val_loss: 0.3456 - val_acc: 0.8471\n",
      "Epoch 1311/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8464 - val_loss: 0.3448 - val_acc: 0.8469\n",
      "Epoch 1312/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8464 - val_loss: 0.3476 - val_acc: 0.8456\n",
      "Epoch 1313/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8473 - val_loss: 0.3437 - val_acc: 0.8468\n",
      "Epoch 1314/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8458 - val_loss: 0.3467 - val_acc: 0.8472\n",
      "Epoch 1315/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3410 - acc: 0.8475 - val_loss: 0.3479 - val_acc: 0.8471\n",
      "Epoch 1316/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8466 - val_loss: 0.3466 - val_acc: 0.8472\n",
      "Epoch 1317/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3404 - acc: 0.8482 - val_loss: 0.3450 - val_acc: 0.8469\n",
      "Epoch 1318/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8471 - val_loss: 0.3503 - val_acc: 0.8425\n",
      "Epoch 1319/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3411 - acc: 0.8467 - val_loss: 0.3488 - val_acc: 0.8462\n",
      "Epoch 1320/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8478 - val_loss: 0.3431 - val_acc: 0.8481\n",
      "Epoch 1321/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8470 - val_loss: 0.3466 - val_acc: 0.8448\n",
      "Epoch 1322/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3408 - acc: 0.8462 - val_loss: 0.3500 - val_acc: 0.8425\n",
      "Epoch 1323/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8473 - val_loss: 0.3448 - val_acc: 0.8480\n",
      "Epoch 1324/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8473 - val_loss: 0.3450 - val_acc: 0.8474\n",
      "Epoch 1325/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8478 - val_loss: 0.3444 - val_acc: 0.8469\n",
      "Epoch 1326/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8475 - val_loss: 0.3483 - val_acc: 0.8434\n",
      "Epoch 1327/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8474 - val_loss: 0.3474 - val_acc: 0.8434\n",
      "Epoch 1328/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8470 - val_loss: 0.3453 - val_acc: 0.8477\n",
      "Epoch 1329/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3407 - acc: 0.8469 - val_loss: 0.3450 - val_acc: 0.8484\n",
      "Epoch 1330/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3405 - acc: 0.8464 - val_loss: 0.3483 - val_acc: 0.8467\n",
      "Epoch 1331/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8468 - val_loss: 0.3479 - val_acc: 0.8464\n",
      "Epoch 1332/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3408 - acc: 0.8465 - val_loss: 0.3538 - val_acc: 0.8423\n",
      "Epoch 1333/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8478 - val_loss: 0.3456 - val_acc: 0.8462\n",
      "Epoch 1334/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8467 - val_loss: 0.3512 - val_acc: 0.8399\n",
      "Epoch 1335/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8473 - val_loss: 0.3479 - val_acc: 0.8447\n",
      "Epoch 1336/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8482 - val_loss: 0.3474 - val_acc: 0.8473\n",
      "Epoch 1337/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8473 - val_loss: 0.3452 - val_acc: 0.8472\n",
      "Epoch 1338/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8482 - val_loss: 0.3468 - val_acc: 0.8448\n",
      "Epoch 1339/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8474 - val_loss: 0.3455 - val_acc: 0.8469\n",
      "Epoch 1340/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8484 - val_loss: 0.3444 - val_acc: 0.8478\n",
      "Epoch 1341/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8463 - val_loss: 0.3457 - val_acc: 0.8454\n",
      "Epoch 1342/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8478 - val_loss: 0.3445 - val_acc: 0.8469\n",
      "Epoch 1343/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3407 - acc: 0.8458 - val_loss: 0.3459 - val_acc: 0.8450\n",
      "Epoch 1344/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8466 - val_loss: 0.3495 - val_acc: 0.8448\n",
      "Epoch 1345/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.8456 - val_loss: 0.3439 - val_acc: 0.8487\n",
      "Epoch 1346/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8471 - val_loss: 0.3452 - val_acc: 0.8480\n",
      "Epoch 1347/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8484 - val_loss: 0.3528 - val_acc: 0.8427\n",
      "Epoch 1348/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8480 - val_loss: 0.3435 - val_acc: 0.8477\n",
      "Epoch 1349/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8471 - val_loss: 0.3445 - val_acc: 0.8486\n",
      "Epoch 1350/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8472 - val_loss: 0.3455 - val_acc: 0.8468\n",
      "Epoch 1351/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8469 - val_loss: 0.3458 - val_acc: 0.8453\n",
      "Epoch 1352/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8466 - val_loss: 0.3494 - val_acc: 0.8427\n",
      "Epoch 1353/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8448 - val_loss: 0.3453 - val_acc: 0.8477\n",
      "Epoch 1354/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8462 - val_loss: 0.3534 - val_acc: 0.8426\n",
      "Epoch 1355/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8446 - val_loss: 0.3450 - val_acc: 0.8470\n",
      "Epoch 1356/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8464 - val_loss: 0.3499 - val_acc: 0.8421\n",
      "Epoch 1357/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8476 - val_loss: 0.3458 - val_acc: 0.8463\n",
      "Epoch 1358/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8460 - val_loss: 0.3446 - val_acc: 0.8484\n",
      "Epoch 1359/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8461 - val_loss: 0.3461 - val_acc: 0.8449\n",
      "Epoch 1360/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8469 - val_loss: 0.3480 - val_acc: 0.8456\n",
      "Epoch 1361/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8480 - val_loss: 0.3460 - val_acc: 0.8455\n",
      "Epoch 1362/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8479 - val_loss: 0.3499 - val_acc: 0.8435\n",
      "Epoch 1363/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8478 - val_loss: 0.3484 - val_acc: 0.8435\n",
      "Epoch 1364/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3416 - acc: 0.8478 - val_loss: 0.3475 - val_acc: 0.8452\n",
      "Epoch 1365/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8475 - val_loss: 0.3452 - val_acc: 0.8449\n",
      "Epoch 1366/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8477 - val_loss: 0.3444 - val_acc: 0.8477\n",
      "Epoch 1367/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8464 - val_loss: 0.3459 - val_acc: 0.8456\n",
      "Epoch 1368/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8474 - val_loss: 0.3476 - val_acc: 0.8439\n",
      "Epoch 1369/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3405 - acc: 0.8467 - val_loss: 0.3469 - val_acc: 0.8473\n",
      "Epoch 1370/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3412 - acc: 0.8457 - val_loss: 0.3472 - val_acc: 0.8429\n",
      "Epoch 1371/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8470 - val_loss: 0.3466 - val_acc: 0.8471\n",
      "Epoch 1372/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3414 - acc: 0.8475 - val_loss: 0.3452 - val_acc: 0.8462\n",
      "Epoch 1373/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8475 - val_loss: 0.3481 - val_acc: 0.8454\n",
      "Epoch 1374/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3412 - acc: 0.8467 - val_loss: 0.3447 - val_acc: 0.8490\n",
      "Epoch 1375/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3412 - acc: 0.8460 - val_loss: 0.3459 - val_acc: 0.8467\n",
      "Epoch 1376/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3409 - acc: 0.8458 - val_loss: 0.3446 - val_acc: 0.8460\n",
      "Epoch 1377/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3408 - acc: 0.8468 - val_loss: 0.3491 - val_acc: 0.8437\n",
      "Epoch 1378/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3403 - acc: 0.8472 - val_loss: 0.3479 - val_acc: 0.8440\n",
      "Epoch 1379/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3412 - acc: 0.8464 - val_loss: 0.3446 - val_acc: 0.8495\n",
      "Epoch 1380/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3406 - acc: 0.8463 - val_loss: 0.3441 - val_acc: 0.8471\n",
      "Epoch 1381/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3404 - acc: 0.8481 - val_loss: 0.3449 - val_acc: 0.8484\n",
      "Epoch 1382/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3400 - acc: 0.8481 - val_loss: 0.3442 - val_acc: 0.8460\n",
      "Epoch 1383/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3406 - acc: 0.8470 - val_loss: 0.3440 - val_acc: 0.8479\n",
      "Epoch 1384/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3404 - acc: 0.8457 - val_loss: 0.3484 - val_acc: 0.8479\n",
      "Epoch 1385/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3410 - acc: 0.8464 - val_loss: 0.3468 - val_acc: 0.8445\n",
      "Epoch 1386/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3405 - acc: 0.8476 - val_loss: 0.3515 - val_acc: 0.8403\n",
      "Epoch 1387/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3407 - acc: 0.8480 - val_loss: 0.3449 - val_acc: 0.8456\n",
      "Epoch 1388/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3407 - acc: 0.8470 - val_loss: 0.3465 - val_acc: 0.8442\n",
      "Epoch 1389/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3403 - acc: 0.8468 - val_loss: 0.3471 - val_acc: 0.8442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1390/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3402 - acc: 0.8471 - val_loss: 0.3457 - val_acc: 0.8469\n",
      "Epoch 1391/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3408 - acc: 0.8474 - val_loss: 0.3443 - val_acc: 0.8476\n",
      "Epoch 1392/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3407 - acc: 0.8479 - val_loss: 0.3441 - val_acc: 0.8496\n",
      "Epoch 1393/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3409 - acc: 0.8466 - val_loss: 0.3438 - val_acc: 0.8474\n",
      "Epoch 1394/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8479 - val_loss: 0.3448 - val_acc: 0.8466\n",
      "Epoch 1395/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3403 - acc: 0.8472 - val_loss: 0.3458 - val_acc: 0.8463\n",
      "Epoch 1396/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8471 - val_loss: 0.3432 - val_acc: 0.8478\n",
      "Epoch 1397/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3405 - acc: 0.8462 - val_loss: 0.3497 - val_acc: 0.8445\n",
      "Epoch 1398/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3402 - acc: 0.8461 - val_loss: 0.3477 - val_acc: 0.8446\n",
      "Epoch 1399/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8470 - val_loss: 0.3450 - val_acc: 0.8453\n",
      "Epoch 1400/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3406 - acc: 0.8468 - val_loss: 0.3475 - val_acc: 0.8442\n",
      "Epoch 1401/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3401 - acc: 0.8469 - val_loss: 0.3436 - val_acc: 0.8458\n",
      "Epoch 1402/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8481 - val_loss: 0.3481 - val_acc: 0.8435\n",
      "Epoch 1403/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8479 - val_loss: 0.3466 - val_acc: 0.8456\n",
      "Epoch 1404/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8480 - val_loss: 0.3437 - val_acc: 0.8472\n",
      "Epoch 1405/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8472 - val_loss: 0.3464 - val_acc: 0.8455\n",
      "Epoch 1406/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8477 - val_loss: 0.3465 - val_acc: 0.8442\n",
      "Epoch 1407/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8472 - val_loss: 0.3461 - val_acc: 0.8436\n",
      "Epoch 1408/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8474 - val_loss: 0.3458 - val_acc: 0.8479\n",
      "Epoch 1409/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8462 - val_loss: 0.3440 - val_acc: 0.8484\n",
      "Epoch 1410/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8469 - val_loss: 0.3470 - val_acc: 0.8476\n",
      "Epoch 1411/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3405 - acc: 0.8479 - val_loss: 0.3458 - val_acc: 0.8476\n",
      "Epoch 1412/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3401 - acc: 0.8478 - val_loss: 0.3437 - val_acc: 0.8474\n",
      "Epoch 1413/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3404 - acc: 0.8463 - val_loss: 0.3461 - val_acc: 0.8448\n",
      "Epoch 1414/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8465 - val_loss: 0.3453 - val_acc: 0.8466\n",
      "Epoch 1415/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8470 - val_loss: 0.3434 - val_acc: 0.8476\n",
      "Epoch 1416/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8470 - val_loss: 0.3510 - val_acc: 0.8430\n",
      "Epoch 1417/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3416 - acc: 0.8473 - val_loss: 0.3439 - val_acc: 0.8461\n",
      "Epoch 1418/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3402 - acc: 0.8483 - val_loss: 0.3477 - val_acc: 0.8442\n",
      "Epoch 1419/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3403 - acc: 0.8465 - val_loss: 0.3536 - val_acc: 0.8409\n",
      "Epoch 1420/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8477 - val_loss: 0.3478 - val_acc: 0.8448\n",
      "Epoch 1421/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8471 - val_loss: 0.3501 - val_acc: 0.8458\n",
      "Epoch 1422/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8476 - val_loss: 0.3447 - val_acc: 0.8448\n",
      "Epoch 1423/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8474 - val_loss: 0.3460 - val_acc: 0.8461\n",
      "Epoch 1424/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8474 - val_loss: 0.3456 - val_acc: 0.8449\n",
      "Epoch 1425/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3404 - acc: 0.8476 - val_loss: 0.3473 - val_acc: 0.8456\n",
      "Epoch 1426/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3405 - acc: 0.8457 - val_loss: 0.3458 - val_acc: 0.8442\n",
      "Epoch 1427/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3406 - acc: 0.8479 - val_loss: 0.3481 - val_acc: 0.8446\n",
      "Epoch 1428/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3408 - acc: 0.8461 - val_loss: 0.3458 - val_acc: 0.8465\n",
      "Epoch 1429/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3402 - acc: 0.8471 - val_loss: 0.3452 - val_acc: 0.8463\n",
      "Epoch 1430/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8478 - val_loss: 0.3456 - val_acc: 0.8477\n",
      "Epoch 1431/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8468 - val_loss: 0.3514 - val_acc: 0.8419\n",
      "Epoch 1432/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8470 - val_loss: 0.3479 - val_acc: 0.8445\n",
      "Epoch 1433/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8465 - val_loss: 0.3452 - val_acc: 0.8479\n",
      "Epoch 1434/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8477 - val_loss: 0.3442 - val_acc: 0.8477\n",
      "Epoch 1435/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8475 - val_loss: 0.3513 - val_acc: 0.8435\n",
      "Epoch 1436/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3414 - acc: 0.8471 - val_loss: 0.3449 - val_acc: 0.8484\n",
      "Epoch 1437/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8476 - val_loss: 0.3440 - val_acc: 0.8473\n",
      "Epoch 1438/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8482 - val_loss: 0.3441 - val_acc: 0.8485\n",
      "Epoch 1439/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8476 - val_loss: 0.3453 - val_acc: 0.8476\n",
      "Epoch 1440/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8470 - val_loss: 0.3504 - val_acc: 0.8427\n",
      "Epoch 1441/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8475 - val_loss: 0.3448 - val_acc: 0.8445\n",
      "Epoch 1442/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8479 - val_loss: 0.3452 - val_acc: 0.8463\n",
      "Epoch 1443/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8478 - val_loss: 0.3459 - val_acc: 0.8461\n",
      "Epoch 1444/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8476 - val_loss: 0.3436 - val_acc: 0.8467\n",
      "Epoch 1445/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8479 - val_loss: 0.3444 - val_acc: 0.8486\n",
      "Epoch 1446/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3398 - acc: 0.8481 - val_loss: 0.3458 - val_acc: 0.8479\n",
      "Epoch 1447/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8473 - val_loss: 0.3451 - val_acc: 0.8463\n",
      "Epoch 1448/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8469 - val_loss: 0.3430 - val_acc: 0.8485\n",
      "Epoch 1449/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3408 - acc: 0.8473 - val_loss: 0.3454 - val_acc: 0.8466\n",
      "Epoch 1450/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3400 - acc: 0.8472 - val_loss: 0.3438 - val_acc: 0.8486\n",
      "Epoch 1451/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8451 - val_loss: 0.3455 - val_acc: 0.8453\n",
      "Epoch 1452/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8470 - val_loss: 0.3469 - val_acc: 0.8445\n",
      "Epoch 1453/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8472 - val_loss: 0.3518 - val_acc: 0.8422\n",
      "Epoch 1454/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3403 - acc: 0.8463 - val_loss: 0.3444 - val_acc: 0.8473\n",
      "Epoch 1455/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3413 - acc: 0.8475 - val_loss: 0.3532 - val_acc: 0.8451\n",
      "Epoch 1456/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3408 - acc: 0.8470 - val_loss: 0.3483 - val_acc: 0.8466\n",
      "Epoch 1457/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8470 - val_loss: 0.3446 - val_acc: 0.8478\n",
      "Epoch 1458/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3396 - acc: 0.8474 - val_loss: 0.3469 - val_acc: 0.8470\n",
      "Epoch 1459/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8460 - val_loss: 0.3446 - val_acc: 0.8487\n",
      "Epoch 1460/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8470 - val_loss: 0.3473 - val_acc: 0.8461\n",
      "Epoch 1461/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8457 - val_loss: 0.3472 - val_acc: 0.8469\n",
      "Epoch 1462/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8478 - val_loss: 0.3462 - val_acc: 0.8465\n",
      "Epoch 1463/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8464 - val_loss: 0.3446 - val_acc: 0.8471\n",
      "Epoch 1464/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8471 - val_loss: 0.3470 - val_acc: 0.8451\n",
      "Epoch 1465/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8488 - val_loss: 0.3490 - val_acc: 0.8423\n",
      "Epoch 1466/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8476 - val_loss: 0.3521 - val_acc: 0.8390\n",
      "Epoch 1467/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8483 - val_loss: 0.3453 - val_acc: 0.8481\n",
      "Epoch 1468/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8481 - val_loss: 0.3458 - val_acc: 0.8460\n",
      "Epoch 1469/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8478 - val_loss: 0.3452 - val_acc: 0.8468\n",
      "Epoch 1470/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8485 - val_loss: 0.3504 - val_acc: 0.8436\n",
      "Epoch 1471/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8478 - val_loss: 0.3477 - val_acc: 0.8469\n",
      "Epoch 1472/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3402 - acc: 0.8467 - val_loss: 0.3455 - val_acc: 0.8473\n",
      "Epoch 1473/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8465 - val_loss: 0.3442 - val_acc: 0.8491\n",
      "Epoch 1474/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3402 - acc: 0.8470 - val_loss: 0.3461 - val_acc: 0.8484\n",
      "Epoch 1475/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3410 - acc: 0.8464 - val_loss: 0.3451 - val_acc: 0.8461\n",
      "Epoch 1476/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8469 - val_loss: 0.3454 - val_acc: 0.8465\n",
      "Epoch 1477/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3405 - acc: 0.8467 - val_loss: 0.3490 - val_acc: 0.8400\n",
      "Epoch 1478/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8469 - val_loss: 0.3450 - val_acc: 0.8456\n",
      "Epoch 1479/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8461 - val_loss: 0.3500 - val_acc: 0.8445\n",
      "Epoch 1480/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8486 - val_loss: 0.3446 - val_acc: 0.8453\n",
      "Epoch 1481/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8473 - val_loss: 0.3458 - val_acc: 0.8484\n",
      "Epoch 1482/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8470 - val_loss: 0.3470 - val_acc: 0.8430\n",
      "Epoch 1483/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8481 - val_loss: 0.3513 - val_acc: 0.8436\n",
      "Epoch 1484/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8478 - val_loss: 0.3456 - val_acc: 0.8457\n",
      "Epoch 1485/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3417 - acc: 0.8466 - val_loss: 0.3452 - val_acc: 0.8458\n",
      "Epoch 1486/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8479 - val_loss: 0.3444 - val_acc: 0.8469\n",
      "Epoch 1487/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8483 - val_loss: 0.3451 - val_acc: 0.8461\n",
      "Epoch 1488/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8482 - val_loss: 0.3494 - val_acc: 0.8432\n",
      "Epoch 1489/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8482 - val_loss: 0.3442 - val_acc: 0.8491\n",
      "Epoch 1490/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8470 - val_loss: 0.3527 - val_acc: 0.8395\n",
      "Epoch 1491/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8475 - val_loss: 0.3467 - val_acc: 0.8460\n",
      "Epoch 1492/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8472 - val_loss: 0.3486 - val_acc: 0.8466\n",
      "Epoch 1493/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8465 - val_loss: 0.3492 - val_acc: 0.8441\n",
      "Epoch 1494/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8480 - val_loss: 0.3453 - val_acc: 0.8463\n",
      "Epoch 1495/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8469 - val_loss: 0.3459 - val_acc: 0.8474\n",
      "Epoch 1496/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8469 - val_loss: 0.3459 - val_acc: 0.8452\n",
      "Epoch 1497/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8471 - val_loss: 0.3463 - val_acc: 0.8466\n",
      "Epoch 1498/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8470 - val_loss: 0.3456 - val_acc: 0.8469\n",
      "Epoch 1499/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8478 - val_loss: 0.3451 - val_acc: 0.8456\n",
      "Epoch 1500/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8473 - val_loss: 0.3506 - val_acc: 0.8422\n",
      "Epoch 1501/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8470 - val_loss: 0.3435 - val_acc: 0.8476\n",
      "Epoch 1502/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8475 - val_loss: 0.3484 - val_acc: 0.8446\n",
      "Epoch 1503/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8468 - val_loss: 0.3437 - val_acc: 0.8467\n",
      "Epoch 1504/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8482 - val_loss: 0.3459 - val_acc: 0.8435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1505/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8460 - val_loss: 0.3457 - val_acc: 0.8443\n",
      "Epoch 1506/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3405 - acc: 0.8469 - val_loss: 0.3450 - val_acc: 0.8463\n",
      "Epoch 1507/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8474 - val_loss: 0.3495 - val_acc: 0.8430\n",
      "Epoch 1508/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3401 - acc: 0.8470 - val_loss: 0.3468 - val_acc: 0.8442\n",
      "Epoch 1509/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3404 - acc: 0.8466 - val_loss: 0.3463 - val_acc: 0.8460\n",
      "Epoch 1510/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3404 - acc: 0.8471 - val_loss: 0.3460 - val_acc: 0.8450\n",
      "Epoch 1511/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3402 - acc: 0.8475 - val_loss: 0.3451 - val_acc: 0.8466\n",
      "Epoch 1512/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3404 - acc: 0.8475 - val_loss: 0.3482 - val_acc: 0.8465\n",
      "Epoch 1513/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3401 - acc: 0.8478 - val_loss: 0.3486 - val_acc: 0.8448\n",
      "Epoch 1514/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8481 - val_loss: 0.3453 - val_acc: 0.8477\n",
      "Epoch 1515/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8473 - val_loss: 0.3473 - val_acc: 0.8444\n",
      "Epoch 1516/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8477 - val_loss: 0.3508 - val_acc: 0.8445\n",
      "Epoch 1517/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8466 - val_loss: 0.3467 - val_acc: 0.8453\n",
      "Epoch 1518/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8472 - val_loss: 0.3477 - val_acc: 0.8445\n",
      "Epoch 1519/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8485 - val_loss: 0.3486 - val_acc: 0.8435\n",
      "Epoch 1520/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8485 - val_loss: 0.3479 - val_acc: 0.8440\n",
      "Epoch 1521/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8471 - val_loss: 0.3444 - val_acc: 0.8469\n",
      "Epoch 1522/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8472 - val_loss: 0.3435 - val_acc: 0.8486\n",
      "Epoch 1523/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8474 - val_loss: 0.3439 - val_acc: 0.8464\n",
      "Epoch 1524/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8482 - val_loss: 0.3461 - val_acc: 0.8466\n",
      "Epoch 1525/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8489 - val_loss: 0.3488 - val_acc: 0.8442\n",
      "Epoch 1526/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8473 - val_loss: 0.3448 - val_acc: 0.8466\n",
      "Epoch 1527/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8474 - val_loss: 0.3502 - val_acc: 0.8431\n",
      "Epoch 1528/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8475 - val_loss: 0.3432 - val_acc: 0.8474\n",
      "Epoch 1529/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8480 - val_loss: 0.3494 - val_acc: 0.8418\n",
      "Epoch 1530/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8466 - val_loss: 0.3451 - val_acc: 0.8461\n",
      "Epoch 1531/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8467 - val_loss: 0.3457 - val_acc: 0.8474\n",
      "Epoch 1532/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8476 - val_loss: 0.3461 - val_acc: 0.8477\n",
      "Epoch 1533/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3411 - acc: 0.8484 - val_loss: 0.3495 - val_acc: 0.8430\n",
      "Epoch 1534/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8478 - val_loss: 0.3452 - val_acc: 0.8471\n",
      "Epoch 1535/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3407 - acc: 0.8479 - val_loss: 0.3454 - val_acc: 0.8478\n",
      "Epoch 1536/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8471 - val_loss: 0.3474 - val_acc: 0.8426\n",
      "Epoch 1537/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8485 - val_loss: 0.3442 - val_acc: 0.8471\n",
      "Epoch 1538/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8469 - val_loss: 0.3454 - val_acc: 0.8467\n",
      "Epoch 1539/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8490 - val_loss: 0.3441 - val_acc: 0.8469\n",
      "Epoch 1540/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8480 - val_loss: 0.3451 - val_acc: 0.8471\n",
      "Epoch 1541/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8472 - val_loss: 0.3459 - val_acc: 0.8464\n",
      "Epoch 1542/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8483 - val_loss: 0.3514 - val_acc: 0.8399\n",
      "Epoch 1543/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8466 - val_loss: 0.3465 - val_acc: 0.8468\n",
      "Epoch 1544/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8473 - val_loss: 0.3448 - val_acc: 0.8464\n",
      "Epoch 1545/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8479 - val_loss: 0.3442 - val_acc: 0.8466\n",
      "Epoch 1546/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8477 - val_loss: 0.3503 - val_acc: 0.8415\n",
      "Epoch 1547/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8480 - val_loss: 0.3470 - val_acc: 0.8455\n",
      "Epoch 1548/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8471 - val_loss: 0.3455 - val_acc: 0.8458\n",
      "Epoch 1549/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8480 - val_loss: 0.3458 - val_acc: 0.8475\n",
      "Epoch 1550/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8476 - val_loss: 0.3461 - val_acc: 0.8458\n",
      "Epoch 1551/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3403 - acc: 0.8475 - val_loss: 0.3439 - val_acc: 0.8480\n",
      "Epoch 1552/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8476 - val_loss: 0.3467 - val_acc: 0.8446\n",
      "Epoch 1553/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8472 - val_loss: 0.3468 - val_acc: 0.8471\n",
      "Epoch 1554/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3400 - acc: 0.8473 - val_loss: 0.3502 - val_acc: 0.8437\n",
      "Epoch 1555/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3403 - acc: 0.8465 - val_loss: 0.3467 - val_acc: 0.8437\n",
      "Epoch 1556/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3405 - acc: 0.8481 - val_loss: 0.3455 - val_acc: 0.8462\n",
      "Epoch 1557/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3404 - acc: 0.8467 - val_loss: 0.3447 - val_acc: 0.8452\n",
      "Epoch 1558/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3410 - acc: 0.8469 - val_loss: 0.3454 - val_acc: 0.8461\n",
      "Epoch 1559/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8480 - val_loss: 0.3451 - val_acc: 0.8445\n",
      "Epoch 1560/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8469 - val_loss: 0.3457 - val_acc: 0.8468\n",
      "Epoch 1561/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8466 - val_loss: 0.3450 - val_acc: 0.8478\n",
      "Epoch 1562/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3405 - acc: 0.8474 - val_loss: 0.3456 - val_acc: 0.8445\n",
      "Epoch 1563/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8476 - val_loss: 0.3492 - val_acc: 0.8414\n",
      "Epoch 1564/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8476 - val_loss: 0.3486 - val_acc: 0.8459\n",
      "Epoch 1565/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8461 - val_loss: 0.3460 - val_acc: 0.8464\n",
      "Epoch 1566/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8474 - val_loss: 0.3460 - val_acc: 0.8452\n",
      "Epoch 1567/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8469 - val_loss: 0.3529 - val_acc: 0.8455\n",
      "Epoch 1568/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8473 - val_loss: 0.3525 - val_acc: 0.8414\n",
      "Epoch 1569/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3400 - acc: 0.8471 - val_loss: 0.3462 - val_acc: 0.8453\n",
      "Epoch 1570/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8477 - val_loss: 0.3464 - val_acc: 0.8456\n",
      "Epoch 1571/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8487 - val_loss: 0.3459 - val_acc: 0.8453\n",
      "Epoch 1572/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8474 - val_loss: 0.3465 - val_acc: 0.8461\n",
      "Epoch 1573/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8473 - val_loss: 0.3440 - val_acc: 0.8482\n",
      "Epoch 1574/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8465 - val_loss: 0.3463 - val_acc: 0.8452\n",
      "Epoch 1575/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8474 - val_loss: 0.3453 - val_acc: 0.8481\n",
      "Epoch 1576/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8467 - val_loss: 0.3455 - val_acc: 0.8468\n",
      "Epoch 1577/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8471 - val_loss: 0.3494 - val_acc: 0.8430\n",
      "Epoch 1578/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8467 - val_loss: 0.3448 - val_acc: 0.8470\n",
      "Epoch 1579/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8485 - val_loss: 0.3469 - val_acc: 0.8443\n",
      "Epoch 1580/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8470 - val_loss: 0.3483 - val_acc: 0.8424\n",
      "Epoch 1581/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8470 - val_loss: 0.3500 - val_acc: 0.8453\n",
      "Epoch 1582/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3403 - acc: 0.8474 - val_loss: 0.3469 - val_acc: 0.8483\n",
      "Epoch 1583/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8469 - val_loss: 0.3518 - val_acc: 0.8428\n",
      "Epoch 1584/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8477 - val_loss: 0.3451 - val_acc: 0.8474\n",
      "Epoch 1585/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8475 - val_loss: 0.3536 - val_acc: 0.8432\n",
      "Epoch 1586/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8477 - val_loss: 0.3462 - val_acc: 0.8458\n",
      "Epoch 1587/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8478 - val_loss: 0.3457 - val_acc: 0.8465\n",
      "Epoch 1588/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8477 - val_loss: 0.3449 - val_acc: 0.8464\n",
      "Epoch 1589/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8474 - val_loss: 0.3476 - val_acc: 0.8468\n",
      "Epoch 1590/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3403 - acc: 0.8473 - val_loss: 0.3460 - val_acc: 0.8454\n",
      "Epoch 1591/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8473 - val_loss: 0.3465 - val_acc: 0.8454\n",
      "Epoch 1592/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8481 - val_loss: 0.3460 - val_acc: 0.8451\n",
      "Epoch 1593/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8480 - val_loss: 0.3441 - val_acc: 0.8469\n",
      "Epoch 1594/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8469 - val_loss: 0.3510 - val_acc: 0.8425\n",
      "Epoch 1595/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8473 - val_loss: 0.3435 - val_acc: 0.8475\n",
      "Epoch 1596/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8476 - val_loss: 0.3446 - val_acc: 0.8448\n",
      "Epoch 1597/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8469 - val_loss: 0.3466 - val_acc: 0.8444\n",
      "Epoch 1598/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3408 - acc: 0.8473 - val_loss: 0.3465 - val_acc: 0.8466\n",
      "Epoch 1599/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8469 - val_loss: 0.3504 - val_acc: 0.8427\n",
      "Epoch 1600/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8472 - val_loss: 0.3451 - val_acc: 0.8466\n",
      "Epoch 1601/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8468 - val_loss: 0.3460 - val_acc: 0.8450\n",
      "Epoch 1602/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8464 - val_loss: 0.3453 - val_acc: 0.8452\n",
      "Epoch 1603/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8476 - val_loss: 0.3470 - val_acc: 0.8461\n",
      "Epoch 1604/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8476 - val_loss: 0.3456 - val_acc: 0.8450\n",
      "Epoch 1605/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8468 - val_loss: 0.3457 - val_acc: 0.8450\n",
      "Epoch 1606/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3395 - acc: 0.8478 - val_loss: 0.3473 - val_acc: 0.8428\n",
      "Epoch 1607/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8485 - val_loss: 0.3449 - val_acc: 0.8476\n",
      "Epoch 1608/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8475 - val_loss: 0.3450 - val_acc: 0.8463\n",
      "Epoch 1609/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8474 - val_loss: 0.3450 - val_acc: 0.8474\n",
      "Epoch 1610/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3409 - acc: 0.8487 - val_loss: 0.3460 - val_acc: 0.8463\n",
      "Epoch 1611/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8482 - val_loss: 0.3478 - val_acc: 0.8466\n",
      "Epoch 1612/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8471 - val_loss: 0.3470 - val_acc: 0.8453\n",
      "Epoch 1613/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8483 - val_loss: 0.3481 - val_acc: 0.8457\n",
      "Epoch 1614/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8465 - val_loss: 0.3455 - val_acc: 0.8474\n",
      "Epoch 1615/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8484 - val_loss: 0.3431 - val_acc: 0.8476\n",
      "Epoch 1616/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8488 - val_loss: 0.3451 - val_acc: 0.8461\n",
      "Epoch 1617/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8489 - val_loss: 0.3507 - val_acc: 0.8430\n",
      "Epoch 1618/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3394 - acc: 0.8483 - val_loss: 0.3472 - val_acc: 0.8444\n",
      "Epoch 1619/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8478 - val_loss: 0.3466 - val_acc: 0.8444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1620/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3400 - acc: 0.8475 - val_loss: 0.3494 - val_acc: 0.8432\n",
      "Epoch 1621/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8481 - val_loss: 0.3483 - val_acc: 0.8434\n",
      "Epoch 1622/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8473 - val_loss: 0.3451 - val_acc: 0.8460\n",
      "Epoch 1623/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8477 - val_loss: 0.3462 - val_acc: 0.8456\n",
      "Epoch 1624/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3412 - acc: 0.8470 - val_loss: 0.3448 - val_acc: 0.8482\n",
      "Epoch 1625/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8472 - val_loss: 0.3471 - val_acc: 0.8459\n",
      "Epoch 1626/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8478 - val_loss: 0.3454 - val_acc: 0.8467\n",
      "Epoch 1627/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8465 - val_loss: 0.3460 - val_acc: 0.8450\n",
      "Epoch 1628/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8466 - val_loss: 0.3481 - val_acc: 0.8461\n",
      "Epoch 1629/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8469 - val_loss: 0.3456 - val_acc: 0.8464\n",
      "Epoch 1630/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3397 - acc: 0.8467 - val_loss: 0.3467 - val_acc: 0.8469\n",
      "Epoch 1631/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8478 - val_loss: 0.3438 - val_acc: 0.8467\n",
      "Epoch 1632/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8485 - val_loss: 0.3466 - val_acc: 0.8447\n",
      "Epoch 1633/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8487 - val_loss: 0.3447 - val_acc: 0.8461\n",
      "Epoch 1634/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8483 - val_loss: 0.3445 - val_acc: 0.8464\n",
      "Epoch 1635/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3399 - acc: 0.8485 - val_loss: 0.3444 - val_acc: 0.8482\n",
      "Epoch 1636/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8476 - val_loss: 0.3498 - val_acc: 0.8436\n",
      "Epoch 1637/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3410 - acc: 0.8478 - val_loss: 0.3466 - val_acc: 0.8450\n",
      "Epoch 1638/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3406 - acc: 0.8458 - val_loss: 0.3470 - val_acc: 0.8426\n",
      "Epoch 1639/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8480 - val_loss: 0.3454 - val_acc: 0.8466\n",
      "Epoch 1640/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3398 - acc: 0.8477 - val_loss: 0.3457 - val_acc: 0.8458\n",
      "Epoch 1641/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8478 - val_loss: 0.3463 - val_acc: 0.8442\n",
      "Epoch 1642/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8476 - val_loss: 0.3447 - val_acc: 0.8464\n",
      "Epoch 1643/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3405 - acc: 0.8473 - val_loss: 0.3451 - val_acc: 0.8471\n",
      "Epoch 1644/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8483 - val_loss: 0.3506 - val_acc: 0.8411\n",
      "Epoch 1645/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3395 - acc: 0.8474 - val_loss: 0.3460 - val_acc: 0.8454\n",
      "Epoch 1646/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8466 - val_loss: 0.3432 - val_acc: 0.8469\n",
      "Epoch 1647/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8484 - val_loss: 0.3459 - val_acc: 0.8445\n",
      "Epoch 1648/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3395 - acc: 0.8474 - val_loss: 0.3453 - val_acc: 0.8458\n",
      "Epoch 1649/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8485 - val_loss: 0.3449 - val_acc: 0.8481\n",
      "Epoch 1650/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8482 - val_loss: 0.3460 - val_acc: 0.8453\n",
      "Epoch 1651/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3394 - acc: 0.8470 - val_loss: 0.3492 - val_acc: 0.8436\n",
      "Epoch 1652/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8480 - val_loss: 0.3467 - val_acc: 0.8452\n",
      "Epoch 1653/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8473 - val_loss: 0.3468 - val_acc: 0.8440\n",
      "Epoch 1654/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3401 - acc: 0.8468 - val_loss: 0.3485 - val_acc: 0.8420\n",
      "Epoch 1655/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8481 - val_loss: 0.3457 - val_acc: 0.8458\n",
      "Epoch 1656/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8477 - val_loss: 0.3476 - val_acc: 0.8447\n",
      "Epoch 1657/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8483 - val_loss: 0.3444 - val_acc: 0.8463\n",
      "Epoch 1658/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8488 - val_loss: 0.3454 - val_acc: 0.8455\n",
      "Epoch 1659/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8480 - val_loss: 0.3504 - val_acc: 0.8448\n",
      "Epoch 1660/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8481 - val_loss: 0.3465 - val_acc: 0.8470\n",
      "Epoch 1661/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3400 - acc: 0.8490 - val_loss: 0.3453 - val_acc: 0.8489\n",
      "Epoch 1662/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8486 - val_loss: 0.3453 - val_acc: 0.8477\n",
      "Epoch 1663/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8478 - val_loss: 0.3472 - val_acc: 0.8463\n",
      "Epoch 1664/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3393 - acc: 0.8482 - val_loss: 0.3447 - val_acc: 0.8459\n",
      "Epoch 1665/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8483 - val_loss: 0.3480 - val_acc: 0.8439\n",
      "Epoch 1666/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3394 - acc: 0.8472 - val_loss: 0.3499 - val_acc: 0.8423\n",
      "Epoch 1667/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8471 - val_loss: 0.3609 - val_acc: 0.8350\n",
      "Epoch 1668/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8487 - val_loss: 0.3462 - val_acc: 0.8473\n",
      "Epoch 1669/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8488 - val_loss: 0.3438 - val_acc: 0.8488\n",
      "Epoch 1670/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8473 - val_loss: 0.3455 - val_acc: 0.8446\n",
      "Epoch 1671/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8477 - val_loss: 0.3484 - val_acc: 0.8429\n",
      "Epoch 1672/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8470 - val_loss: 0.3445 - val_acc: 0.8459\n",
      "Epoch 1673/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8470 - val_loss: 0.3461 - val_acc: 0.8458\n",
      "Epoch 1674/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3404 - acc: 0.8479 - val_loss: 0.3444 - val_acc: 0.8454\n",
      "Epoch 1675/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3391 - acc: 0.8485 - val_loss: 0.3481 - val_acc: 0.8437\n",
      "Epoch 1676/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3394 - acc: 0.8471 - val_loss: 0.3466 - val_acc: 0.8426\n",
      "Epoch 1677/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8484 - val_loss: 0.3451 - val_acc: 0.8462\n",
      "Epoch 1678/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8473 - val_loss: 0.3455 - val_acc: 0.8459\n",
      "Epoch 1679/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8475 - val_loss: 0.3451 - val_acc: 0.8448\n",
      "Epoch 1680/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8476 - val_loss: 0.3455 - val_acc: 0.8446\n",
      "Epoch 1681/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3393 - acc: 0.8473 - val_loss: 0.3450 - val_acc: 0.8463\n",
      "Epoch 1682/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8478 - val_loss: 0.3475 - val_acc: 0.8456\n",
      "Epoch 1683/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8473 - val_loss: 0.3485 - val_acc: 0.8443\n",
      "Epoch 1684/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3399 - acc: 0.8481 - val_loss: 0.3436 - val_acc: 0.8464\n",
      "Epoch 1685/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3388 - acc: 0.8479 - val_loss: 0.3467 - val_acc: 0.8473\n",
      "Epoch 1686/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3396 - acc: 0.8484 - val_loss: 0.3505 - val_acc: 0.8428\n",
      "Epoch 1687/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3395 - acc: 0.8466 - val_loss: 0.3467 - val_acc: 0.8440\n",
      "Epoch 1688/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3402 - acc: 0.8463 - val_loss: 0.3440 - val_acc: 0.8443\n",
      "Epoch 1689/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8475 - val_loss: 0.3442 - val_acc: 0.8480\n",
      "Epoch 1690/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3393 - acc: 0.8484 - val_loss: 0.3475 - val_acc: 0.8457\n",
      "Epoch 1691/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8475 - val_loss: 0.3448 - val_acc: 0.8466\n",
      "Epoch 1692/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8480 - val_loss: 0.3499 - val_acc: 0.8437\n",
      "Epoch 1693/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8481 - val_loss: 0.3467 - val_acc: 0.8440\n",
      "Epoch 1694/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8472 - val_loss: 0.3482 - val_acc: 0.8420\n",
      "Epoch 1695/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8475 - val_loss: 0.3469 - val_acc: 0.8473\n",
      "Epoch 1696/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3400 - acc: 0.8480 - val_loss: 0.3443 - val_acc: 0.8461\n",
      "Epoch 1697/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8477 - val_loss: 0.3457 - val_acc: 0.8440\n",
      "Epoch 1698/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8471 - val_loss: 0.3516 - val_acc: 0.8424\n",
      "Epoch 1699/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8464 - val_loss: 0.3445 - val_acc: 0.8452\n",
      "Epoch 1700/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8475 - val_loss: 0.3467 - val_acc: 0.8437\n",
      "Epoch 1701/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8466 - val_loss: 0.3441 - val_acc: 0.8456\n",
      "Epoch 1702/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8477 - val_loss: 0.3458 - val_acc: 0.8411\n",
      "Epoch 1703/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3388 - acc: 0.8471 - val_loss: 0.3445 - val_acc: 0.8479\n",
      "Epoch 1704/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3398 - acc: 0.8477 - val_loss: 0.3437 - val_acc: 0.8470\n",
      "Epoch 1705/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3402 - acc: 0.8479 - val_loss: 0.3445 - val_acc: 0.8450\n",
      "Epoch 1706/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3399 - acc: 0.8472 - val_loss: 0.3458 - val_acc: 0.8442\n",
      "Epoch 1707/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3395 - acc: 0.8478 - val_loss: 0.3440 - val_acc: 0.8466\n",
      "Epoch 1708/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3393 - acc: 0.8468 - val_loss: 0.3466 - val_acc: 0.8437\n",
      "Epoch 1709/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8472 - val_loss: 0.3456 - val_acc: 0.8440\n",
      "Epoch 1710/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3394 - acc: 0.8475 - val_loss: 0.3455 - val_acc: 0.8460\n",
      "Epoch 1711/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3394 - acc: 0.8478 - val_loss: 0.3468 - val_acc: 0.8452\n",
      "Epoch 1712/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3391 - acc: 0.8468 - val_loss: 0.3517 - val_acc: 0.8417\n",
      "Epoch 1713/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8481 - val_loss: 0.3469 - val_acc: 0.8416\n",
      "Epoch 1714/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8459 - val_loss: 0.3451 - val_acc: 0.8461\n",
      "Epoch 1715/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3393 - acc: 0.8475 - val_loss: 0.3469 - val_acc: 0.8417\n",
      "Epoch 1716/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3391 - acc: 0.8487 - val_loss: 0.3470 - val_acc: 0.8439\n",
      "Epoch 1717/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3403 - acc: 0.8455 - val_loss: 0.3449 - val_acc: 0.8466\n",
      "Epoch 1718/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8477 - val_loss: 0.3445 - val_acc: 0.8475\n",
      "Epoch 1719/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8488 - val_loss: 0.3436 - val_acc: 0.8474\n",
      "Epoch 1720/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8481 - val_loss: 0.3450 - val_acc: 0.8453\n",
      "Epoch 1721/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3387 - acc: 0.8480 - val_loss: 0.3516 - val_acc: 0.8404\n",
      "Epoch 1722/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8472 - val_loss: 0.3443 - val_acc: 0.8449\n",
      "Epoch 1723/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3394 - acc: 0.8475 - val_loss: 0.3452 - val_acc: 0.8441\n",
      "Epoch 1724/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3393 - acc: 0.8474 - val_loss: 0.3445 - val_acc: 0.8442\n",
      "Epoch 1725/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8475 - val_loss: 0.3461 - val_acc: 0.8435\n",
      "Epoch 1726/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8473 - val_loss: 0.3459 - val_acc: 0.8457\n",
      "Epoch 1727/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3385 - acc: 0.8478 - val_loss: 0.3489 - val_acc: 0.8432\n",
      "Epoch 1728/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8472 - val_loss: 0.3438 - val_acc: 0.8476\n",
      "Epoch 1729/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3392 - acc: 0.8479 - val_loss: 0.3434 - val_acc: 0.8461\n",
      "Epoch 1730/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8472 - val_loss: 0.3455 - val_acc: 0.8442\n",
      "Epoch 1731/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8478 - val_loss: 0.3468 - val_acc: 0.8447\n",
      "Epoch 1732/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3390 - acc: 0.8477 - val_loss: 0.3467 - val_acc: 0.8448\n",
      "Epoch 1733/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8474 - val_loss: 0.3451 - val_acc: 0.8465\n",
      "Epoch 1734/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8486 - val_loss: 0.3491 - val_acc: 0.8431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1735/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8477 - val_loss: 0.3475 - val_acc: 0.8444\n",
      "Epoch 1736/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8489 - val_loss: 0.3475 - val_acc: 0.8425\n",
      "Epoch 1737/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8491 - val_loss: 0.3457 - val_acc: 0.8442\n",
      "Epoch 1738/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8482 - val_loss: 0.3477 - val_acc: 0.8424\n",
      "Epoch 1739/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8482 - val_loss: 0.3454 - val_acc: 0.8453\n",
      "Epoch 1740/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8481 - val_loss: 0.3440 - val_acc: 0.8478\n",
      "Epoch 1741/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3390 - acc: 0.8473 - val_loss: 0.3498 - val_acc: 0.8433\n",
      "Epoch 1742/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3393 - acc: 0.8486 - val_loss: 0.3441 - val_acc: 0.8472\n",
      "Epoch 1743/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3394 - acc: 0.8473 - val_loss: 0.3442 - val_acc: 0.8448\n",
      "Epoch 1744/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8479 - val_loss: 0.3431 - val_acc: 0.8484\n",
      "Epoch 1745/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3393 - acc: 0.8482 - val_loss: 0.3465 - val_acc: 0.8453\n",
      "Epoch 1746/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3392 - acc: 0.8481 - val_loss: 0.3487 - val_acc: 0.8454\n",
      "Epoch 1747/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8477 - val_loss: 0.3464 - val_acc: 0.8474\n",
      "Epoch 1748/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3393 - acc: 0.8474 - val_loss: 0.3476 - val_acc: 0.8435\n",
      "Epoch 1749/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3391 - acc: 0.8479 - val_loss: 0.3449 - val_acc: 0.8469\n",
      "Epoch 1750/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3390 - acc: 0.8474 - val_loss: 0.3458 - val_acc: 0.8440\n",
      "Epoch 1751/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8477 - val_loss: 0.3457 - val_acc: 0.8427\n",
      "Epoch 1752/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3388 - acc: 0.8480 - val_loss: 0.3483 - val_acc: 0.8431\n",
      "Epoch 1753/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8480 - val_loss: 0.3465 - val_acc: 0.8456\n",
      "Epoch 1754/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3393 - acc: 0.8483 - val_loss: 0.3434 - val_acc: 0.8459\n",
      "Epoch 1755/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8470 - val_loss: 0.3444 - val_acc: 0.8449\n",
      "Epoch 1756/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3386 - acc: 0.8479 - val_loss: 0.3477 - val_acc: 0.8460\n",
      "Epoch 1757/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3398 - acc: 0.8483 - val_loss: 0.3466 - val_acc: 0.8426\n",
      "Epoch 1758/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3393 - acc: 0.8484 - val_loss: 0.3503 - val_acc: 0.8415\n",
      "Epoch 1759/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3388 - acc: 0.8486 - val_loss: 0.3451 - val_acc: 0.8465\n",
      "Epoch 1760/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8482 - val_loss: 0.3527 - val_acc: 0.8403\n",
      "Epoch 1761/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3393 - acc: 0.8481 - val_loss: 0.3453 - val_acc: 0.8464\n",
      "Epoch 1762/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8490 - val_loss: 0.3446 - val_acc: 0.8462\n",
      "Epoch 1763/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8484 - val_loss: 0.3467 - val_acc: 0.8434\n",
      "Epoch 1764/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8477 - val_loss: 0.3479 - val_acc: 0.8442\n",
      "Epoch 1765/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8476 - val_loss: 0.3491 - val_acc: 0.8450\n",
      "Epoch 1766/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8477 - val_loss: 0.3516 - val_acc: 0.8429\n",
      "Epoch 1767/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3395 - acc: 0.8480 - val_loss: 0.3459 - val_acc: 0.8458\n",
      "Epoch 1768/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8477 - val_loss: 0.3439 - val_acc: 0.8470\n",
      "Epoch 1769/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8481 - val_loss: 0.3462 - val_acc: 0.8462\n",
      "Epoch 1770/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8473 - val_loss: 0.3464 - val_acc: 0.8440\n",
      "Epoch 1771/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3398 - acc: 0.8478 - val_loss: 0.3463 - val_acc: 0.8440\n",
      "Epoch 1772/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3397 - acc: 0.8484 - val_loss: 0.3445 - val_acc: 0.8445\n",
      "Epoch 1773/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3388 - acc: 0.8470 - val_loss: 0.3475 - val_acc: 0.8420\n",
      "Epoch 1774/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8474 - val_loss: 0.3448 - val_acc: 0.8450\n",
      "Epoch 1775/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8483 - val_loss: 0.3471 - val_acc: 0.8444\n",
      "Epoch 1776/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8481 - val_loss: 0.3453 - val_acc: 0.8445\n",
      "Epoch 1777/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8480 - val_loss: 0.3473 - val_acc: 0.8428\n",
      "Epoch 1778/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3395 - acc: 0.8477 - val_loss: 0.3464 - val_acc: 0.8445\n",
      "Epoch 1779/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8473 - val_loss: 0.3461 - val_acc: 0.8451\n",
      "Epoch 1780/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8479 - val_loss: 0.3503 - val_acc: 0.8411\n",
      "Epoch 1781/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8484 - val_loss: 0.3447 - val_acc: 0.8467\n",
      "Epoch 1782/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3389 - acc: 0.8483 - val_loss: 0.3452 - val_acc: 0.8458\n",
      "Epoch 1783/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8480 - val_loss: 0.3455 - val_acc: 0.8441\n",
      "Epoch 1784/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3390 - acc: 0.8477 - val_loss: 0.3454 - val_acc: 0.8456\n",
      "Epoch 1785/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3387 - acc: 0.8483 - val_loss: 0.3454 - val_acc: 0.8467\n",
      "Epoch 1786/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3394 - acc: 0.8486 - val_loss: 0.3522 - val_acc: 0.8405\n",
      "Epoch 1787/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3392 - acc: 0.8479 - val_loss: 0.3452 - val_acc: 0.8460\n",
      "Epoch 1788/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8478 - val_loss: 0.3472 - val_acc: 0.8449\n",
      "Epoch 1789/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3395 - acc: 0.8478 - val_loss: 0.3444 - val_acc: 0.8472\n",
      "Epoch 1790/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8491 - val_loss: 0.3494 - val_acc: 0.8411\n",
      "Epoch 1791/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8490 - val_loss: 0.3452 - val_acc: 0.8453\n",
      "Epoch 1792/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8478 - val_loss: 0.3463 - val_acc: 0.8456\n",
      "Epoch 1793/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8481 - val_loss: 0.3460 - val_acc: 0.8434\n",
      "Epoch 1794/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3387 - acc: 0.8492 - val_loss: 0.3470 - val_acc: 0.8440\n",
      "Epoch 1795/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3388 - acc: 0.8487 - val_loss: 0.3460 - val_acc: 0.8448\n",
      "Epoch 1796/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3389 - acc: 0.8470 - val_loss: 0.3482 - val_acc: 0.8438\n",
      "Epoch 1797/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3385 - acc: 0.8477 - val_loss: 0.3463 - val_acc: 0.8458\n",
      "Epoch 1798/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8480 - val_loss: 0.3445 - val_acc: 0.8456\n",
      "Epoch 1799/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3389 - acc: 0.8487 - val_loss: 0.3463 - val_acc: 0.8449\n",
      "Epoch 1800/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3388 - acc: 0.8474 - val_loss: 0.3451 - val_acc: 0.8448\n",
      "Epoch 1801/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3387 - acc: 0.8481 - val_loss: 0.3459 - val_acc: 0.8447\n",
      "Epoch 1802/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3387 - acc: 0.8473 - val_loss: 0.3480 - val_acc: 0.8442\n",
      "Epoch 1803/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8480 - val_loss: 0.3455 - val_acc: 0.8453\n",
      "Epoch 1804/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3378 - acc: 0.8478 - val_loss: 0.3460 - val_acc: 0.8432\n",
      "Epoch 1805/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3383 - acc: 0.8481 - val_loss: 0.3454 - val_acc: 0.8429\n",
      "Epoch 1806/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3381 - acc: 0.8485 - val_loss: 0.3465 - val_acc: 0.8456\n",
      "Epoch 1807/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3396 - acc: 0.8476 - val_loss: 0.3455 - val_acc: 0.8460\n",
      "Epoch 1808/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8486 - val_loss: 0.3451 - val_acc: 0.8450\n",
      "Epoch 1809/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8487 - val_loss: 0.3490 - val_acc: 0.8411\n",
      "Epoch 1810/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8479 - val_loss: 0.3453 - val_acc: 0.8456\n",
      "Epoch 1811/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8483 - val_loss: 0.3448 - val_acc: 0.8458\n",
      "Epoch 1812/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8474 - val_loss: 0.3477 - val_acc: 0.8439\n",
      "Epoch 1813/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3381 - acc: 0.8478 - val_loss: 0.3473 - val_acc: 0.8444\n",
      "Epoch 1814/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3388 - acc: 0.8479 - val_loss: 0.3450 - val_acc: 0.8476\n",
      "Epoch 1815/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3385 - acc: 0.8483 - val_loss: 0.3441 - val_acc: 0.8477\n",
      "Epoch 1816/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8469 - val_loss: 0.3474 - val_acc: 0.8461\n",
      "Epoch 1817/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8476 - val_loss: 0.3448 - val_acc: 0.8461\n",
      "Epoch 1818/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3382 - acc: 0.8484 - val_loss: 0.3447 - val_acc: 0.8469\n",
      "Epoch 1819/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8470 - val_loss: 0.3436 - val_acc: 0.8463\n",
      "Epoch 1820/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3382 - acc: 0.8494 - val_loss: 0.3442 - val_acc: 0.8456\n",
      "Epoch 1821/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8482 - val_loss: 0.3472 - val_acc: 0.8453\n",
      "Epoch 1822/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8477 - val_loss: 0.3518 - val_acc: 0.8421\n",
      "Epoch 1823/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3388 - acc: 0.8470 - val_loss: 0.3465 - val_acc: 0.8446\n",
      "Epoch 1824/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8475 - val_loss: 0.3450 - val_acc: 0.8440\n",
      "Epoch 1825/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8477 - val_loss: 0.3499 - val_acc: 0.8446\n",
      "Epoch 1826/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8478 - val_loss: 0.3457 - val_acc: 0.8428\n",
      "Epoch 1827/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3394 - acc: 0.8480 - val_loss: 0.3438 - val_acc: 0.8468\n",
      "Epoch 1828/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3392 - acc: 0.8476 - val_loss: 0.3453 - val_acc: 0.8457\n",
      "Epoch 1829/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8479 - val_loss: 0.3514 - val_acc: 0.8426\n",
      "Epoch 1830/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3385 - acc: 0.8475 - val_loss: 0.3451 - val_acc: 0.8465\n",
      "Epoch 1831/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8483 - val_loss: 0.3470 - val_acc: 0.8446\n",
      "Epoch 1832/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8481 - val_loss: 0.3445 - val_acc: 0.8468\n",
      "Epoch 1833/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8489 - val_loss: 0.3455 - val_acc: 0.8456\n",
      "Epoch 1834/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8480 - val_loss: 0.3480 - val_acc: 0.8424\n",
      "Epoch 1835/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8476 - val_loss: 0.3457 - val_acc: 0.8454\n",
      "Epoch 1836/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3389 - acc: 0.8469 - val_loss: 0.3469 - val_acc: 0.8438\n",
      "Epoch 1837/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3384 - acc: 0.8489 - val_loss: 0.3494 - val_acc: 0.8411\n",
      "Epoch 1838/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8483 - val_loss: 0.3473 - val_acc: 0.8437\n",
      "Epoch 1839/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8483 - val_loss: 0.3454 - val_acc: 0.8450\n",
      "Epoch 1840/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3385 - acc: 0.8482 - val_loss: 0.3478 - val_acc: 0.8452\n",
      "Epoch 1841/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3390 - acc: 0.8479 - val_loss: 0.3465 - val_acc: 0.8453\n",
      "Epoch 1842/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3387 - acc: 0.8486 - val_loss: 0.3486 - val_acc: 0.8432\n",
      "Epoch 1843/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8473 - val_loss: 0.3451 - val_acc: 0.8450\n",
      "Epoch 1844/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8478 - val_loss: 0.3512 - val_acc: 0.8409\n",
      "Epoch 1845/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8486 - val_loss: 0.3450 - val_acc: 0.8445\n",
      "Epoch 1846/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8475 - val_loss: 0.3490 - val_acc: 0.8440\n",
      "Epoch 1847/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3384 - acc: 0.8490 - val_loss: 0.3464 - val_acc: 0.8426\n",
      "Epoch 1848/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3380 - acc: 0.8480 - val_loss: 0.3479 - val_acc: 0.8432\n",
      "Epoch 1849/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8475 - val_loss: 0.3492 - val_acc: 0.8442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1850/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8485 - val_loss: 0.3448 - val_acc: 0.8445\n",
      "Epoch 1851/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3389 - acc: 0.8472 - val_loss: 0.3458 - val_acc: 0.8463\n",
      "Epoch 1852/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3390 - acc: 0.8477 - val_loss: 0.3450 - val_acc: 0.8448\n",
      "Epoch 1853/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8482 - val_loss: 0.3473 - val_acc: 0.8433\n",
      "Epoch 1854/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3385 - acc: 0.8486 - val_loss: 0.3498 - val_acc: 0.8424\n",
      "Epoch 1855/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3390 - acc: 0.8488 - val_loss: 0.3494 - val_acc: 0.8421\n",
      "Epoch 1856/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3387 - acc: 0.8476 - val_loss: 0.3510 - val_acc: 0.8427\n",
      "Epoch 1857/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3383 - acc: 0.8478 - val_loss: 0.3470 - val_acc: 0.8449\n",
      "Epoch 1858/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3386 - acc: 0.8490 - val_loss: 0.3462 - val_acc: 0.8445\n",
      "Epoch 1859/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3386 - acc: 0.8470 - val_loss: 0.3432 - val_acc: 0.8464\n",
      "Epoch 1860/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8473 - val_loss: 0.3449 - val_acc: 0.8452\n",
      "Epoch 1861/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3384 - acc: 0.8476 - val_loss: 0.3455 - val_acc: 0.8441\n",
      "Epoch 1862/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3387 - acc: 0.8486 - val_loss: 0.3445 - val_acc: 0.8445\n",
      "Epoch 1863/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8483 - val_loss: 0.3450 - val_acc: 0.8447\n",
      "Epoch 1864/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3386 - acc: 0.8477 - val_loss: 0.3461 - val_acc: 0.8461\n",
      "Epoch 1865/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3382 - acc: 0.8474 - val_loss: 0.3445 - val_acc: 0.8469\n",
      "Epoch 1866/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3383 - acc: 0.8480 - val_loss: 0.3461 - val_acc: 0.8441\n",
      "Epoch 1867/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3383 - acc: 0.8480 - val_loss: 0.3478 - val_acc: 0.8434\n",
      "Epoch 1868/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3380 - acc: 0.8488 - val_loss: 0.3455 - val_acc: 0.8449\n",
      "Epoch 1869/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3381 - acc: 0.8477 - val_loss: 0.3455 - val_acc: 0.8440\n",
      "Epoch 1870/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3385 - acc: 0.8482 - val_loss: 0.3478 - val_acc: 0.8435\n",
      "Epoch 1871/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8479 - val_loss: 0.3498 - val_acc: 0.8435\n",
      "Epoch 1872/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8485 - val_loss: 0.3462 - val_acc: 0.8445\n",
      "Epoch 1873/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8487 - val_loss: 0.3448 - val_acc: 0.8466\n",
      "Epoch 1874/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8493 - val_loss: 0.3440 - val_acc: 0.8473\n",
      "Epoch 1875/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3381 - acc: 0.8485 - val_loss: 0.3478 - val_acc: 0.8427\n",
      "Epoch 1876/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8476 - val_loss: 0.3466 - val_acc: 0.8449\n",
      "Epoch 1877/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8484 - val_loss: 0.3444 - val_acc: 0.8462\n",
      "Epoch 1878/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8487 - val_loss: 0.3470 - val_acc: 0.8450\n",
      "Epoch 1879/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3382 - acc: 0.8490 - val_loss: 0.3469 - val_acc: 0.8450\n",
      "Epoch 1880/2000\n",
      "41408/41408 [==============================] - ETA: 0s - loss: 0.3375 - acc: 0.848 - 1s 23us/step - loss: 0.3385 - acc: 0.8477 - val_loss: 0.3484 - val_acc: 0.8429\n",
      "Epoch 1881/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8483 - val_loss: 0.3477 - val_acc: 0.8458\n",
      "Epoch 1882/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8482 - val_loss: 0.3453 - val_acc: 0.8450\n",
      "Epoch 1883/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8497 - val_loss: 0.3443 - val_acc: 0.8460\n",
      "Epoch 1884/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8468 - val_loss: 0.3505 - val_acc: 0.8420\n",
      "Epoch 1885/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8480 - val_loss: 0.3485 - val_acc: 0.8432\n",
      "Epoch 1886/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8486 - val_loss: 0.3458 - val_acc: 0.8449\n",
      "Epoch 1887/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8479 - val_loss: 0.3441 - val_acc: 0.8464\n",
      "Epoch 1888/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8476 - val_loss: 0.3469 - val_acc: 0.8436\n",
      "Epoch 1889/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3377 - acc: 0.8491 - val_loss: 0.3468 - val_acc: 0.8431\n",
      "Epoch 1890/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3382 - acc: 0.8491 - val_loss: 0.3440 - val_acc: 0.8448\n",
      "Epoch 1891/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3379 - acc: 0.8490 - val_loss: 0.3450 - val_acc: 0.8450\n",
      "Epoch 1892/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8478 - val_loss: 0.3447 - val_acc: 0.8469\n",
      "Epoch 1893/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8477 - val_loss: 0.3513 - val_acc: 0.8427\n",
      "Epoch 1894/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8480 - val_loss: 0.3446 - val_acc: 0.8469\n",
      "Epoch 1895/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8481 - val_loss: 0.3465 - val_acc: 0.8437\n",
      "Epoch 1896/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8469 - val_loss: 0.3495 - val_acc: 0.8444\n",
      "Epoch 1897/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3381 - acc: 0.8481 - val_loss: 0.3478 - val_acc: 0.8437\n",
      "Epoch 1898/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8487 - val_loss: 0.3457 - val_acc: 0.8458\n",
      "Epoch 1899/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3382 - acc: 0.8496 - val_loss: 0.3486 - val_acc: 0.8427\n",
      "Epoch 1900/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8490 - val_loss: 0.3478 - val_acc: 0.8448\n",
      "Epoch 1901/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8478 - val_loss: 0.3449 - val_acc: 0.8469\n",
      "Epoch 1902/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8476 - val_loss: 0.3455 - val_acc: 0.8456\n",
      "Epoch 1903/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3383 - acc: 0.8482 - val_loss: 0.3459 - val_acc: 0.8465\n",
      "Epoch 1904/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3379 - acc: 0.8484 - val_loss: 0.3456 - val_acc: 0.8442\n",
      "Epoch 1905/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3377 - acc: 0.8485 - val_loss: 0.3484 - val_acc: 0.8455\n",
      "Epoch 1906/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8479 - val_loss: 0.3441 - val_acc: 0.8469\n",
      "Epoch 1907/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3379 - acc: 0.8494 - val_loss: 0.3461 - val_acc: 0.8459\n",
      "Epoch 1908/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3380 - acc: 0.8494 - val_loss: 0.3504 - val_acc: 0.8417\n",
      "Epoch 1909/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3391 - acc: 0.8477 - val_loss: 0.3475 - val_acc: 0.8428\n",
      "Epoch 1910/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8489 - val_loss: 0.3437 - val_acc: 0.8466\n",
      "Epoch 1911/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3392 - acc: 0.8478 - val_loss: 0.3442 - val_acc: 0.8461\n",
      "Epoch 1912/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3379 - acc: 0.8479 - val_loss: 0.3456 - val_acc: 0.8435\n",
      "Epoch 1913/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3385 - acc: 0.8477 - val_loss: 0.3453 - val_acc: 0.8448\n",
      "Epoch 1914/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3383 - acc: 0.8486 - val_loss: 0.3452 - val_acc: 0.8463\n",
      "Epoch 1915/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3377 - acc: 0.8479 - val_loss: 0.3511 - val_acc: 0.8409\n",
      "Epoch 1916/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3389 - acc: 0.8480 - val_loss: 0.3467 - val_acc: 0.8444\n",
      "Epoch 1917/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3385 - acc: 0.8470 - val_loss: 0.3439 - val_acc: 0.8444\n",
      "Epoch 1918/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8483 - val_loss: 0.3476 - val_acc: 0.8432\n",
      "Epoch 1919/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3384 - acc: 0.8477 - val_loss: 0.3458 - val_acc: 0.8449\n",
      "Epoch 1920/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3387 - acc: 0.8486 - val_loss: 0.3451 - val_acc: 0.8453\n",
      "Epoch 1921/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8487 - val_loss: 0.3440 - val_acc: 0.8453\n",
      "Epoch 1922/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3383 - acc: 0.8480 - val_loss: 0.3473 - val_acc: 0.8429\n",
      "Epoch 1923/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8474 - val_loss: 0.3474 - val_acc: 0.8411\n",
      "Epoch 1924/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8490 - val_loss: 0.3482 - val_acc: 0.8432\n",
      "Epoch 1925/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8486 - val_loss: 0.3455 - val_acc: 0.8450\n",
      "Epoch 1926/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8497 - val_loss: 0.3463 - val_acc: 0.8435\n",
      "Epoch 1927/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8480 - val_loss: 0.3442 - val_acc: 0.8439\n",
      "Epoch 1928/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8481 - val_loss: 0.3514 - val_acc: 0.8403\n",
      "Epoch 1929/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3384 - acc: 0.8493 - val_loss: 0.3458 - val_acc: 0.8456\n",
      "Epoch 1930/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3375 - acc: 0.8487 - val_loss: 0.3442 - val_acc: 0.8469\n",
      "Epoch 1931/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3385 - acc: 0.8481 - val_loss: 0.3427 - val_acc: 0.8451\n",
      "Epoch 1932/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3382 - acc: 0.8484 - val_loss: 0.3461 - val_acc: 0.8441\n",
      "Epoch 1933/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8474 - val_loss: 0.3442 - val_acc: 0.8452\n",
      "Epoch 1934/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3382 - acc: 0.8484 - val_loss: 0.3562 - val_acc: 0.8388\n",
      "Epoch 1935/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3383 - acc: 0.8467 - val_loss: 0.3450 - val_acc: 0.8459\n",
      "Epoch 1936/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3385 - acc: 0.8474 - val_loss: 0.3437 - val_acc: 0.8458\n",
      "Epoch 1937/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8484 - val_loss: 0.3470 - val_acc: 0.8435\n",
      "Epoch 1938/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3388 - acc: 0.8485 - val_loss: 0.3460 - val_acc: 0.8446\n",
      "Epoch 1939/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3390 - acc: 0.8482 - val_loss: 0.3454 - val_acc: 0.8461\n",
      "Epoch 1940/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8474 - val_loss: 0.3466 - val_acc: 0.8431\n",
      "Epoch 1941/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8475 - val_loss: 0.3462 - val_acc: 0.8454\n",
      "Epoch 1942/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8473 - val_loss: 0.3503 - val_acc: 0.8424\n",
      "Epoch 1943/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3383 - acc: 0.8494 - val_loss: 0.3481 - val_acc: 0.8429\n",
      "Epoch 1944/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3385 - acc: 0.8486 - val_loss: 0.3429 - val_acc: 0.8473\n",
      "Epoch 1945/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3387 - acc: 0.8472 - val_loss: 0.3486 - val_acc: 0.8435\n",
      "Epoch 1946/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8481 - val_loss: 0.3467 - val_acc: 0.8438\n",
      "Epoch 1947/2000\n",
      "41408/41408 [==============================] - 1s 22us/step - loss: 0.3386 - acc: 0.8477 - val_loss: 0.3441 - val_acc: 0.8460\n",
      "Epoch 1948/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8487 - val_loss: 0.3473 - val_acc: 0.8425\n",
      "Epoch 1949/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8481 - val_loss: 0.3445 - val_acc: 0.8465\n",
      "Epoch 1950/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8478 - val_loss: 0.3470 - val_acc: 0.8448\n",
      "Epoch 1951/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8469 - val_loss: 0.3473 - val_acc: 0.8446\n",
      "Epoch 1952/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8479 - val_loss: 0.3455 - val_acc: 0.8442\n",
      "Epoch 1953/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3390 - acc: 0.8473 - val_loss: 0.3475 - val_acc: 0.8440\n",
      "Epoch 1954/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8480 - val_loss: 0.3445 - val_acc: 0.8453\n",
      "Epoch 1955/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8477 - val_loss: 0.3482 - val_acc: 0.8419\n",
      "Epoch 1956/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3380 - acc: 0.8486 - val_loss: 0.3452 - val_acc: 0.8446\n",
      "Epoch 1957/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3380 - acc: 0.8471 - val_loss: 0.3484 - val_acc: 0.8445\n",
      "Epoch 1958/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3378 - acc: 0.8479 - val_loss: 0.3481 - val_acc: 0.8440\n",
      "Epoch 1959/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3386 - acc: 0.8482 - val_loss: 0.3488 - val_acc: 0.8441\n",
      "Epoch 1960/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8473 - val_loss: 0.3440 - val_acc: 0.8463\n",
      "Epoch 1961/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8480 - val_loss: 0.3451 - val_acc: 0.8450\n",
      "Epoch 1962/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8488 - val_loss: 0.3438 - val_acc: 0.8465\n",
      "Epoch 1963/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8483 - val_loss: 0.3456 - val_acc: 0.8450\n",
      "Epoch 1964/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8487 - val_loss: 0.3499 - val_acc: 0.8442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1965/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3391 - acc: 0.8481 - val_loss: 0.3454 - val_acc: 0.8450\n",
      "Epoch 1966/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3393 - acc: 0.8487 - val_loss: 0.3475 - val_acc: 0.8445\n",
      "Epoch 1967/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3394 - acc: 0.8474 - val_loss: 0.3450 - val_acc: 0.8448\n",
      "Epoch 1968/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3385 - acc: 0.8484 - val_loss: 0.3436 - val_acc: 0.8464\n",
      "Epoch 1969/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8483 - val_loss: 0.3446 - val_acc: 0.8476\n",
      "Epoch 1970/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3388 - acc: 0.8484 - val_loss: 0.3462 - val_acc: 0.8451\n",
      "Epoch 1971/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8487 - val_loss: 0.3520 - val_acc: 0.8416\n",
      "Epoch 1972/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3387 - acc: 0.8481 - val_loss: 0.3455 - val_acc: 0.8459\n",
      "Epoch 1973/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3386 - acc: 0.8467 - val_loss: 0.3464 - val_acc: 0.8453\n",
      "Epoch 1974/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8485 - val_loss: 0.3479 - val_acc: 0.8435\n",
      "Epoch 1975/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3386 - acc: 0.8481 - val_loss: 0.3461 - val_acc: 0.8453\n",
      "Epoch 1976/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3379 - acc: 0.8486 - val_loss: 0.3455 - val_acc: 0.8452\n",
      "Epoch 1977/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3389 - acc: 0.8490 - val_loss: 0.3452 - val_acc: 0.8477\n",
      "Epoch 1978/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8481 - val_loss: 0.3465 - val_acc: 0.8433\n",
      "Epoch 1979/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8484 - val_loss: 0.3434 - val_acc: 0.8466\n",
      "Epoch 1980/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3383 - acc: 0.8481 - val_loss: 0.3435 - val_acc: 0.8453\n",
      "Epoch 1981/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8488 - val_loss: 0.3463 - val_acc: 0.8466\n",
      "Epoch 1982/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3387 - acc: 0.8484 - val_loss: 0.3450 - val_acc: 0.8452\n",
      "Epoch 1983/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8478 - val_loss: 0.3480 - val_acc: 0.8441\n",
      "Epoch 1984/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8462 - val_loss: 0.3545 - val_acc: 0.8397\n",
      "Epoch 1985/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8476 - val_loss: 0.3459 - val_acc: 0.8427\n",
      "Epoch 1986/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3381 - acc: 0.8482 - val_loss: 0.3493 - val_acc: 0.8432\n",
      "Epoch 1987/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3379 - acc: 0.8482 - val_loss: 0.3425 - val_acc: 0.8463\n",
      "Epoch 1988/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3380 - acc: 0.8485 - val_loss: 0.3462 - val_acc: 0.8437\n",
      "Epoch 1989/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8485 - val_loss: 0.3451 - val_acc: 0.8454\n",
      "Epoch 1990/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3385 - acc: 0.8490 - val_loss: 0.3440 - val_acc: 0.8464\n",
      "Epoch 1991/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.8475 - val_loss: 0.3482 - val_acc: 0.8443\n",
      "Epoch 1992/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3387 - acc: 0.8484 - val_loss: 0.3460 - val_acc: 0.8442\n",
      "Epoch 1993/2000\n",
      "41408/41408 [==============================] - 1s 25us/step - loss: 0.3382 - acc: 0.8478 - val_loss: 0.3495 - val_acc: 0.8429\n",
      "Epoch 1994/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3385 - acc: 0.8478 - val_loss: 0.3489 - val_acc: 0.8461\n",
      "Epoch 1995/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3387 - acc: 0.8474 - val_loss: 0.3487 - val_acc: 0.8422\n",
      "Epoch 1996/2000\n",
      "41408/41408 [==============================] - 1s 27us/step - loss: 0.3382 - acc: 0.8483 - val_loss: 0.3445 - val_acc: 0.8463\n",
      "Epoch 1997/2000\n",
      "41408/41408 [==============================] - 1s 26us/step - loss: 0.3384 - acc: 0.8474 - val_loss: 0.3456 - val_acc: 0.8437\n",
      "Epoch 1998/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3380 - acc: 0.8482 - val_loss: 0.3431 - val_acc: 0.8463\n",
      "Epoch 1999/2000\n",
      "41408/41408 [==============================] - 1s 23us/step - loss: 0.3384 - acc: 0.8478 - val_loss: 0.3433 - val_acc: 0.8480\n",
      "Epoch 2000/2000\n",
      "41408/41408 [==============================] - 1s 24us/step - loss: 0.3383 - acc: 0.8483 - val_loss: 0.3460 - val_acc: 0.8428\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_X[:], train_Y[:], \n",
    "          epochs=2000, \n",
    "          batch_size=32, \n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          #validation_split=0.1)\n",
    "          validation_data=(test_X, test_Y))\n",
    "\n",
    "history = {k : history[k] + h.history[k] for k in hist_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y[train_Y==0].shape, train_Y[train_Y==1].shape\n",
    "test_Y[test_Y==0].shape, test_Y[test_Y==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce31842518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.7410142e-01 2.5898589e-02]\n",
      " [9.7761589e-01 2.2384083e-02]\n",
      " [9.7797078e-01 2.2029223e-02]\n",
      " [5.2552408e-01 4.7447595e-01]\n",
      " [8.1728786e-01 1.8271212e-01]\n",
      " [2.8420327e-02 9.7157967e-01]\n",
      " [1.0399166e-01 8.9600837e-01]\n",
      " [9.7105443e-01 2.8945554e-02]\n",
      " [1.0137895e-04 9.9989861e-01]\n",
      " [8.2810514e-04 9.9917191e-01]]\n"
     ]
    }
   ],
   "source": [
    "# calculate predicted values\n",
    "Y_pred_ = model.predict(test_X)\n",
    "# predictions are outputted as floats from [0,1]\n",
    "print(Y_pred_[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = numpy.argmax(Y_pred_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5697 1205]\n",
      " [ 965 5937]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# we must translate it to 0, 1 based on thresholding at 0.5\n",
    "# where < 0.5 set to 0, to 1 otherwise\n",
    "Y_pred = numpy.where(Y_pred < 0.5, 0, 1)\n",
    "\n",
    "# calculate confusion matrix\n",
    "conf_mat = confusion_matrix(test_Y_, Y_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6902/6902 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3273585427372188, 0.8601854534399264]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eval on test data\n",
    "model.evaluate(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41408/41408 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33733608502278556, 0.8480245363214838]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "model.save('URZ_model_NTPS.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive step of the training\n",
    "\n",
    "* let's remove those training samples which are classified as noise by analysts but NN says the are real arrivals - could be a small arrivals omited by analysts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix before removal of noise classified as signal from train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaptive step of the training\n",
    "Y_train_pred = numpy.argmax(model.predict(train_X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarization, reshape\n",
    "Y_train_pred = numpy.reshape(numpy.where(Y_train_pred < 0.5, 0, 1), (len(Y_train_pred), 1))\n",
    "Y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.abs(Y_train_pred - train_Y_).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(train_Y_, Y_train_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat[0,1]+conf_mat[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removal of noise classified as signal from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's remove noise classified as signal in train set\n",
    "#0 - noise, 1 - signal\n",
    "#0 classified as 0: 0 - 0 = 0\n",
    "#1 classified as 0: 0 - 1 = -1\n",
    "#0 classified as 1: 1 - 0 = 1 - to be removed\n",
    "train_X_1 = train_X[(Y_train_pred - train_Y_)[:,0] < 1, :]\n",
    "train_Y_1 = train_Y[(Y_train_pred - train_Y_)[:,0] < 1, :]\n",
    "train_Y_1_ = numpy.reshape(numpy.argmax(train_Y_1, axis=1), (train_Y_1.shape[0], 1))\n",
    "train_X_1.shape, train_Y_1.shape, train_Y_1_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-training with a new training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = {k : [] for k in hist_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = len(x_indices)\n",
    "numpy.random.seed(11)\n",
    "\n",
    "# create model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(n_input, input_dim=n_input, activation='sigmoid'))\n",
    "model_1.add(Dense(6, activation='sigmoid'))\n",
    "model_1.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=1., clipvalue=0.5)\n",
    "adam = Adam(lr=0.0001) #, clipnorm, clipvalue=0.5)\n",
    "\n",
    "model_1.compile(\n",
    "    loss = 'binary_crossentropy', \n",
    "    optimizer = 'adam',  # adam, sgd\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model_1.fit(train_X_1[:], train_Y_1[:], \n",
    "          epochs=500, \n",
    "          batch_size=32, \n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          #validation_split=0.1)\n",
    "          validation_data=([test_X, test_Y]))\n",
    "\n",
    "history_1 = {k : history_1[k] + h.history[k] for k in hist_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval on test data\n",
    "model_1.evaluate(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred_1 = numpy.reshape(numpy.where(numpy.argmax(model_1.predict(train_X_1), axis=1) < 0.5, 0, 1), (train_X_1.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(train_Y_1_, Y_train_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network TP vs S \n",
    "\n",
    "* we need a new dataset for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for TP vs S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20704, 25) (6902, 25)\n"
     ]
    }
   ],
   "source": [
    "print(TPS_train.shape, TPS_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20704, 15) (20704, 2) (6902, 15) (6902, 2)\n"
     ]
    }
   ],
   "source": [
    "train_X_TPS = TPS_train[x_indices].values.astype(float)\n",
    "train_Y_TPS = TPS_train[y_indices]\n",
    "\n",
    "test_X_TPS = TPS_test[x_indices].values.astype(float)\n",
    "test_Y_TPS = TPS_test[y_indices]\n",
    "\n",
    "#regS = 0, T/regP = 1\n",
    "train_Y_TPS_ = numpy.array(numpy.where(train_Y_TPS['CLASS_PHASE'] == 'regS', 0, 1), dtype=float)\n",
    "test_Y_TPS_ = numpy.array(numpy.where(test_Y_TPS['CLASS_PHASE'] == 'regS', 0, 1), dtype=float)\n",
    "\n",
    "#convert to categorical\n",
    "train_Y_TPS = keras.utils.to_categorical(train_Y_TPS_)\n",
    "test_Y_TPS = keras.utils.to_categorical(test_Y_TPS_)\n",
    "\n",
    "print(train_X_TPS.shape, train_Y_TPS.shape, test_X_TPS.shape, test_Y_TPS.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually added datasets for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6006, 15) (6006, 2) (6006, 1)\n"
     ]
    }
   ],
   "source": [
    "#those manually added\n",
    "nsm = df_S_all[df_S_all['SOURCE'] == 'M'].shape[0]\n",
    "npm = df_P_all[df_P_all['SOURCE'] == 'M'].shape[0]\n",
    "ntm = df_T_all[df_T_all['SOURCE'] == 'M'].shape[0]\n",
    "nnm = df_N_all[df_N_all['SOURCE'] == 'M'].shape[0]\n",
    "\n",
    "#we build a balanced datased - the same portion of regS, regP and tele\n",
    "#we have this count of phases\n",
    "man_samp_count = min(nsm, npm, ntm)\n",
    "\n",
    "#sample TPS dataset, random_state is a seed\n",
    "mssS = df_S_all[df_S_all['SOURCE'] == 'M'].sample(man_samp_count, random_state=11)\n",
    "mssP = df_P_all[df_P_all['SOURCE'] == 'M'].sample(man_samp_count)\n",
    "mssT = df_T_all[df_T_all['SOURCE'] == 'M'].sample(man_samp_count)\n",
    "MTPS_data = pd.concat([mssS, mssP, mssT])\n",
    "\n",
    "#manually added noise makes nos sense - we do not sanmple N\n",
    "\n",
    "#lets shuffle dataset\n",
    "MTPS_data = MTPS_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "manual_X = MTPS_data[x_indices].values.astype(float)\n",
    "#regS = 0, T/regP = 1\n",
    "manual_Y_TPS_ = numpy.array(numpy.where(MTPS_data[y_indices] == 'regS', 0, 1), dtype=float)\n",
    "manual_Y_TPS = keras.utils.to_categorical(manual_Y_)\n",
    "\n",
    "print(manual_X.shape, manual_Y_TPS.shape, manual_Y_TPS_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual dataset ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dvlscratch/SHI/users/hofman/ML/env/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 2, 2, 3, 3, 2, 1, 3, 2, 3, 3, 2, 1, 1, 2, 1, 2, 2])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_Y_GT = le.transform(MTPS_data[y_indices])\n",
    "manual_Y_GT[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_TPS = {k : [] for k in hist_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = len(x_indices)\n",
    "numpy.random.seed(11)\n",
    "\n",
    "# create model\n",
    "model_TPS = Sequential()\n",
    "model_TPS.add(Dense(n_input, input_dim=n_input, activation='sigmoid'))\n",
    "model_TPS.add(Dense(6, activation='sigmoid'))\n",
    "model_TPS.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model_TPS.compile(\n",
    "    loss = 'binary_crossentropy', \n",
    "    optimizer = 'adam',  # adam, sgd\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20704 samples, validate on 6902 samples\n",
      "Epoch 1/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2014 - acc: 0.9151 - val_loss: 0.2331 - val_acc: 0.8981\n",
      "Epoch 2/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2002 - acc: 0.9177 - val_loss: 0.2324 - val_acc: 0.8978\n",
      "Epoch 3/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2012 - acc: 0.9159 - val_loss: 0.2344 - val_acc: 0.8994\n",
      "Epoch 4/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2013 - acc: 0.9163 - val_loss: 0.2358 - val_acc: 0.8945\n",
      "Epoch 5/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2016 - acc: 0.9154 - val_loss: 0.2319 - val_acc: 0.9005\n",
      "Epoch 6/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2009 - acc: 0.9154 - val_loss: 0.2364 - val_acc: 0.8950\n",
      "Epoch 7/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2028 - acc: 0.9154 - val_loss: 0.2345 - val_acc: 0.8999\n",
      "Epoch 8/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2014 - acc: 0.9158 - val_loss: 0.2324 - val_acc: 0.8998\n",
      "Epoch 9/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2012 - acc: 0.9152 - val_loss: 0.2351 - val_acc: 0.8994\n",
      "Epoch 10/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2000 - acc: 0.9162 - val_loss: 0.2326 - val_acc: 0.8979\n",
      "Epoch 11/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2010 - acc: 0.9151 - val_loss: 0.2326 - val_acc: 0.8982\n",
      "Epoch 12/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1999 - acc: 0.9165 - val_loss: 0.2318 - val_acc: 0.8958\n",
      "Epoch 13/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2001 - acc: 0.9165 - val_loss: 0.2334 - val_acc: 0.8974\n",
      "Epoch 14/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2044 - acc: 0.9149 - val_loss: 0.2341 - val_acc: 0.8971\n",
      "Epoch 15/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2009 - acc: 0.9170 - val_loss: 0.2341 - val_acc: 0.8985\n",
      "Epoch 16/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2022 - acc: 0.9156 - val_loss: 0.2395 - val_acc: 0.8969\n",
      "Epoch 17/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2031 - acc: 0.9151 - val_loss: 0.2409 - val_acc: 0.8970\n",
      "Epoch 18/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2018 - acc: 0.9153 - val_loss: 0.2359 - val_acc: 0.8941\n",
      "Epoch 19/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2013 - acc: 0.9161 - val_loss: 0.2348 - val_acc: 0.8979\n",
      "Epoch 20/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2015 - acc: 0.9172 - val_loss: 0.2322 - val_acc: 0.8969\n",
      "Epoch 21/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2007 - acc: 0.9161 - val_loss: 0.2322 - val_acc: 0.8981\n",
      "Epoch 22/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2004 - acc: 0.9171 - val_loss: 0.2316 - val_acc: 0.8989\n",
      "Epoch 23/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2003 - acc: 0.9163 - val_loss: 0.2300 - val_acc: 0.8988\n",
      "Epoch 24/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1999 - acc: 0.9154 - val_loss: 0.2325 - val_acc: 0.8987\n",
      "Epoch 25/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2008 - acc: 0.9159 - val_loss: 0.2317 - val_acc: 0.8976\n",
      "Epoch 26/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2011 - acc: 0.9163 - val_loss: 0.2325 - val_acc: 0.8951\n",
      "Epoch 27/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2007 - acc: 0.9160 - val_loss: 0.2333 - val_acc: 0.8976\n",
      "Epoch 28/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2018 - acc: 0.9168 - val_loss: 0.2354 - val_acc: 0.8965\n",
      "Epoch 29/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2023 - acc: 0.9155 - val_loss: 0.2349 - val_acc: 0.8937\n",
      "Epoch 30/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2000 - acc: 0.9163 - val_loss: 0.2330 - val_acc: 0.8983\n",
      "Epoch 31/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2004 - acc: 0.9156 - val_loss: 0.2310 - val_acc: 0.8976\n",
      "Epoch 32/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2010 - acc: 0.9156 - val_loss: 0.2327 - val_acc: 0.8982\n",
      "Epoch 33/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2007 - acc: 0.9161 - val_loss: 0.2347 - val_acc: 0.8932\n",
      "Epoch 34/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2012 - acc: 0.9149 - val_loss: 0.2347 - val_acc: 0.8960\n",
      "Epoch 35/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2020 - acc: 0.9157 - val_loss: 0.2350 - val_acc: 0.8980\n",
      "Epoch 36/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2031 - acc: 0.9136 - val_loss: 0.2352 - val_acc: 0.8965\n",
      "Epoch 37/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2021 - acc: 0.9156 - val_loss: 0.2340 - val_acc: 0.8970\n",
      "Epoch 38/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2028 - acc: 0.9157 - val_loss: 0.2397 - val_acc: 0.8936\n",
      "Epoch 39/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2024 - acc: 0.9139 - val_loss: 0.2331 - val_acc: 0.8973\n",
      "Epoch 40/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2037 - acc: 0.9134 - val_loss: 0.2344 - val_acc: 0.8955\n",
      "Epoch 41/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2014 - acc: 0.9159 - val_loss: 0.2324 - val_acc: 0.8960\n",
      "Epoch 42/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2005 - acc: 0.9162 - val_loss: 0.2346 - val_acc: 0.8981\n",
      "Epoch 43/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2007 - acc: 0.9161 - val_loss: 0.2353 - val_acc: 0.8982\n",
      "Epoch 44/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2011 - acc: 0.9152 - val_loss: 0.2332 - val_acc: 0.8987\n",
      "Epoch 45/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2001 - acc: 0.9173 - val_loss: 0.2348 - val_acc: 0.8997\n",
      "Epoch 46/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2007 - acc: 0.9160 - val_loss: 0.2338 - val_acc: 0.8963\n",
      "Epoch 47/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2016 - acc: 0.9144 - val_loss: 0.2344 - val_acc: 0.8965\n",
      "Epoch 48/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2012 - acc: 0.9160 - val_loss: 0.2324 - val_acc: 0.8997\n",
      "Epoch 49/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2017 - acc: 0.9159 - val_loss: 0.2345 - val_acc: 0.8974\n",
      "Epoch 50/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2010 - acc: 0.9163 - val_loss: 0.2333 - val_acc: 0.8967\n",
      "Epoch 51/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1997 - acc: 0.9159 - val_loss: 0.2326 - val_acc: 0.8979\n",
      "Epoch 52/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2039 - acc: 0.9136 - val_loss: 0.2331 - val_acc: 0.8967\n",
      "Epoch 53/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2029 - acc: 0.9152 - val_loss: 0.2338 - val_acc: 0.8968\n",
      "Epoch 54/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2010 - acc: 0.9160 - val_loss: 0.2380 - val_acc: 0.8968\n",
      "Epoch 55/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2014 - acc: 0.9162 - val_loss: 0.2321 - val_acc: 0.8979\n",
      "Epoch 56/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2013 - acc: 0.9155 - val_loss: 0.2348 - val_acc: 0.8969\n",
      "Epoch 57/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2012 - acc: 0.9169 - val_loss: 0.2340 - val_acc: 0.8985\n",
      "Epoch 58/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2011 - acc: 0.9148 - val_loss: 0.2359 - val_acc: 0.8964\n",
      "Epoch 59/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1998 - acc: 0.9174 - val_loss: 0.2364 - val_acc: 0.8925\n",
      "Epoch 60/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2009 - acc: 0.9156 - val_loss: 0.2328 - val_acc: 0.8955\n",
      "Epoch 61/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2002 - acc: 0.9168 - val_loss: 0.2336 - val_acc: 0.8980\n",
      "Epoch 62/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1998 - acc: 0.9167 - val_loss: 0.2341 - val_acc: 0.8960\n",
      "Epoch 63/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2014 - acc: 0.9155 - val_loss: 0.2322 - val_acc: 0.8981\n",
      "Epoch 64/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2007 - acc: 0.9162 - val_loss: 0.2345 - val_acc: 0.8985\n",
      "Epoch 65/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2005 - acc: 0.9171 - val_loss: 0.2319 - val_acc: 0.8979\n",
      "Epoch 66/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2006 - acc: 0.9162 - val_loss: 0.2325 - val_acc: 0.8985\n",
      "Epoch 67/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1996 - acc: 0.9167 - val_loss: 0.2323 - val_acc: 0.8994\n",
      "Epoch 68/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2018 - acc: 0.9158 - val_loss: 0.2408 - val_acc: 0.8892\n",
      "Epoch 69/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2019 - acc: 0.9144 - val_loss: 0.2362 - val_acc: 0.8960\n",
      "Epoch 70/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2010 - acc: 0.9162 - val_loss: 0.2366 - val_acc: 0.8981\n",
      "Epoch 71/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2016 - acc: 0.9163 - val_loss: 0.2336 - val_acc: 0.8965\n",
      "Epoch 72/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2003 - acc: 0.9168 - val_loss: 0.2316 - val_acc: 0.8970\n",
      "Epoch 73/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1995 - acc: 0.9172 - val_loss: 0.2332 - val_acc: 0.8979\n",
      "Epoch 74/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.2032 - acc: 0.9145 - val_loss: 0.2362 - val_acc: 0.8963\n",
      "Epoch 75/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2014 - acc: 0.9160 - val_loss: 0.2321 - val_acc: 0.8978\n",
      "Epoch 76/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2041 - acc: 0.9143 - val_loss: 0.2404 - val_acc: 0.8903\n",
      "Epoch 77/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2038 - acc: 0.9132 - val_loss: 0.2373 - val_acc: 0.8926\n",
      "Epoch 78/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2012 - acc: 0.9162 - val_loss: 0.2338 - val_acc: 0.8967\n",
      "Epoch 79/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2028 - acc: 0.9148 - val_loss: 0.2338 - val_acc: 0.8979\n",
      "Epoch 80/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.2002 - acc: 0.9171 - val_loss: 0.2333 - val_acc: 0.8963\n",
      "Epoch 81/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2011 - acc: 0.9155 - val_loss: 0.2334 - val_acc: 0.8976\n",
      "Epoch 82/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2015 - acc: 0.9158 - val_loss: 0.2334 - val_acc: 0.8984\n",
      "Epoch 83/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2010 - acc: 0.9160 - val_loss: 0.2320 - val_acc: 0.8976\n",
      "Epoch 84/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2013 - acc: 0.9158 - val_loss: 0.2328 - val_acc: 0.8973\n",
      "Epoch 85/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2007 - acc: 0.9160 - val_loss: 0.2374 - val_acc: 0.8944\n",
      "Epoch 86/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2003 - acc: 0.9156 - val_loss: 0.2338 - val_acc: 0.8984\n",
      "Epoch 87/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2000 - acc: 0.9154 - val_loss: 0.2325 - val_acc: 0.8971\n",
      "Epoch 88/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2026 - acc: 0.9156 - val_loss: 0.2347 - val_acc: 0.8966\n",
      "Epoch 89/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2013 - acc: 0.9158 - val_loss: 0.2329 - val_acc: 0.8975\n",
      "Epoch 90/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1995 - acc: 0.9161 - val_loss: 0.2349 - val_acc: 0.8972\n",
      "Epoch 91/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2005 - acc: 0.9161 - val_loss: 0.2368 - val_acc: 0.8981\n",
      "Epoch 92/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2004 - acc: 0.9171 - val_loss: 0.2314 - val_acc: 0.8987\n",
      "Epoch 93/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2015 - acc: 0.9157 - val_loss: 0.2377 - val_acc: 0.8943\n",
      "Epoch 94/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.2001 - acc: 0.9161 - val_loss: 0.2331 - val_acc: 0.8981\n",
      "Epoch 95/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.2002 - acc: 0.9165 - val_loss: 0.2322 - val_acc: 0.8966\n",
      "Epoch 96/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1991 - acc: 0.9170 - val_loss: 0.2332 - val_acc: 0.8981\n",
      "Epoch 97/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1998 - acc: 0.9168 - val_loss: 0.2329 - val_acc: 0.8971\n",
      "Epoch 98/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2021 - acc: 0.9156 - val_loss: 0.2348 - val_acc: 0.8963\n",
      "Epoch 99/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2021 - acc: 0.9156 - val_loss: 0.2351 - val_acc: 0.8981\n",
      "Epoch 100/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1999 - acc: 0.9154 - val_loss: 0.2368 - val_acc: 0.8933\n",
      "Epoch 101/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1997 - acc: 0.9164 - val_loss: 0.2386 - val_acc: 0.8955\n",
      "Epoch 102/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1997 - acc: 0.9160 - val_loss: 0.2337 - val_acc: 0.8961\n",
      "Epoch 103/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2000 - acc: 0.9162 - val_loss: 0.2363 - val_acc: 0.8937\n",
      "Epoch 104/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2011 - acc: 0.9150 - val_loss: 0.2335 - val_acc: 0.8984\n",
      "Epoch 105/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1998 - acc: 0.9166 - val_loss: 0.2312 - val_acc: 0.8994\n",
      "Epoch 106/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2000 - acc: 0.9172 - val_loss: 0.2337 - val_acc: 0.8984\n",
      "Epoch 107/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2008 - acc: 0.9165 - val_loss: 0.2335 - val_acc: 0.8981\n",
      "Epoch 108/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2006 - acc: 0.9163 - val_loss: 0.2307 - val_acc: 0.8992\n",
      "Epoch 109/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2002 - acc: 0.9169 - val_loss: 0.2320 - val_acc: 0.8980\n",
      "Epoch 110/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2008 - acc: 0.9162 - val_loss: 0.2334 - val_acc: 0.8982\n",
      "Epoch 111/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1996 - acc: 0.9170 - val_loss: 0.2329 - val_acc: 0.8989\n",
      "Epoch 112/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2002 - acc: 0.9148 - val_loss: 0.2352 - val_acc: 0.8984\n",
      "Epoch 113/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2008 - acc: 0.9166 - val_loss: 0.2316 - val_acc: 0.8974\n",
      "Epoch 114/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2006 - acc: 0.9167 - val_loss: 0.2328 - val_acc: 0.8964\n",
      "Epoch 115/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2001 - acc: 0.9168 - val_loss: 0.2336 - val_acc: 0.8981\n",
      "Epoch 116/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2014 - acc: 0.9161 - val_loss: 0.2334 - val_acc: 0.8971\n",
      "Epoch 117/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2000 - acc: 0.9162 - val_loss: 0.2349 - val_acc: 0.8995\n",
      "Epoch 118/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1998 - acc: 0.9167 - val_loss: 0.2343 - val_acc: 0.8977\n",
      "Epoch 119/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2005 - acc: 0.9162 - val_loss: 0.2308 - val_acc: 0.8991\n",
      "Epoch 120/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2001 - acc: 0.9169 - val_loss: 0.2334 - val_acc: 0.8974\n",
      "Epoch 121/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1991 - acc: 0.9172 - val_loss: 0.2330 - val_acc: 0.8979\n",
      "Epoch 122/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1996 - acc: 0.9173 - val_loss: 0.2309 - val_acc: 0.8979\n",
      "Epoch 123/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2000 - acc: 0.9155 - val_loss: 0.2340 - val_acc: 0.8969\n",
      "Epoch 124/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2023 - acc: 0.9155 - val_loss: 0.2335 - val_acc: 0.8978\n",
      "Epoch 125/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2013 - acc: 0.9154 - val_loss: 0.2339 - val_acc: 0.8964\n",
      "Epoch 126/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.2008 - acc: 0.9159 - val_loss: 0.2354 - val_acc: 0.8976\n",
      "Epoch 127/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1997 - acc: 0.9175 - val_loss: 0.2334 - val_acc: 0.8966\n",
      "Epoch 128/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1999 - acc: 0.9161 - val_loss: 0.2327 - val_acc: 0.8973\n",
      "Epoch 129/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1999 - acc: 0.9163 - val_loss: 0.2329 - val_acc: 0.8994\n",
      "Epoch 130/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2003 - acc: 0.9167 - val_loss: 0.2342 - val_acc: 0.8982\n",
      "Epoch 131/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.2017 - acc: 0.9162 - val_loss: 0.2515 - val_acc: 0.8890\n",
      "Epoch 132/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.2033 - acc: 0.9149 - val_loss: 0.2335 - val_acc: 0.8979\n",
      "Epoch 133/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2012 - acc: 0.9155 - val_loss: 0.2355 - val_acc: 0.8980\n",
      "Epoch 134/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.2025 - acc: 0.9158 - val_loss: 0.2346 - val_acc: 0.8992\n",
      "Epoch 135/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.2000 - acc: 0.9162 - val_loss: 0.2331 - val_acc: 0.8994\n",
      "Epoch 136/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2014 - acc: 0.9143 - val_loss: 0.2311 - val_acc: 0.8976\n",
      "Epoch 137/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2009 - acc: 0.9157 - val_loss: 0.2331 - val_acc: 0.8966\n",
      "Epoch 138/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1998 - acc: 0.9172 - val_loss: 0.2298 - val_acc: 0.8987\n",
      "Epoch 139/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2005 - acc: 0.9160 - val_loss: 0.2342 - val_acc: 0.8939\n",
      "Epoch 140/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1999 - acc: 0.9165 - val_loss: 0.2318 - val_acc: 0.8995\n",
      "Epoch 141/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.2002 - acc: 0.9161 - val_loss: 0.2319 - val_acc: 0.8982\n",
      "Epoch 142/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1988 - acc: 0.9172 - val_loss: 0.2338 - val_acc: 0.8975\n",
      "Epoch 143/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1998 - acc: 0.9167 - val_loss: 0.2339 - val_acc: 0.8958\n",
      "Epoch 144/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1996 - acc: 0.9171 - val_loss: 0.2327 - val_acc: 0.8984\n",
      "Epoch 145/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2006 - acc: 0.9162 - val_loss: 0.2338 - val_acc: 0.8979\n",
      "Epoch 146/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2014 - acc: 0.9158 - val_loss: 0.2339 - val_acc: 0.8979\n",
      "Epoch 147/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2007 - acc: 0.9163 - val_loss: 0.2350 - val_acc: 0.8964\n",
      "Epoch 148/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1998 - acc: 0.9167 - val_loss: 0.2334 - val_acc: 0.8988\n",
      "Epoch 149/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1990 - acc: 0.9173 - val_loss: 0.2342 - val_acc: 0.8964\n",
      "Epoch 150/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2004 - acc: 0.9165 - val_loss: 0.2335 - val_acc: 0.9001\n",
      "Epoch 151/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2000 - acc: 0.9169 - val_loss: 0.2348 - val_acc: 0.8966\n",
      "Epoch 152/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2003 - acc: 0.9173 - val_loss: 0.2327 - val_acc: 0.8984\n",
      "Epoch 153/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2000 - acc: 0.9163 - val_loss: 0.2353 - val_acc: 0.8969\n",
      "Epoch 154/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2004 - acc: 0.9162 - val_loss: 0.2328 - val_acc: 0.8986\n",
      "Epoch 155/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2006 - acc: 0.9172 - val_loss: 0.2330 - val_acc: 0.8989\n",
      "Epoch 156/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1997 - acc: 0.9172 - val_loss: 0.2325 - val_acc: 0.8969\n",
      "Epoch 157/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1995 - acc: 0.9176 - val_loss: 0.2306 - val_acc: 0.8992\n",
      "Epoch 158/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2009 - acc: 0.9168 - val_loss: 0.2407 - val_acc: 0.8983\n",
      "Epoch 159/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2003 - acc: 0.9158 - val_loss: 0.2356 - val_acc: 0.8955\n",
      "Epoch 160/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2001 - acc: 0.9162 - val_loss: 0.2349 - val_acc: 0.8963\n",
      "Epoch 161/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1994 - acc: 0.9162 - val_loss: 0.2334 - val_acc: 0.8979\n",
      "Epoch 162/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2003 - acc: 0.9161 - val_loss: 0.2340 - val_acc: 0.8968\n",
      "Epoch 163/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1996 - acc: 0.9167 - val_loss: 0.2344 - val_acc: 0.8982\n",
      "Epoch 164/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1989 - acc: 0.9165 - val_loss: 0.2339 - val_acc: 0.8985\n",
      "Epoch 165/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1995 - acc: 0.9166 - val_loss: 0.2324 - val_acc: 0.8971\n",
      "Epoch 166/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1994 - acc: 0.9163 - val_loss: 0.2326 - val_acc: 0.8989\n",
      "Epoch 167/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1991 - acc: 0.9170 - val_loss: 0.2357 - val_acc: 0.8958\n",
      "Epoch 168/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2000 - acc: 0.9166 - val_loss: 0.2342 - val_acc: 0.8974\n",
      "Epoch 169/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1994 - acc: 0.9168 - val_loss: 0.2341 - val_acc: 0.8963\n",
      "Epoch 170/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1999 - acc: 0.9162 - val_loss: 0.2326 - val_acc: 0.8968\n",
      "Epoch 171/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9173 - val_loss: 0.2337 - val_acc: 0.8973\n",
      "Epoch 172/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1997 - acc: 0.9163 - val_loss: 0.2331 - val_acc: 0.8988\n",
      "Epoch 173/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1985 - acc: 0.9170 - val_loss: 0.2326 - val_acc: 0.8990\n",
      "Epoch 174/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1993 - acc: 0.9166 - val_loss: 0.2312 - val_acc: 0.8981\n",
      "Epoch 175/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1990 - acc: 0.9172 - val_loss: 0.2316 - val_acc: 0.8978\n",
      "Epoch 176/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1995 - acc: 0.9162 - val_loss: 0.2345 - val_acc: 0.8978\n",
      "Epoch 177/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1997 - acc: 0.9169 - val_loss: 0.2339 - val_acc: 0.8986\n",
      "Epoch 178/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1994 - acc: 0.9161 - val_loss: 0.2354 - val_acc: 0.8963\n",
      "Epoch 179/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1997 - acc: 0.9167 - val_loss: 0.2362 - val_acc: 0.8968\n",
      "Epoch 180/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1998 - acc: 0.9167 - val_loss: 0.2344 - val_acc: 0.8971\n",
      "Epoch 181/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2017 - acc: 0.9148 - val_loss: 0.2347 - val_acc: 0.8965\n",
      "Epoch 182/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1985 - acc: 0.9164 - val_loss: 0.2360 - val_acc: 0.8980\n",
      "Epoch 183/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1988 - acc: 0.9174 - val_loss: 0.2349 - val_acc: 0.8967\n",
      "Epoch 184/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1989 - acc: 0.9170 - val_loss: 0.2334 - val_acc: 0.8968\n",
      "Epoch 185/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2006 - acc: 0.9160 - val_loss: 0.2382 - val_acc: 0.8931\n",
      "Epoch 186/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2004 - acc: 0.9158 - val_loss: 0.2380 - val_acc: 0.8969\n",
      "Epoch 187/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1994 - acc: 0.9168 - val_loss: 0.2331 - val_acc: 0.8969\n",
      "Epoch 188/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2016 - acc: 0.9156 - val_loss: 0.2345 - val_acc: 0.8968\n",
      "Epoch 189/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2012 - acc: 0.9159 - val_loss: 0.2332 - val_acc: 0.8998\n",
      "Epoch 190/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2007 - acc: 0.9163 - val_loss: 0.2324 - val_acc: 0.8978\n",
      "Epoch 191/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1994 - acc: 0.9159 - val_loss: 0.2353 - val_acc: 0.8966\n",
      "Epoch 192/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9171 - val_loss: 0.2323 - val_acc: 0.8980\n",
      "Epoch 193/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9169 - val_loss: 0.2341 - val_acc: 0.8969\n",
      "Epoch 194/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1995 - acc: 0.9167 - val_loss: 0.2335 - val_acc: 0.8971\n",
      "Epoch 195/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.2001 - acc: 0.9159 - val_loss: 0.2308 - val_acc: 0.8976\n",
      "Epoch 196/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1991 - acc: 0.9172 - val_loss: 0.2342 - val_acc: 0.8978\n",
      "Epoch 197/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1990 - acc: 0.9171 - val_loss: 0.2357 - val_acc: 0.8959\n",
      "Epoch 198/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1988 - acc: 0.9162 - val_loss: 0.2319 - val_acc: 0.8973\n",
      "Epoch 199/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1993 - acc: 0.9160 - val_loss: 0.2337 - val_acc: 0.8969\n",
      "Epoch 200/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1994 - acc: 0.9162 - val_loss: 0.2324 - val_acc: 0.8977\n",
      "Epoch 201/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1988 - acc: 0.9162 - val_loss: 0.2334 - val_acc: 0.8965\n",
      "Epoch 202/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2004 - acc: 0.9155 - val_loss: 0.2375 - val_acc: 0.8979\n",
      "Epoch 203/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1996 - acc: 0.9162 - val_loss: 0.2352 - val_acc: 0.8934\n",
      "Epoch 204/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2000 - acc: 0.9156 - val_loss: 0.2332 - val_acc: 0.8980\n",
      "Epoch 205/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1996 - acc: 0.9160 - val_loss: 0.2368 - val_acc: 0.8979\n",
      "Epoch 206/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2007 - acc: 0.9164 - val_loss: 0.2328 - val_acc: 0.8960\n",
      "Epoch 207/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1997 - acc: 0.9165 - val_loss: 0.2338 - val_acc: 0.8965\n",
      "Epoch 208/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9170 - val_loss: 0.2320 - val_acc: 0.8967\n",
      "Epoch 209/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1992 - acc: 0.9166 - val_loss: 0.2320 - val_acc: 0.8962\n",
      "Epoch 210/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1980 - acc: 0.9171 - val_loss: 0.2357 - val_acc: 0.8959\n",
      "Epoch 211/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1998 - acc: 0.9174 - val_loss: 0.2384 - val_acc: 0.8923\n",
      "Epoch 212/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2002 - acc: 0.9155 - val_loss: 0.2352 - val_acc: 0.8973\n",
      "Epoch 213/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1996 - acc: 0.9169 - val_loss: 0.2323 - val_acc: 0.8987\n",
      "Epoch 214/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1996 - acc: 0.9166 - val_loss: 0.2313 - val_acc: 0.8983\n",
      "Epoch 215/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9169 - val_loss: 0.2325 - val_acc: 0.8989\n",
      "Epoch 216/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1985 - acc: 0.9164 - val_loss: 0.2328 - val_acc: 0.8968\n",
      "Epoch 217/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2001 - acc: 0.9161 - val_loss: 0.2352 - val_acc: 0.8986\n",
      "Epoch 218/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1991 - acc: 0.9167 - val_loss: 0.2358 - val_acc: 0.9002\n",
      "Epoch 219/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1995 - acc: 0.9169 - val_loss: 0.2353 - val_acc: 0.8960\n",
      "Epoch 220/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9177 - val_loss: 0.2355 - val_acc: 0.8963\n",
      "Epoch 221/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1988 - acc: 0.9175 - val_loss: 0.2311 - val_acc: 0.9002\n",
      "Epoch 222/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1983 - acc: 0.9176 - val_loss: 0.2341 - val_acc: 0.8958\n",
      "Epoch 223/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9173 - val_loss: 0.2315 - val_acc: 0.8999\n",
      "Epoch 224/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9172 - val_loss: 0.2311 - val_acc: 0.8987\n",
      "Epoch 225/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1985 - acc: 0.9170 - val_loss: 0.2341 - val_acc: 0.8995\n",
      "Epoch 226/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1995 - acc: 0.9164 - val_loss: 0.2336 - val_acc: 0.8982\n",
      "Epoch 227/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9171 - val_loss: 0.2338 - val_acc: 0.8982\n",
      "Epoch 228/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9168 - val_loss: 0.2339 - val_acc: 0.8963\n",
      "Epoch 229/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1982 - acc: 0.9169 - val_loss: 0.2324 - val_acc: 0.8976\n",
      "Epoch 230/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1993 - acc: 0.9167 - val_loss: 0.2331 - val_acc: 0.8966\n",
      "Epoch 231/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9177 - val_loss: 0.2311 - val_acc: 0.8979\n",
      "Epoch 232/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9178 - val_loss: 0.2334 - val_acc: 0.8979\n",
      "Epoch 233/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1999 - acc: 0.9162 - val_loss: 0.2359 - val_acc: 0.8972\n",
      "Epoch 234/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1977 - acc: 0.9184 - val_loss: 0.2339 - val_acc: 0.8963\n",
      "Epoch 235/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1998 - acc: 0.9164 - val_loss: 0.2346 - val_acc: 0.8943\n",
      "Epoch 236/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1993 - acc: 0.9155 - val_loss: 0.2324 - val_acc: 0.8997\n",
      "Epoch 237/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2007 - acc: 0.9162 - val_loss: 0.2344 - val_acc: 0.8995\n",
      "Epoch 238/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1984 - acc: 0.9160 - val_loss: 0.2327 - val_acc: 0.8982\n",
      "Epoch 239/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1985 - acc: 0.9166 - val_loss: 0.2347 - val_acc: 0.8961\n",
      "Epoch 240/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.2007 - acc: 0.9157 - val_loss: 0.2364 - val_acc: 0.8966\n",
      "Epoch 241/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1992 - acc: 0.9160 - val_loss: 0.2380 - val_acc: 0.8939\n",
      "Epoch 242/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1991 - acc: 0.9157 - val_loss: 0.2347 - val_acc: 0.8942\n",
      "Epoch 243/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1986 - acc: 0.9179 - val_loss: 0.2355 - val_acc: 0.8958\n",
      "Epoch 244/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1990 - acc: 0.9168 - val_loss: 0.2344 - val_acc: 0.8960\n",
      "Epoch 245/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1984 - acc: 0.9168 - val_loss: 0.2330 - val_acc: 0.8976\n",
      "Epoch 246/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1990 - acc: 0.9171 - val_loss: 0.2394 - val_acc: 0.8939\n",
      "Epoch 247/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1993 - acc: 0.9165 - val_loss: 0.2338 - val_acc: 0.8979\n",
      "Epoch 248/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1979 - acc: 0.9169 - val_loss: 0.2343 - val_acc: 0.8957\n",
      "Epoch 249/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9173 - val_loss: 0.2346 - val_acc: 0.8960\n",
      "Epoch 250/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1992 - acc: 0.9162 - val_loss: 0.2316 - val_acc: 0.8979\n",
      "Epoch 251/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1993 - acc: 0.9164 - val_loss: 0.2343 - val_acc: 0.8986\n",
      "Epoch 252/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1978 - acc: 0.9169 - val_loss: 0.2362 - val_acc: 0.8953\n",
      "Epoch 253/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2000 - acc: 0.9162 - val_loss: 0.2608 - val_acc: 0.8924\n",
      "Epoch 254/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2013 - acc: 0.9156 - val_loss: 0.2327 - val_acc: 0.8967\n",
      "Epoch 255/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1988 - acc: 0.9163 - val_loss: 0.2336 - val_acc: 0.8986\n",
      "Epoch 256/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1988 - acc: 0.9177 - val_loss: 0.2353 - val_acc: 0.8959\n",
      "Epoch 257/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1993 - acc: 0.9167 - val_loss: 0.2371 - val_acc: 0.8952\n",
      "Epoch 258/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1984 - acc: 0.9169 - val_loss: 0.2351 - val_acc: 0.8958\n",
      "Epoch 259/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1983 - acc: 0.9169 - val_loss: 0.2323 - val_acc: 0.8971\n",
      "Epoch 260/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1986 - acc: 0.9164 - val_loss: 0.2330 - val_acc: 0.8974\n",
      "Epoch 261/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1985 - acc: 0.9162 - val_loss: 0.2352 - val_acc: 0.8973\n",
      "Epoch 262/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9168 - val_loss: 0.2331 - val_acc: 0.8983\n",
      "Epoch 263/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1994 - acc: 0.9167 - val_loss: 0.2350 - val_acc: 0.8978\n",
      "Epoch 264/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1978 - acc: 0.9174 - val_loss: 0.2343 - val_acc: 0.8963\n",
      "Epoch 265/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1981 - acc: 0.9166 - val_loss: 0.2437 - val_acc: 0.8895\n",
      "Epoch 266/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1979 - acc: 0.9174 - val_loss: 0.2331 - val_acc: 0.8976\n",
      "Epoch 267/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1991 - acc: 0.9164 - val_loss: 0.2371 - val_acc: 0.8958\n",
      "Epoch 268/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9167 - val_loss: 0.2391 - val_acc: 0.8927\n",
      "Epoch 269/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1993 - acc: 0.9161 - val_loss: 0.2366 - val_acc: 0.8983\n",
      "Epoch 270/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1986 - acc: 0.9177 - val_loss: 0.2357 - val_acc: 0.9005\n",
      "Epoch 271/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1992 - acc: 0.9164 - val_loss: 0.2363 - val_acc: 0.8970\n",
      "Epoch 272/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1986 - acc: 0.9171 - val_loss: 0.2334 - val_acc: 0.8976\n",
      "Epoch 273/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1986 - acc: 0.9162 - val_loss: 0.2324 - val_acc: 0.8963\n",
      "Epoch 274/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1994 - acc: 0.9158 - val_loss: 0.2378 - val_acc: 0.8940\n",
      "Epoch 275/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1992 - acc: 0.9165 - val_loss: 0.2359 - val_acc: 0.8937\n",
      "Epoch 276/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1981 - acc: 0.9179 - val_loss: 0.2333 - val_acc: 0.8944\n",
      "Epoch 277/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1996 - acc: 0.9163 - val_loss: 0.2352 - val_acc: 0.8962\n",
      "Epoch 278/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1999 - acc: 0.9162 - val_loss: 0.2390 - val_acc: 0.8989\n",
      "Epoch 279/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1997 - acc: 0.9169 - val_loss: 0.2320 - val_acc: 0.8967\n",
      "Epoch 280/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.2007 - acc: 0.9150 - val_loss: 0.2404 - val_acc: 0.8894\n",
      "Epoch 281/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1995 - acc: 0.9146 - val_loss: 0.2353 - val_acc: 0.8980\n",
      "Epoch 282/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9165 - val_loss: 0.2362 - val_acc: 0.8952\n",
      "Epoch 283/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1990 - acc: 0.9169 - val_loss: 0.2360 - val_acc: 0.8973\n",
      "Epoch 284/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1988 - acc: 0.9157 - val_loss: 0.2346 - val_acc: 0.8955\n",
      "Epoch 285/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1999 - acc: 0.9164 - val_loss: 0.2348 - val_acc: 0.8977\n",
      "Epoch 286/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1994 - acc: 0.9162 - val_loss: 0.2329 - val_acc: 0.8987\n",
      "Epoch 287/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1978 - acc: 0.9169 - val_loss: 0.2364 - val_acc: 0.8950\n",
      "Epoch 288/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1980 - acc: 0.9162 - val_loss: 0.2333 - val_acc: 0.8984\n",
      "Epoch 289/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1976 - acc: 0.9163 - val_loss: 0.2342 - val_acc: 0.8977\n",
      "Epoch 290/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1975 - acc: 0.9170 - val_loss: 0.2342 - val_acc: 0.8961\n",
      "Epoch 291/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9171 - val_loss: 0.2401 - val_acc: 0.8958\n",
      "Epoch 292/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9173 - val_loss: 0.2355 - val_acc: 0.8959\n",
      "Epoch 293/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1991 - acc: 0.9152 - val_loss: 0.2340 - val_acc: 0.8974\n",
      "Epoch 294/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1980 - acc: 0.9172 - val_loss: 0.2347 - val_acc: 0.8954\n",
      "Epoch 295/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1978 - acc: 0.9177 - val_loss: 0.2329 - val_acc: 0.8960\n",
      "Epoch 296/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1980 - acc: 0.9170 - val_loss: 0.2348 - val_acc: 0.8945\n",
      "Epoch 297/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1991 - acc: 0.9157 - val_loss: 0.2332 - val_acc: 0.8961\n",
      "Epoch 298/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1976 - acc: 0.9177 - val_loss: 0.2374 - val_acc: 0.8952\n",
      "Epoch 299/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1994 - acc: 0.9164 - val_loss: 0.2361 - val_acc: 0.8970\n",
      "Epoch 300/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1992 - acc: 0.9175 - val_loss: 0.2351 - val_acc: 0.8964\n",
      "Epoch 301/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1982 - acc: 0.9169 - val_loss: 0.2342 - val_acc: 0.8967\n",
      "Epoch 302/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1980 - acc: 0.9177 - val_loss: 0.2322 - val_acc: 0.8978\n",
      "Epoch 303/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1978 - acc: 0.9171 - val_loss: 0.2313 - val_acc: 0.8976\n",
      "Epoch 304/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9160 - val_loss: 0.2345 - val_acc: 0.8967\n",
      "Epoch 305/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1987 - acc: 0.9172 - val_loss: 0.2334 - val_acc: 0.8963\n",
      "Epoch 306/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1986 - acc: 0.9177 - val_loss: 0.2336 - val_acc: 0.8966\n",
      "Epoch 307/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1996 - acc: 0.9179 - val_loss: 0.2332 - val_acc: 0.8992\n",
      "Epoch 308/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9174 - val_loss: 0.2337 - val_acc: 0.8983\n",
      "Epoch 309/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1977 - acc: 0.9178 - val_loss: 0.2326 - val_acc: 0.8978\n",
      "Epoch 310/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1984 - acc: 0.9180 - val_loss: 0.2323 - val_acc: 0.8979\n",
      "Epoch 311/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1986 - acc: 0.9165 - val_loss: 0.2331 - val_acc: 0.8993\n",
      "Epoch 312/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1976 - acc: 0.9166 - val_loss: 0.2335 - val_acc: 0.8962\n",
      "Epoch 313/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9171 - val_loss: 0.2319 - val_acc: 0.8968\n",
      "Epoch 314/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1986 - acc: 0.9162 - val_loss: 0.2386 - val_acc: 0.8923\n",
      "Epoch 315/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1988 - acc: 0.9170 - val_loss: 0.2359 - val_acc: 0.8980\n",
      "Epoch 316/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1981 - acc: 0.9170 - val_loss: 0.2350 - val_acc: 0.8962\n",
      "Epoch 317/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1985 - acc: 0.9164 - val_loss: 0.2393 - val_acc: 0.8925\n",
      "Epoch 318/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1988 - acc: 0.9169 - val_loss: 0.2351 - val_acc: 0.8962\n",
      "Epoch 319/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1979 - acc: 0.9172 - val_loss: 0.2356 - val_acc: 0.8947\n",
      "Epoch 320/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1997 - acc: 0.9156 - val_loss: 0.2334 - val_acc: 0.8968\n",
      "Epoch 321/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1988 - acc: 0.9171 - val_loss: 0.2349 - val_acc: 0.8967\n",
      "Epoch 322/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9177 - val_loss: 0.2350 - val_acc: 0.8972\n",
      "Epoch 323/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2003 - acc: 0.9177 - val_loss: 0.2334 - val_acc: 0.8963\n",
      "Epoch 324/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1980 - acc: 0.9168 - val_loss: 0.2337 - val_acc: 0.8997\n",
      "Epoch 325/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9170 - val_loss: 0.2382 - val_acc: 0.8920\n",
      "Epoch 326/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1979 - acc: 0.9167 - val_loss: 0.2334 - val_acc: 0.8976\n",
      "Epoch 327/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1983 - acc: 0.9168 - val_loss: 0.2328 - val_acc: 0.8957\n",
      "Epoch 328/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1989 - acc: 0.9159 - val_loss: 0.2354 - val_acc: 0.8952\n",
      "Epoch 329/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1986 - acc: 0.9169 - val_loss: 0.2331 - val_acc: 0.8967\n",
      "Epoch 330/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1996 - acc: 0.9160 - val_loss: 0.2354 - val_acc: 0.8975\n",
      "Epoch 331/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1979 - acc: 0.9180 - val_loss: 0.2341 - val_acc: 0.8984\n",
      "Epoch 332/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1976 - acc: 0.9173 - val_loss: 0.2349 - val_acc: 0.8939\n",
      "Epoch 333/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1981 - acc: 0.9172 - val_loss: 0.2369 - val_acc: 0.8967\n",
      "Epoch 334/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1973 - acc: 0.9170 - val_loss: 0.2364 - val_acc: 0.8968\n",
      "Epoch 335/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1978 - acc: 0.9175 - val_loss: 0.2376 - val_acc: 0.8961\n",
      "Epoch 336/1500\n",
      "20704/20704 [==============================] - 1s 26us/step - loss: 0.1983 - acc: 0.9167 - val_loss: 0.2364 - val_acc: 0.8972\n",
      "Epoch 337/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1981 - acc: 0.9174 - val_loss: 0.2368 - val_acc: 0.8952\n",
      "Epoch 338/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1988 - acc: 0.9164 - val_loss: 0.2351 - val_acc: 0.8966\n",
      "Epoch 339/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1979 - acc: 0.9169 - val_loss: 0.2339 - val_acc: 0.8968\n",
      "Epoch 340/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1980 - acc: 0.9175 - val_loss: 0.2337 - val_acc: 0.8987\n",
      "Epoch 341/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1968 - acc: 0.9180 - val_loss: 0.2373 - val_acc: 0.8947\n",
      "Epoch 342/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1989 - acc: 0.9174 - val_loss: 0.2344 - val_acc: 0.8983\n",
      "Epoch 343/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1979 - acc: 0.9170 - val_loss: 0.2354 - val_acc: 0.8955\n",
      "Epoch 344/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1992 - acc: 0.9169 - val_loss: 0.2357 - val_acc: 0.8944\n",
      "Epoch 345/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1986 - acc: 0.9167 - val_loss: 0.2350 - val_acc: 0.8964\n",
      "Epoch 346/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1987 - acc: 0.9165 - val_loss: 0.2338 - val_acc: 0.8956\n",
      "Epoch 347/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1984 - acc: 0.9177 - val_loss: 0.2328 - val_acc: 0.8971\n",
      "Epoch 348/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9178 - val_loss: 0.2343 - val_acc: 0.8970\n",
      "Epoch 349/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1976 - acc: 0.9175 - val_loss: 0.2364 - val_acc: 0.8936\n",
      "Epoch 350/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1989 - acc: 0.9173 - val_loss: 0.2345 - val_acc: 0.8987\n",
      "Epoch 351/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1976 - acc: 0.9172 - val_loss: 0.2328 - val_acc: 0.8987\n",
      "Epoch 352/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1975 - acc: 0.9175 - val_loss: 0.2351 - val_acc: 0.8969\n",
      "Epoch 353/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9171 - val_loss: 0.2329 - val_acc: 0.8969\n",
      "Epoch 354/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1980 - acc: 0.9172 - val_loss: 0.2331 - val_acc: 0.8985\n",
      "Epoch 355/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1970 - acc: 0.9184 - val_loss: 0.2331 - val_acc: 0.8994\n",
      "Epoch 356/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1984 - acc: 0.9177 - val_loss: 0.2336 - val_acc: 0.8967\n",
      "Epoch 357/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1992 - acc: 0.9173 - val_loss: 0.2342 - val_acc: 0.8958\n",
      "Epoch 358/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1978 - acc: 0.9165 - val_loss: 0.2355 - val_acc: 0.8975\n",
      "Epoch 359/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1990 - acc: 0.9161 - val_loss: 0.2407 - val_acc: 0.8932\n",
      "Epoch 360/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1987 - acc: 0.9160 - val_loss: 0.2348 - val_acc: 0.8958\n",
      "Epoch 361/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1976 - acc: 0.9174 - val_loss: 0.2349 - val_acc: 0.8993\n",
      "Epoch 362/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1979 - acc: 0.9180 - val_loss: 0.2335 - val_acc: 0.8979\n",
      "Epoch 363/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1980 - acc: 0.9174 - val_loss: 0.2368 - val_acc: 0.8947\n",
      "Epoch 364/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9182 - val_loss: 0.2373 - val_acc: 0.8981\n",
      "Epoch 365/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1981 - acc: 0.9166 - val_loss: 0.2348 - val_acc: 0.8937\n",
      "Epoch 366/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1982 - acc: 0.9170 - val_loss: 0.2348 - val_acc: 0.8962\n",
      "Epoch 367/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1996 - acc: 0.9169 - val_loss: 0.2343 - val_acc: 0.8960\n",
      "Epoch 368/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1984 - acc: 0.9168 - val_loss: 0.2343 - val_acc: 0.8964\n",
      "Epoch 369/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1981 - acc: 0.9169 - val_loss: 0.2338 - val_acc: 0.8995\n",
      "Epoch 370/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1988 - acc: 0.9172 - val_loss: 0.2342 - val_acc: 0.8979\n",
      "Epoch 371/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1986 - acc: 0.9176 - val_loss: 0.2338 - val_acc: 0.8971\n",
      "Epoch 372/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1977 - acc: 0.9181 - val_loss: 0.2335 - val_acc: 0.8976\n",
      "Epoch 373/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1981 - acc: 0.9172 - val_loss: 0.2344 - val_acc: 0.8973\n",
      "Epoch 374/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1977 - acc: 0.9161 - val_loss: 0.2343 - val_acc: 0.8993\n",
      "Epoch 375/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1982 - acc: 0.9173 - val_loss: 0.2343 - val_acc: 0.8992\n",
      "Epoch 376/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1981 - acc: 0.9167 - val_loss: 0.2370 - val_acc: 0.8975\n",
      "Epoch 377/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1971 - acc: 0.9181 - val_loss: 0.2333 - val_acc: 0.8966\n",
      "Epoch 378/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1984 - acc: 0.9164 - val_loss: 0.2334 - val_acc: 0.8972\n",
      "Epoch 379/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1971 - acc: 0.9183 - val_loss: 0.2341 - val_acc: 0.8966\n",
      "Epoch 380/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1971 - acc: 0.9169 - val_loss: 0.2329 - val_acc: 0.8977\n",
      "Epoch 381/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1976 - acc: 0.9176 - val_loss: 0.2381 - val_acc: 0.8947\n",
      "Epoch 382/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1980 - acc: 0.9171 - val_loss: 0.2411 - val_acc: 0.8934\n",
      "Epoch 383/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1995 - acc: 0.9155 - val_loss: 0.2342 - val_acc: 0.8979\n",
      "Epoch 384/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1996 - acc: 0.9158 - val_loss: 0.2375 - val_acc: 0.8945\n",
      "Epoch 385/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1976 - acc: 0.9171 - val_loss: 0.2337 - val_acc: 0.8981\n",
      "Epoch 386/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1982 - acc: 0.9178 - val_loss: 0.2343 - val_acc: 0.8976\n",
      "Epoch 387/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1973 - acc: 0.9171 - val_loss: 0.2355 - val_acc: 0.8949\n",
      "Epoch 388/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1979 - acc: 0.9170 - val_loss: 0.2334 - val_acc: 0.8971\n",
      "Epoch 389/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9176 - val_loss: 0.2341 - val_acc: 0.8951\n",
      "Epoch 390/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1985 - acc: 0.9173 - val_loss: 0.2610 - val_acc: 0.8920\n",
      "Epoch 391/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1992 - acc: 0.9159 - val_loss: 0.2369 - val_acc: 0.8952\n",
      "Epoch 392/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1966 - acc: 0.9179 - val_loss: 0.2349 - val_acc: 0.8975\n",
      "Epoch 393/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1970 - acc: 0.9177 - val_loss: 0.2346 - val_acc: 0.8970\n",
      "Epoch 394/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1978 - acc: 0.9172 - val_loss: 0.2359 - val_acc: 0.8981\n",
      "Epoch 395/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1976 - acc: 0.9176 - val_loss: 0.2329 - val_acc: 0.8969\n",
      "Epoch 396/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9172 - val_loss: 0.2348 - val_acc: 0.8990\n",
      "Epoch 397/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1980 - acc: 0.9178 - val_loss: 0.2339 - val_acc: 0.8975\n",
      "Epoch 398/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9168 - val_loss: 0.2349 - val_acc: 0.8974\n",
      "Epoch 399/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1975 - acc: 0.9175 - val_loss: 0.2380 - val_acc: 0.8938\n",
      "Epoch 400/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1984 - acc: 0.9169 - val_loss: 0.2354 - val_acc: 0.8966\n",
      "Epoch 401/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1974 - acc: 0.9170 - val_loss: 0.2349 - val_acc: 0.8961\n",
      "Epoch 402/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1967 - acc: 0.9174 - val_loss: 0.2374 - val_acc: 0.8970\n",
      "Epoch 403/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1979 - acc: 0.9171 - val_loss: 0.2339 - val_acc: 0.8977\n",
      "Epoch 404/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1974 - acc: 0.9183 - val_loss: 0.2332 - val_acc: 0.8984\n",
      "Epoch 405/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1983 - acc: 0.9166 - val_loss: 0.2343 - val_acc: 0.8953\n",
      "Epoch 406/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9178 - val_loss: 0.2341 - val_acc: 0.8990\n",
      "Epoch 407/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1982 - acc: 0.9179 - val_loss: 0.2351 - val_acc: 0.8958\n",
      "Epoch 408/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9176 - val_loss: 0.2356 - val_acc: 0.8972\n",
      "Epoch 409/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9171 - val_loss: 0.2361 - val_acc: 0.8949\n",
      "Epoch 410/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9168 - val_loss: 0.2348 - val_acc: 0.8971\n",
      "Epoch 411/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9181 - val_loss: 0.2334 - val_acc: 0.8958\n",
      "Epoch 412/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1984 - acc: 0.9166 - val_loss: 0.2310 - val_acc: 0.8996\n",
      "Epoch 413/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1982 - acc: 0.9168 - val_loss: 0.2321 - val_acc: 0.8994\n",
      "Epoch 414/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9182 - val_loss: 0.2364 - val_acc: 0.8956\n",
      "Epoch 415/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1980 - acc: 0.9163 - val_loss: 0.2352 - val_acc: 0.8985\n",
      "Epoch 416/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1978 - acc: 0.9167 - val_loss: 0.2347 - val_acc: 0.8988\n",
      "Epoch 417/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9166 - val_loss: 0.2337 - val_acc: 0.8970\n",
      "Epoch 418/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1980 - acc: 0.9170 - val_loss: 0.2336 - val_acc: 0.8982\n",
      "Epoch 419/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1977 - acc: 0.9176 - val_loss: 0.2343 - val_acc: 0.8973\n",
      "Epoch 420/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1976 - acc: 0.9174 - val_loss: 0.2328 - val_acc: 0.8986\n",
      "Epoch 421/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1983 - acc: 0.9169 - val_loss: 0.2373 - val_acc: 0.8983\n",
      "Epoch 422/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1982 - acc: 0.9169 - val_loss: 0.2327 - val_acc: 0.8989\n",
      "Epoch 423/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1979 - acc: 0.9174 - val_loss: 0.2384 - val_acc: 0.8942\n",
      "Epoch 424/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1975 - acc: 0.9172 - val_loss: 0.2370 - val_acc: 0.8981\n",
      "Epoch 425/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1986 - acc: 0.9175 - val_loss: 0.2334 - val_acc: 0.8977\n",
      "Epoch 426/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1966 - acc: 0.9177 - val_loss: 0.2337 - val_acc: 0.8980\n",
      "Epoch 427/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9180 - val_loss: 0.2336 - val_acc: 0.8981\n",
      "Epoch 428/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9176 - val_loss: 0.2327 - val_acc: 0.8992\n",
      "Epoch 429/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9173 - val_loss: 0.2341 - val_acc: 0.8969\n",
      "Epoch 430/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1965 - acc: 0.9192 - val_loss: 0.2338 - val_acc: 0.8961\n",
      "Epoch 431/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1982 - acc: 0.9165 - val_loss: 0.2342 - val_acc: 0.8992\n",
      "Epoch 432/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1978 - acc: 0.9168 - val_loss: 0.2356 - val_acc: 0.8981\n",
      "Epoch 433/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9167 - val_loss: 0.2378 - val_acc: 0.8933\n",
      "Epoch 434/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1972 - acc: 0.9179 - val_loss: 0.2340 - val_acc: 0.8976\n",
      "Epoch 435/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1986 - acc: 0.9166 - val_loss: 0.2356 - val_acc: 0.8962\n",
      "Epoch 436/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9174 - val_loss: 0.2408 - val_acc: 0.8963\n",
      "Epoch 437/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1979 - acc: 0.9174 - val_loss: 0.2350 - val_acc: 0.8974\n",
      "Epoch 438/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1987 - acc: 0.9164 - val_loss: 0.2372 - val_acc: 0.8955\n",
      "Epoch 439/1500\n",
      "20704/20704 [==============================] - 1s 26us/step - loss: 0.1972 - acc: 0.9169 - val_loss: 0.2340 - val_acc: 0.8987\n",
      "Epoch 440/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1979 - acc: 0.9168 - val_loss: 0.2351 - val_acc: 0.8981\n",
      "Epoch 441/1500\n",
      "20704/20704 [==============================] - 1s 26us/step - loss: 0.1987 - acc: 0.9168 - val_loss: 0.2397 - val_acc: 0.8952\n",
      "Epoch 442/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1982 - acc: 0.9162 - val_loss: 0.2361 - val_acc: 0.8939\n",
      "Epoch 443/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9161 - val_loss: 0.2357 - val_acc: 0.8956\n",
      "Epoch 444/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9169 - val_loss: 0.2419 - val_acc: 0.8912\n",
      "Epoch 445/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1973 - acc: 0.9179 - val_loss: 0.2337 - val_acc: 0.8975\n",
      "Epoch 446/1500\n",
      "20704/20704 [==============================] - 1s 26us/step - loss: 0.1971 - acc: 0.9177 - val_loss: 0.2353 - val_acc: 0.8950\n",
      "Epoch 447/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9172 - val_loss: 0.2379 - val_acc: 0.8970\n",
      "Epoch 448/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9180 - val_loss: 0.2360 - val_acc: 0.8952\n",
      "Epoch 449/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9178 - val_loss: 0.2347 - val_acc: 0.8989\n",
      "Epoch 450/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1965 - acc: 0.9179 - val_loss: 0.2353 - val_acc: 0.8981\n",
      "Epoch 451/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1972 - acc: 0.9178 - val_loss: 0.2341 - val_acc: 0.8984\n",
      "Epoch 452/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1982 - acc: 0.9174 - val_loss: 0.2344 - val_acc: 0.8967\n",
      "Epoch 453/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1973 - acc: 0.9174 - val_loss: 0.2358 - val_acc: 0.8945\n",
      "Epoch 454/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9172 - val_loss: 0.2343 - val_acc: 0.8960\n",
      "Epoch 455/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1974 - acc: 0.9167 - val_loss: 0.2331 - val_acc: 0.8993\n",
      "Epoch 456/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1977 - acc: 0.9181 - val_loss: 0.2371 - val_acc: 0.8960\n",
      "Epoch 457/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1978 - acc: 0.9174 - val_loss: 0.2348 - val_acc: 0.8979\n",
      "Epoch 458/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1980 - acc: 0.9175 - val_loss: 0.2375 - val_acc: 0.8966\n",
      "Epoch 459/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9178 - val_loss: 0.2343 - val_acc: 0.8970\n",
      "Epoch 460/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9177 - val_loss: 0.2343 - val_acc: 0.8992\n",
      "Epoch 461/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1962 - acc: 0.9176 - val_loss: 0.2359 - val_acc: 0.8969\n",
      "Epoch 462/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1973 - acc: 0.9173 - val_loss: 0.2356 - val_acc: 0.8974\n",
      "Epoch 463/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1983 - acc: 0.9172 - val_loss: 0.2356 - val_acc: 0.8981\n",
      "Epoch 464/1500\n",
      "20704/20704 [==============================] - 1s 26us/step - loss: 0.1969 - acc: 0.9174 - val_loss: 0.2401 - val_acc: 0.8921\n",
      "Epoch 465/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9179 - val_loss: 0.2334 - val_acc: 0.8973\n",
      "Epoch 466/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1968 - acc: 0.9171 - val_loss: 0.2336 - val_acc: 0.8972\n",
      "Epoch 467/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9187 - val_loss: 0.2366 - val_acc: 0.8975\n",
      "Epoch 468/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1957 - acc: 0.9183 - val_loss: 0.2351 - val_acc: 0.8984\n",
      "Epoch 469/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9175 - val_loss: 0.2342 - val_acc: 0.8994\n",
      "Epoch 470/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9169 - val_loss: 0.2342 - val_acc: 0.8977\n",
      "Epoch 471/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1965 - acc: 0.9172 - val_loss: 0.2461 - val_acc: 0.8920\n",
      "Epoch 472/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1979 - acc: 0.9172 - val_loss: 0.2364 - val_acc: 0.8961\n",
      "Epoch 473/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9184 - val_loss: 0.2338 - val_acc: 0.8968\n",
      "Epoch 474/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1965 - acc: 0.9177 - val_loss: 0.2334 - val_acc: 0.8996\n",
      "Epoch 475/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9174 - val_loss: 0.2355 - val_acc: 0.8971\n",
      "Epoch 476/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9170 - val_loss: 0.2333 - val_acc: 0.8976\n",
      "Epoch 477/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9173 - val_loss: 0.2372 - val_acc: 0.8939\n",
      "Epoch 478/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9165 - val_loss: 0.2336 - val_acc: 0.8962\n",
      "Epoch 479/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9183 - val_loss: 0.2384 - val_acc: 0.8941\n",
      "Epoch 480/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9171 - val_loss: 0.2358 - val_acc: 0.8980\n",
      "Epoch 481/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9173 - val_loss: 0.2323 - val_acc: 0.8993\n",
      "Epoch 482/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9182 - val_loss: 0.2354 - val_acc: 0.8969\n",
      "Epoch 483/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9170 - val_loss: 0.2344 - val_acc: 0.8994\n",
      "Epoch 484/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9178 - val_loss: 0.2347 - val_acc: 0.8981\n",
      "Epoch 485/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9168 - val_loss: 0.2338 - val_acc: 0.8990\n",
      "Epoch 486/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9165 - val_loss: 0.2364 - val_acc: 0.8959\n",
      "Epoch 487/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1995 - acc: 0.9157 - val_loss: 0.2419 - val_acc: 0.8962\n",
      "Epoch 488/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1979 - acc: 0.9161 - val_loss: 0.2349 - val_acc: 0.8983\n",
      "Epoch 489/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1979 - acc: 0.9165 - val_loss: 0.2330 - val_acc: 0.8980\n",
      "Epoch 490/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1986 - acc: 0.9155 - val_loss: 0.2370 - val_acc: 0.8931\n",
      "Epoch 491/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1986 - acc: 0.9165 - val_loss: 0.2362 - val_acc: 0.8999\n",
      "Epoch 492/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1973 - acc: 0.9166 - val_loss: 0.2358 - val_acc: 0.8973\n",
      "Epoch 493/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1971 - acc: 0.9167 - val_loss: 0.2332 - val_acc: 0.8979\n",
      "Epoch 494/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1961 - acc: 0.9177 - val_loss: 0.2375 - val_acc: 0.8963\n",
      "Epoch 495/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1977 - acc: 0.9167 - val_loss: 0.2330 - val_acc: 0.8972\n",
      "Epoch 496/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1958 - acc: 0.9180 - val_loss: 0.2382 - val_acc: 0.8954\n",
      "Epoch 497/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9175 - val_loss: 0.2339 - val_acc: 0.8976\n",
      "Epoch 498/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1973 - acc: 0.9176 - val_loss: 0.2336 - val_acc: 0.8981\n",
      "Epoch 499/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1975 - acc: 0.9176 - val_loss: 0.2337 - val_acc: 0.8974\n",
      "Epoch 500/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9181 - val_loss: 0.2324 - val_acc: 0.8971\n",
      "Epoch 501/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1979 - acc: 0.9171 - val_loss: 0.2330 - val_acc: 0.8971\n",
      "Epoch 502/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1971 - acc: 0.9177 - val_loss: 0.2323 - val_acc: 0.8994\n",
      "Epoch 503/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1967 - acc: 0.9180 - val_loss: 0.2322 - val_acc: 0.8990\n",
      "Epoch 504/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1959 - acc: 0.9180 - val_loss: 0.2349 - val_acc: 0.8987\n",
      "Epoch 505/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1977 - acc: 0.9167 - val_loss: 0.2354 - val_acc: 0.8960\n",
      "Epoch 506/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1985 - acc: 0.9163 - val_loss: 0.2441 - val_acc: 0.8931\n",
      "Epoch 507/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1973 - acc: 0.9174 - val_loss: 0.2365 - val_acc: 0.8964\n",
      "Epoch 508/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1973 - acc: 0.9172 - val_loss: 0.2365 - val_acc: 0.8935\n",
      "Epoch 509/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1976 - acc: 0.9176 - val_loss: 0.2353 - val_acc: 0.8973\n",
      "Epoch 510/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1970 - acc: 0.9172 - val_loss: 0.2337 - val_acc: 0.8975\n",
      "Epoch 511/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1964 - acc: 0.9178 - val_loss: 0.2333 - val_acc: 0.8986\n",
      "Epoch 512/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9175 - val_loss: 0.2320 - val_acc: 0.8970\n",
      "Epoch 513/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9178 - val_loss: 0.2336 - val_acc: 0.8958\n",
      "Epoch 514/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9176 - val_loss: 0.2335 - val_acc: 0.8977\n",
      "Epoch 515/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1977 - acc: 0.9161 - val_loss: 0.2380 - val_acc: 0.8955\n",
      "Epoch 516/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9175 - val_loss: 0.2336 - val_acc: 0.8971\n",
      "Epoch 517/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9175 - val_loss: 0.2347 - val_acc: 0.8977\n",
      "Epoch 518/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1973 - acc: 0.9170 - val_loss: 0.2340 - val_acc: 0.8981\n",
      "Epoch 519/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9175 - val_loss: 0.2334 - val_acc: 0.8987\n",
      "Epoch 520/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9184 - val_loss: 0.2332 - val_acc: 0.8991\n",
      "Epoch 521/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9194 - val_loss: 0.2340 - val_acc: 0.8961\n",
      "Epoch 522/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9179 - val_loss: 0.2368 - val_acc: 0.8967\n",
      "Epoch 523/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9174 - val_loss: 0.2345 - val_acc: 0.8969\n",
      "Epoch 524/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9174 - val_loss: 0.2346 - val_acc: 0.8992\n",
      "Epoch 525/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9185 - val_loss: 0.2334 - val_acc: 0.8970\n",
      "Epoch 526/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9188 - val_loss: 0.2334 - val_acc: 0.8979\n",
      "Epoch 527/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9167 - val_loss: 0.2331 - val_acc: 0.8994\n",
      "Epoch 528/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1973 - acc: 0.9171 - val_loss: 0.2364 - val_acc: 0.8983\n",
      "Epoch 529/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2016 - acc: 0.9150 - val_loss: 0.2443 - val_acc: 0.8893\n",
      "Epoch 530/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2004 - acc: 0.9148 - val_loss: 0.2374 - val_acc: 0.8958\n",
      "Epoch 531/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9163 - val_loss: 0.2348 - val_acc: 0.8971\n",
      "Epoch 532/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9174 - val_loss: 0.2347 - val_acc: 0.8992\n",
      "Epoch 533/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1990 - acc: 0.9155 - val_loss: 0.2399 - val_acc: 0.8950\n",
      "Epoch 534/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1985 - acc: 0.9163 - val_loss: 0.2419 - val_acc: 0.8904\n",
      "Epoch 535/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1988 - acc: 0.9148 - val_loss: 0.2438 - val_acc: 0.8897\n",
      "Epoch 536/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2001 - acc: 0.9146 - val_loss: 0.2382 - val_acc: 0.8940\n",
      "Epoch 537/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1991 - acc: 0.9157 - val_loss: 0.2349 - val_acc: 0.8973\n",
      "Epoch 538/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9157 - val_loss: 0.2352 - val_acc: 0.8973\n",
      "Epoch 539/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1985 - acc: 0.9168 - val_loss: 0.2392 - val_acc: 0.8962\n",
      "Epoch 540/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1985 - acc: 0.9167 - val_loss: 0.2361 - val_acc: 0.8961\n",
      "Epoch 541/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9169 - val_loss: 0.2344 - val_acc: 0.8975\n",
      "Epoch 542/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1964 - acc: 0.9167 - val_loss: 0.2343 - val_acc: 0.8967\n",
      "Epoch 543/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9168 - val_loss: 0.2361 - val_acc: 0.8984\n",
      "Epoch 544/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9170 - val_loss: 0.2345 - val_acc: 0.8957\n",
      "Epoch 545/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1970 - acc: 0.9161 - val_loss: 0.2358 - val_acc: 0.8963\n",
      "Epoch 546/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9171 - val_loss: 0.2355 - val_acc: 0.8966\n",
      "Epoch 547/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9173 - val_loss: 0.2340 - val_acc: 0.8984\n",
      "Epoch 548/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1987 - acc: 0.9162 - val_loss: 0.2357 - val_acc: 0.8984\n",
      "Epoch 549/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9164 - val_loss: 0.2361 - val_acc: 0.8959\n",
      "Epoch 550/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1973 - acc: 0.9168 - val_loss: 0.2378 - val_acc: 0.8929\n",
      "Epoch 551/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9155 - val_loss: 0.2362 - val_acc: 0.8964\n",
      "Epoch 552/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9181 - val_loss: 0.2363 - val_acc: 0.8964\n",
      "Epoch 553/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9171 - val_loss: 0.2394 - val_acc: 0.8955\n",
      "Epoch 554/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1969 - acc: 0.9165 - val_loss: 0.2344 - val_acc: 0.8970\n",
      "Epoch 555/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9169 - val_loss: 0.2384 - val_acc: 0.8967\n",
      "Epoch 556/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1989 - acc: 0.9154 - val_loss: 0.2350 - val_acc: 0.8977\n",
      "Epoch 557/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9174 - val_loss: 0.2370 - val_acc: 0.8983\n",
      "Epoch 558/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1983 - acc: 0.9162 - val_loss: 0.2395 - val_acc: 0.8925\n",
      "Epoch 559/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9175 - val_loss: 0.2363 - val_acc: 0.8973\n",
      "Epoch 560/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1968 - acc: 0.9168 - val_loss: 0.2374 - val_acc: 0.8989\n",
      "Epoch 561/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1962 - acc: 0.9176 - val_loss: 0.2334 - val_acc: 0.8981\n",
      "Epoch 562/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9177 - val_loss: 0.2332 - val_acc: 0.8994\n",
      "Epoch 563/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9173 - val_loss: 0.2376 - val_acc: 0.8987\n",
      "Epoch 564/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1973 - acc: 0.9181 - val_loss: 0.2333 - val_acc: 0.8977\n",
      "Epoch 565/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9171 - val_loss: 0.2337 - val_acc: 0.8987\n",
      "Epoch 566/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9180 - val_loss: 0.2344 - val_acc: 0.8979\n",
      "Epoch 567/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1976 - acc: 0.9166 - val_loss: 0.2359 - val_acc: 0.8971\n",
      "Epoch 568/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1970 - acc: 0.9168 - val_loss: 0.2344 - val_acc: 0.8961\n",
      "Epoch 569/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9170 - val_loss: 0.2335 - val_acc: 0.8974\n",
      "Epoch 570/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1968 - acc: 0.9177 - val_loss: 0.2337 - val_acc: 0.8984\n",
      "Epoch 571/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1971 - acc: 0.9159 - val_loss: 0.2337 - val_acc: 0.9004\n",
      "Epoch 572/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1959 - acc: 0.9183 - val_loss: 0.2352 - val_acc: 0.8973\n",
      "Epoch 573/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1964 - acc: 0.9168 - val_loss: 0.2385 - val_acc: 0.8971\n",
      "Epoch 574/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1964 - acc: 0.9177 - val_loss: 0.2331 - val_acc: 0.8973\n",
      "Epoch 575/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1962 - acc: 0.9191 - val_loss: 0.2345 - val_acc: 0.8981\n",
      "Epoch 576/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1968 - acc: 0.9180 - val_loss: 0.2343 - val_acc: 0.8987\n",
      "Epoch 577/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1966 - acc: 0.9169 - val_loss: 0.2359 - val_acc: 0.8955\n",
      "Epoch 578/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9173 - val_loss: 0.2368 - val_acc: 0.8966\n",
      "Epoch 579/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9177 - val_loss: 0.2328 - val_acc: 0.8971\n",
      "Epoch 580/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1968 - acc: 0.9174 - val_loss: 0.2379 - val_acc: 0.8938\n",
      "Epoch 581/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9162 - val_loss: 0.2340 - val_acc: 0.8966\n",
      "Epoch 582/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1966 - acc: 0.9180 - val_loss: 0.2344 - val_acc: 0.8970\n",
      "Epoch 583/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9177 - val_loss: 0.2366 - val_acc: 0.8975\n",
      "Epoch 584/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9172 - val_loss: 0.2338 - val_acc: 0.8983\n",
      "Epoch 585/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1965 - acc: 0.9185 - val_loss: 0.2360 - val_acc: 0.8976\n",
      "Epoch 586/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9182 - val_loss: 0.2374 - val_acc: 0.8958\n",
      "Epoch 587/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1991 - acc: 0.9162 - val_loss: 0.2370 - val_acc: 0.8968\n",
      "Epoch 588/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2006 - acc: 0.9142 - val_loss: 0.2400 - val_acc: 0.8915\n",
      "Epoch 589/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1985 - acc: 0.9152 - val_loss: 0.2368 - val_acc: 0.8961\n",
      "Epoch 590/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1977 - acc: 0.9170 - val_loss: 0.2340 - val_acc: 0.8973\n",
      "Epoch 591/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1964 - acc: 0.9172 - val_loss: 0.2345 - val_acc: 0.8989\n",
      "Epoch 592/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9169 - val_loss: 0.2348 - val_acc: 0.8984\n",
      "Epoch 593/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1975 - acc: 0.9177 - val_loss: 0.2357 - val_acc: 0.8979\n",
      "Epoch 594/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1985 - acc: 0.9162 - val_loss: 0.2376 - val_acc: 0.8967\n",
      "Epoch 595/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9177 - val_loss: 0.2365 - val_acc: 0.8964\n",
      "Epoch 596/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9180 - val_loss: 0.2354 - val_acc: 0.8973\n",
      "Epoch 597/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9175 - val_loss: 0.2348 - val_acc: 0.8986\n",
      "Epoch 598/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1978 - acc: 0.9170 - val_loss: 0.2356 - val_acc: 0.8986\n",
      "Epoch 599/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9186 - val_loss: 0.2351 - val_acc: 0.8964\n",
      "Epoch 600/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9188 - val_loss: 0.2354 - val_acc: 0.8966\n",
      "Epoch 601/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9178 - val_loss: 0.2336 - val_acc: 0.8995\n",
      "Epoch 602/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9186 - val_loss: 0.2366 - val_acc: 0.8986\n",
      "Epoch 603/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9177 - val_loss: 0.2387 - val_acc: 0.8952\n",
      "Epoch 604/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1970 - acc: 0.9168 - val_loss: 0.2354 - val_acc: 0.8968\n",
      "Epoch 605/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9171 - val_loss: 0.2379 - val_acc: 0.8976\n",
      "Epoch 606/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9174 - val_loss: 0.2344 - val_acc: 0.8976\n",
      "Epoch 607/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1970 - acc: 0.9174 - val_loss: 0.2367 - val_acc: 0.8960\n",
      "Epoch 608/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9176 - val_loss: 0.2335 - val_acc: 0.8976\n",
      "Epoch 609/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9184 - val_loss: 0.2337 - val_acc: 0.8955\n",
      "Epoch 610/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9182 - val_loss: 0.2350 - val_acc: 0.8987\n",
      "Epoch 611/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9179 - val_loss: 0.2349 - val_acc: 0.8973\n",
      "Epoch 612/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1967 - acc: 0.9171 - val_loss: 0.2342 - val_acc: 0.8990\n",
      "Epoch 613/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1960 - acc: 0.9176 - val_loss: 0.2346 - val_acc: 0.8993\n",
      "Epoch 614/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1967 - acc: 0.9181 - val_loss: 0.2340 - val_acc: 0.8987\n",
      "Epoch 615/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9188 - val_loss: 0.2350 - val_acc: 0.8971\n",
      "Epoch 616/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1969 - acc: 0.9163 - val_loss: 0.2349 - val_acc: 0.8966\n",
      "Epoch 617/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9178 - val_loss: 0.2346 - val_acc: 0.8986\n",
      "Epoch 618/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1968 - acc: 0.9179 - val_loss: 0.2355 - val_acc: 0.8977\n",
      "Epoch 619/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1968 - acc: 0.9183 - val_loss: 0.2347 - val_acc: 0.8986\n",
      "Epoch 620/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1962 - acc: 0.9180 - val_loss: 0.2359 - val_acc: 0.8963\n",
      "Epoch 621/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9180 - val_loss: 0.2340 - val_acc: 0.8973\n",
      "Epoch 622/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1973 - acc: 0.9172 - val_loss: 0.2344 - val_acc: 0.8980\n",
      "Epoch 623/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9181 - val_loss: 0.2368 - val_acc: 0.8954\n",
      "Epoch 624/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9178 - val_loss: 0.2378 - val_acc: 0.8971\n",
      "Epoch 625/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1972 - acc: 0.9177 - val_loss: 0.2410 - val_acc: 0.8914\n",
      "Epoch 626/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1988 - acc: 0.9172 - val_loss: 0.2380 - val_acc: 0.8966\n",
      "Epoch 627/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1964 - acc: 0.9173 - val_loss: 0.2355 - val_acc: 0.8970\n",
      "Epoch 628/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1982 - acc: 0.9169 - val_loss: 0.2370 - val_acc: 0.8955\n",
      "Epoch 629/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9169 - val_loss: 0.2357 - val_acc: 0.8967\n",
      "Epoch 630/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9174 - val_loss: 0.2355 - val_acc: 0.8967\n",
      "Epoch 631/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1965 - acc: 0.9178 - val_loss: 0.2345 - val_acc: 0.8980\n",
      "Epoch 632/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9184 - val_loss: 0.2367 - val_acc: 0.8957\n",
      "Epoch 633/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9176 - val_loss: 0.2371 - val_acc: 0.8976\n",
      "Epoch 634/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9180 - val_loss: 0.2343 - val_acc: 0.8964\n",
      "Epoch 635/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9179 - val_loss: 0.2345 - val_acc: 0.8973\n",
      "Epoch 636/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1966 - acc: 0.9175 - val_loss: 0.2350 - val_acc: 0.8968\n",
      "Epoch 637/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1960 - acc: 0.9181 - val_loss: 0.2366 - val_acc: 0.8950\n",
      "Epoch 638/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1964 - acc: 0.9176 - val_loss: 0.2355 - val_acc: 0.8984\n",
      "Epoch 639/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1956 - acc: 0.9188 - val_loss: 0.2350 - val_acc: 0.8965\n",
      "Epoch 640/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9182 - val_loss: 0.2360 - val_acc: 0.8983\n",
      "Epoch 641/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1967 - acc: 0.9178 - val_loss: 0.2350 - val_acc: 0.8980\n",
      "Epoch 642/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1968 - acc: 0.9173 - val_loss: 0.2383 - val_acc: 0.8966\n",
      "Epoch 643/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1960 - acc: 0.9179 - val_loss: 0.2354 - val_acc: 0.8980\n",
      "Epoch 644/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1962 - acc: 0.9176 - val_loss: 0.2385 - val_acc: 0.8957\n",
      "Epoch 645/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1967 - acc: 0.9169 - val_loss: 0.2405 - val_acc: 0.8932\n",
      "Epoch 646/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1976 - acc: 0.9161 - val_loss: 0.2379 - val_acc: 0.8953\n",
      "Epoch 647/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1971 - acc: 0.9167 - val_loss: 0.2372 - val_acc: 0.8967\n",
      "Epoch 648/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9177 - val_loss: 0.2379 - val_acc: 0.8983\n",
      "Epoch 649/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1958 - acc: 0.9173 - val_loss: 0.2377 - val_acc: 0.8956\n",
      "Epoch 650/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1969 - acc: 0.9168 - val_loss: 0.2354 - val_acc: 0.8979\n",
      "Epoch 651/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1961 - acc: 0.9174 - val_loss: 0.2350 - val_acc: 0.8969\n",
      "Epoch 652/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1956 - acc: 0.9175 - val_loss: 0.2380 - val_acc: 0.8944\n",
      "Epoch 653/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9181 - val_loss: 0.2411 - val_acc: 0.8913\n",
      "Epoch 654/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1969 - acc: 0.9152 - val_loss: 0.2363 - val_acc: 0.8960\n",
      "Epoch 655/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9170 - val_loss: 0.2357 - val_acc: 0.8963\n",
      "Epoch 656/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1965 - acc: 0.9164 - val_loss: 0.2342 - val_acc: 0.8968\n",
      "Epoch 657/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9189 - val_loss: 0.2353 - val_acc: 0.8979\n",
      "Epoch 658/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9182 - val_loss: 0.2371 - val_acc: 0.8958\n",
      "Epoch 659/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1965 - acc: 0.9173 - val_loss: 0.2352 - val_acc: 0.8986\n",
      "Epoch 660/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1966 - acc: 0.9175 - val_loss: 0.2356 - val_acc: 0.8987\n",
      "Epoch 661/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1965 - acc: 0.9177 - val_loss: 0.2350 - val_acc: 0.8988\n",
      "Epoch 662/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1977 - acc: 0.9159 - val_loss: 0.2357 - val_acc: 0.8981\n",
      "Epoch 663/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9169 - val_loss: 0.2385 - val_acc: 0.8957\n",
      "Epoch 664/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1973 - acc: 0.9170 - val_loss: 0.2383 - val_acc: 0.8937\n",
      "Epoch 665/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1968 - acc: 0.9165 - val_loss: 0.2350 - val_acc: 0.8970\n",
      "Epoch 666/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1956 - acc: 0.9181 - val_loss: 0.2355 - val_acc: 0.8968\n",
      "Epoch 667/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1962 - acc: 0.9186 - val_loss: 0.2352 - val_acc: 0.8971\n",
      "Epoch 668/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9174 - val_loss: 0.2365 - val_acc: 0.8966\n",
      "Epoch 669/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9178 - val_loss: 0.2337 - val_acc: 0.8988\n",
      "Epoch 670/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1961 - acc: 0.9173 - val_loss: 0.2363 - val_acc: 0.8966\n",
      "Epoch 671/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9174 - val_loss: 0.2331 - val_acc: 0.8971\n",
      "Epoch 672/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9175 - val_loss: 0.2354 - val_acc: 0.8978\n",
      "Epoch 673/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1961 - acc: 0.9187 - val_loss: 0.2350 - val_acc: 0.8973\n",
      "Epoch 674/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9184 - val_loss: 0.2355 - val_acc: 0.8980\n",
      "Epoch 675/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1962 - acc: 0.9165 - val_loss: 0.2389 - val_acc: 0.8939\n",
      "Epoch 676/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1970 - acc: 0.9174 - val_loss: 0.2353 - val_acc: 0.8980\n",
      "Epoch 677/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1969 - acc: 0.9174 - val_loss: 0.2352 - val_acc: 0.8980\n",
      "Epoch 678/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1969 - acc: 0.9168 - val_loss: 0.2336 - val_acc: 0.8992\n",
      "Epoch 679/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9181 - val_loss: 0.2354 - val_acc: 0.8974\n",
      "Epoch 680/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9181 - val_loss: 0.2366 - val_acc: 0.8981\n",
      "Epoch 681/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9176 - val_loss: 0.2360 - val_acc: 0.8964\n",
      "Epoch 682/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9176 - val_loss: 0.2345 - val_acc: 0.8967\n",
      "Epoch 683/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1965 - acc: 0.9180 - val_loss: 0.2361 - val_acc: 0.8984\n",
      "Epoch 684/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9177 - val_loss: 0.2364 - val_acc: 0.8981\n",
      "Epoch 685/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9174 - val_loss: 0.2395 - val_acc: 0.8955\n",
      "Epoch 686/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9167 - val_loss: 0.2371 - val_acc: 0.8974\n",
      "Epoch 687/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1968 - acc: 0.9173 - val_loss: 0.2354 - val_acc: 0.8968\n",
      "Epoch 688/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9176 - val_loss: 0.2376 - val_acc: 0.8945\n",
      "Epoch 689/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1964 - acc: 0.9169 - val_loss: 0.2375 - val_acc: 0.8961\n",
      "Epoch 690/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9175 - val_loss: 0.2327 - val_acc: 0.8984\n",
      "Epoch 691/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9169 - val_loss: 0.2371 - val_acc: 0.8964\n",
      "Epoch 692/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9168 - val_loss: 0.2369 - val_acc: 0.8951\n",
      "Epoch 693/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9182 - val_loss: 0.2369 - val_acc: 0.8955\n",
      "Epoch 694/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9176 - val_loss: 0.2354 - val_acc: 0.8973\n",
      "Epoch 695/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9176 - val_loss: 0.2339 - val_acc: 0.8970\n",
      "Epoch 696/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1964 - acc: 0.9178 - val_loss: 0.2358 - val_acc: 0.8983\n",
      "Epoch 697/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9174 - val_loss: 0.2352 - val_acc: 0.8979\n",
      "Epoch 698/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9167 - val_loss: 0.2350 - val_acc: 0.8981\n",
      "Epoch 699/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9182 - val_loss: 0.2349 - val_acc: 0.8970\n",
      "Epoch 700/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9184 - val_loss: 0.2348 - val_acc: 0.8976\n",
      "Epoch 701/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9184 - val_loss: 0.2335 - val_acc: 0.8977\n",
      "Epoch 702/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9185 - val_loss: 0.2350 - val_acc: 0.8990\n",
      "Epoch 703/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9184 - val_loss: 0.2349 - val_acc: 0.8979\n",
      "Epoch 704/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1969 - acc: 0.9173 - val_loss: 0.2365 - val_acc: 0.8976\n",
      "Epoch 705/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9177 - val_loss: 0.2347 - val_acc: 0.8961\n",
      "Epoch 706/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9180 - val_loss: 0.2352 - val_acc: 0.8963\n",
      "Epoch 707/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9179 - val_loss: 0.2346 - val_acc: 0.8986\n",
      "Epoch 708/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9177 - val_loss: 0.2371 - val_acc: 0.8958\n",
      "Epoch 709/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9177 - val_loss: 0.2376 - val_acc: 0.8970\n",
      "Epoch 710/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1955 - acc: 0.9172 - val_loss: 0.2355 - val_acc: 0.8983\n",
      "Epoch 711/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1956 - acc: 0.9187 - val_loss: 0.2367 - val_acc: 0.8947\n",
      "Epoch 712/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1955 - acc: 0.9181 - val_loss: 0.2353 - val_acc: 0.8970\n",
      "Epoch 713/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9173 - val_loss: 0.2348 - val_acc: 0.8964\n",
      "Epoch 714/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9181 - val_loss: 0.2357 - val_acc: 0.8986\n",
      "Epoch 715/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9176 - val_loss: 0.2360 - val_acc: 0.8997\n",
      "Epoch 716/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9183 - val_loss: 0.2362 - val_acc: 0.8983\n",
      "Epoch 717/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9182 - val_loss: 0.2352 - val_acc: 0.8966\n",
      "Epoch 718/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9183 - val_loss: 0.2357 - val_acc: 0.8970\n",
      "Epoch 719/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1964 - acc: 0.9181 - val_loss: 0.2379 - val_acc: 0.8960\n",
      "Epoch 720/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1965 - acc: 0.9171 - val_loss: 0.2334 - val_acc: 0.8981\n",
      "Epoch 721/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1952 - acc: 0.9184 - val_loss: 0.2366 - val_acc: 0.8977\n",
      "Epoch 722/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1952 - acc: 0.9179 - val_loss: 0.2365 - val_acc: 0.8958\n",
      "Epoch 723/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1960 - acc: 0.9183 - val_loss: 0.2366 - val_acc: 0.8942\n",
      "Epoch 724/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1962 - acc: 0.9166 - val_loss: 0.2382 - val_acc: 0.8942\n",
      "Epoch 725/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1963 - acc: 0.9177 - val_loss: 0.2382 - val_acc: 0.8984\n",
      "Epoch 726/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9190 - val_loss: 0.2362 - val_acc: 0.8990\n",
      "Epoch 727/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9176 - val_loss: 0.2380 - val_acc: 0.8947\n",
      "Epoch 728/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9176 - val_loss: 0.2349 - val_acc: 0.8981\n",
      "Epoch 729/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9184 - val_loss: 0.2345 - val_acc: 0.8981\n",
      "Epoch 730/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9179 - val_loss: 0.2361 - val_acc: 0.8945\n",
      "Epoch 731/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9177 - val_loss: 0.2344 - val_acc: 0.8958\n",
      "Epoch 732/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1960 - acc: 0.9180 - val_loss: 0.2360 - val_acc: 0.8968\n",
      "Epoch 733/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1964 - acc: 0.9170 - val_loss: 0.2353 - val_acc: 0.8990\n",
      "Epoch 734/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1958 - acc: 0.9173 - val_loss: 0.2383 - val_acc: 0.8968\n",
      "Epoch 735/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1954 - acc: 0.9173 - val_loss: 0.2376 - val_acc: 0.8977\n",
      "Epoch 736/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1962 - acc: 0.9176 - val_loss: 0.2394 - val_acc: 0.8979\n",
      "Epoch 737/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9180 - val_loss: 0.2371 - val_acc: 0.8955\n",
      "Epoch 738/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1965 - acc: 0.9165 - val_loss: 0.2359 - val_acc: 0.8989\n",
      "Epoch 739/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9180 - val_loss: 0.2345 - val_acc: 0.8993\n",
      "Epoch 740/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9175 - val_loss: 0.2345 - val_acc: 0.8986\n",
      "Epoch 741/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9184 - val_loss: 0.2338 - val_acc: 0.8970\n",
      "Epoch 742/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9173 - val_loss: 0.2371 - val_acc: 0.8973\n",
      "Epoch 743/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9174 - val_loss: 0.2411 - val_acc: 0.8932\n",
      "Epoch 744/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1965 - acc: 0.9168 - val_loss: 0.2339 - val_acc: 0.8973\n",
      "Epoch 745/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9173 - val_loss: 0.2417 - val_acc: 0.8984\n",
      "Epoch 746/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9170 - val_loss: 0.2371 - val_acc: 0.8973\n",
      "Epoch 747/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9177 - val_loss: 0.2352 - val_acc: 0.8973\n",
      "Epoch 748/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9184 - val_loss: 0.2373 - val_acc: 0.8950\n",
      "Epoch 749/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9180 - val_loss: 0.2343 - val_acc: 0.8971\n",
      "Epoch 750/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9187 - val_loss: 0.2356 - val_acc: 0.8980\n",
      "Epoch 751/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1970 - acc: 0.9170 - val_loss: 0.2383 - val_acc: 0.8973\n",
      "Epoch 752/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9183 - val_loss: 0.2360 - val_acc: 0.8977\n",
      "Epoch 753/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9182 - val_loss: 0.2353 - val_acc: 0.8957\n",
      "Epoch 754/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9169 - val_loss: 0.2356 - val_acc: 0.8954\n",
      "Epoch 755/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1975 - acc: 0.9178 - val_loss: 0.2391 - val_acc: 0.8961\n",
      "Epoch 756/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9179 - val_loss: 0.2343 - val_acc: 0.8974\n",
      "Epoch 757/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9184 - val_loss: 0.2350 - val_acc: 0.8963\n",
      "Epoch 758/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9179 - val_loss: 0.2348 - val_acc: 0.8968\n",
      "Epoch 759/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9177 - val_loss: 0.2347 - val_acc: 0.8989\n",
      "Epoch 760/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9179 - val_loss: 0.2379 - val_acc: 0.8964\n",
      "Epoch 761/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9182 - val_loss: 0.2419 - val_acc: 0.8931\n",
      "Epoch 762/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1964 - acc: 0.9162 - val_loss: 0.2352 - val_acc: 0.8964\n",
      "Epoch 763/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9186 - val_loss: 0.2368 - val_acc: 0.8970\n",
      "Epoch 764/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9171 - val_loss: 0.2365 - val_acc: 0.8964\n",
      "Epoch 765/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9180 - val_loss: 0.2369 - val_acc: 0.8955\n",
      "Epoch 766/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9176 - val_loss: 0.2356 - val_acc: 0.8980\n",
      "Epoch 767/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9187 - val_loss: 0.2397 - val_acc: 0.8954\n",
      "Epoch 768/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9172 - val_loss: 0.2373 - val_acc: 0.8948\n",
      "Epoch 769/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9176 - val_loss: 0.2377 - val_acc: 0.8974\n",
      "Epoch 770/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9171 - val_loss: 0.2402 - val_acc: 0.8952\n",
      "Epoch 771/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9177 - val_loss: 0.2380 - val_acc: 0.8948\n",
      "Epoch 772/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9184 - val_loss: 0.2380 - val_acc: 0.8970\n",
      "Epoch 773/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9170 - val_loss: 0.2353 - val_acc: 0.8977\n",
      "Epoch 774/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9189 - val_loss: 0.2340 - val_acc: 0.8996\n",
      "Epoch 775/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9174 - val_loss: 0.2360 - val_acc: 0.8967\n",
      "Epoch 776/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9178 - val_loss: 0.2379 - val_acc: 0.8971\n",
      "Epoch 777/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1964 - acc: 0.9171 - val_loss: 0.2389 - val_acc: 0.8932\n",
      "Epoch 778/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.9178 - val_loss: 0.2357 - val_acc: 0.8963\n",
      "Epoch 779/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9172 - val_loss: 0.2361 - val_acc: 0.8968\n",
      "Epoch 780/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9173 - val_loss: 0.2381 - val_acc: 0.8944\n",
      "Epoch 781/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1970 - acc: 0.9169 - val_loss: 0.2351 - val_acc: 0.8973\n",
      "Epoch 782/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9179 - val_loss: 0.2361 - val_acc: 0.8967\n",
      "Epoch 783/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9183 - val_loss: 0.2327 - val_acc: 0.8974\n",
      "Epoch 784/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9179 - val_loss: 0.2350 - val_acc: 0.8976\n",
      "Epoch 785/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9185 - val_loss: 0.2343 - val_acc: 0.8984\n",
      "Epoch 786/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9173 - val_loss: 0.2345 - val_acc: 0.8973\n",
      "Epoch 787/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9186 - val_loss: 0.2352 - val_acc: 0.8987\n",
      "Epoch 788/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1956 - acc: 0.9175 - val_loss: 0.2344 - val_acc: 0.8993\n",
      "Epoch 789/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1951 - acc: 0.9184 - val_loss: 0.2347 - val_acc: 0.8966\n",
      "Epoch 790/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1967 - acc: 0.9168 - val_loss: 0.2365 - val_acc: 0.8952\n",
      "Epoch 791/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1965 - acc: 0.9171 - val_loss: 0.2367 - val_acc: 0.8971\n",
      "Epoch 792/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9175 - val_loss: 0.2357 - val_acc: 0.8966\n",
      "Epoch 793/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9188 - val_loss: 0.2354 - val_acc: 0.8974\n",
      "Epoch 794/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1970 - acc: 0.9171 - val_loss: 0.2364 - val_acc: 0.8967\n",
      "Epoch 795/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9171 - val_loss: 0.2363 - val_acc: 0.8960\n",
      "Epoch 796/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9166 - val_loss: 0.2357 - val_acc: 0.8966\n",
      "Epoch 797/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9183 - val_loss: 0.2352 - val_acc: 0.8977\n",
      "Epoch 798/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9176 - val_loss: 0.2346 - val_acc: 0.8994\n",
      "Epoch 799/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1973 - acc: 0.9164 - val_loss: 0.2476 - val_acc: 0.8914\n",
      "Epoch 800/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.2010 - acc: 0.9139 - val_loss: 0.2432 - val_acc: 0.8954\n",
      "Epoch 801/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9179 - val_loss: 0.2391 - val_acc: 0.8958\n",
      "Epoch 802/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1978 - acc: 0.9176 - val_loss: 0.2385 - val_acc: 0.8979\n",
      "Epoch 803/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9173 - val_loss: 0.2367 - val_acc: 0.8967\n",
      "Epoch 804/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1966 - acc: 0.9176 - val_loss: 0.2362 - val_acc: 0.8973\n",
      "Epoch 805/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1956 - acc: 0.9171 - val_loss: 0.2366 - val_acc: 0.8968\n",
      "Epoch 806/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9176 - val_loss: 0.2357 - val_acc: 0.8981\n",
      "Epoch 807/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9185 - val_loss: 0.2363 - val_acc: 0.8968\n",
      "Epoch 808/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1956 - acc: 0.9180 - val_loss: 0.2366 - val_acc: 0.8963\n",
      "Epoch 809/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9189 - val_loss: 0.2386 - val_acc: 0.8941\n",
      "Epoch 810/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9182 - val_loss: 0.2381 - val_acc: 0.8948\n",
      "Epoch 811/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9176 - val_loss: 0.2372 - val_acc: 0.8961\n",
      "Epoch 812/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1964 - acc: 0.9173 - val_loss: 0.2428 - val_acc: 0.8916\n",
      "Epoch 813/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1968 - acc: 0.9172 - val_loss: 0.2354 - val_acc: 0.8964\n",
      "Epoch 814/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9175 - val_loss: 0.2360 - val_acc: 0.8970\n",
      "Epoch 815/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1957 - acc: 0.9177 - val_loss: 0.2385 - val_acc: 0.8938\n",
      "Epoch 816/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9178 - val_loss: 0.2362 - val_acc: 0.8973\n",
      "Epoch 817/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9183 - val_loss: 0.2380 - val_acc: 0.8955\n",
      "Epoch 818/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1964 - acc: 0.9177 - val_loss: 0.2367 - val_acc: 0.8970\n",
      "Epoch 819/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9185 - val_loss: 0.2363 - val_acc: 0.8983\n",
      "Epoch 820/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9178 - val_loss: 0.2367 - val_acc: 0.8967\n",
      "Epoch 821/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9180 - val_loss: 0.2358 - val_acc: 0.8976\n",
      "Epoch 822/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9180 - val_loss: 0.2370 - val_acc: 0.8951\n",
      "Epoch 823/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1960 - acc: 0.9176 - val_loss: 0.2362 - val_acc: 0.8963\n",
      "Epoch 824/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9176 - val_loss: 0.2371 - val_acc: 0.8981\n",
      "Epoch 825/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9175 - val_loss: 0.2390 - val_acc: 0.8964\n",
      "Epoch 826/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9187 - val_loss: 0.2358 - val_acc: 0.8986\n",
      "Epoch 827/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9178 - val_loss: 0.2369 - val_acc: 0.8958\n",
      "Epoch 828/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9174 - val_loss: 0.2353 - val_acc: 0.8974\n",
      "Epoch 829/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9186 - val_loss: 0.2346 - val_acc: 0.8981\n",
      "Epoch 830/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9191 - val_loss: 0.2358 - val_acc: 0.8944\n",
      "Epoch 831/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9179 - val_loss: 0.2383 - val_acc: 0.8960\n",
      "Epoch 832/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9186 - val_loss: 0.2348 - val_acc: 0.8977\n",
      "Epoch 833/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9187 - val_loss: 0.2351 - val_acc: 0.8973\n",
      "Epoch 834/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9184 - val_loss: 0.2343 - val_acc: 0.8973\n",
      "Epoch 835/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9164 - val_loss: 0.2371 - val_acc: 0.8954\n",
      "Epoch 836/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9179 - val_loss: 0.2350 - val_acc: 0.8979\n",
      "Epoch 837/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9185 - val_loss: 0.2348 - val_acc: 0.8983\n",
      "Epoch 838/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9170 - val_loss: 0.2366 - val_acc: 0.8977\n",
      "Epoch 839/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9175 - val_loss: 0.2395 - val_acc: 0.8960\n",
      "Epoch 840/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9186 - val_loss: 0.2366 - val_acc: 0.8980\n",
      "Epoch 841/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9167 - val_loss: 0.2388 - val_acc: 0.8963\n",
      "Epoch 842/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9182 - val_loss: 0.2380 - val_acc: 0.8966\n",
      "Epoch 843/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9174 - val_loss: 0.2358 - val_acc: 0.8977\n",
      "Epoch 844/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9177 - val_loss: 0.2364 - val_acc: 0.8976\n",
      "Epoch 845/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9176 - val_loss: 0.2365 - val_acc: 0.8979\n",
      "Epoch 846/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1984 - acc: 0.9162 - val_loss: 0.2382 - val_acc: 0.8961\n",
      "Epoch 847/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9176 - val_loss: 0.2375 - val_acc: 0.8957\n",
      "Epoch 848/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9176 - val_loss: 0.2403 - val_acc: 0.8954\n",
      "Epoch 849/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9180 - val_loss: 0.2379 - val_acc: 0.8955\n",
      "Epoch 850/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9184 - val_loss: 0.2368 - val_acc: 0.8971\n",
      "Epoch 851/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9182 - val_loss: 0.2371 - val_acc: 0.8966\n",
      "Epoch 852/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9189 - val_loss: 0.2356 - val_acc: 0.8968\n",
      "Epoch 853/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1960 - acc: 0.9170 - val_loss: 0.2433 - val_acc: 0.8895\n",
      "Epoch 854/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1975 - acc: 0.9159 - val_loss: 0.2392 - val_acc: 0.8947\n",
      "Epoch 855/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9178 - val_loss: 0.2374 - val_acc: 0.8958\n",
      "Epoch 856/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9183 - val_loss: 0.2364 - val_acc: 0.8960\n",
      "Epoch 857/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9168 - val_loss: 0.2386 - val_acc: 0.8934\n",
      "Epoch 858/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1960 - acc: 0.9173 - val_loss: 0.2391 - val_acc: 0.8951\n",
      "Epoch 859/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1955 - acc: 0.9180 - val_loss: 0.2365 - val_acc: 0.8980\n",
      "Epoch 860/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9177 - val_loss: 0.2363 - val_acc: 0.8973\n",
      "Epoch 861/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9196 - val_loss: 0.2362 - val_acc: 0.8964\n",
      "Epoch 862/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9172 - val_loss: 0.2350 - val_acc: 0.8963\n",
      "Epoch 863/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1956 - acc: 0.9184 - val_loss: 0.2354 - val_acc: 0.8970\n",
      "Epoch 864/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1953 - acc: 0.9181 - val_loss: 0.2366 - val_acc: 0.8958\n",
      "Epoch 865/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1943 - acc: 0.9184 - val_loss: 0.2372 - val_acc: 0.8968\n",
      "Epoch 866/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1961 - acc: 0.9175 - val_loss: 0.2398 - val_acc: 0.8967\n",
      "Epoch 867/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9181 - val_loss: 0.2371 - val_acc: 0.8947\n",
      "Epoch 868/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9182 - val_loss: 0.2387 - val_acc: 0.8968\n",
      "Epoch 869/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1968 - acc: 0.9169 - val_loss: 0.2364 - val_acc: 0.8964\n",
      "Epoch 870/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9184 - val_loss: 0.2369 - val_acc: 0.8971\n",
      "Epoch 871/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9177 - val_loss: 0.2383 - val_acc: 0.8968\n",
      "Epoch 872/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9172 - val_loss: 0.2369 - val_acc: 0.8970\n",
      "Epoch 873/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9175 - val_loss: 0.2370 - val_acc: 0.8938\n",
      "Epoch 874/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9189 - val_loss: 0.2357 - val_acc: 0.8970\n",
      "Epoch 875/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9181 - val_loss: 0.2365 - val_acc: 0.8961\n",
      "Epoch 876/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9176 - val_loss: 0.2347 - val_acc: 0.8970\n",
      "Epoch 877/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1946 - acc: 0.9187 - val_loss: 0.2378 - val_acc: 0.8967\n",
      "Epoch 878/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9174 - val_loss: 0.2374 - val_acc: 0.8977\n",
      "Epoch 879/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9176 - val_loss: 0.2376 - val_acc: 0.8955\n",
      "Epoch 880/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1981 - acc: 0.9171 - val_loss: 0.2462 - val_acc: 0.8918\n",
      "Epoch 881/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1969 - acc: 0.9174 - val_loss: 0.2402 - val_acc: 0.8977\n",
      "Epoch 882/1500\n",
      "20704/20704 [==============================] - 1s 26us/step - loss: 0.1959 - acc: 0.9179 - val_loss: 0.2366 - val_acc: 0.8971\n",
      "Epoch 883/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9176 - val_loss: 0.2356 - val_acc: 0.8964\n",
      "Epoch 884/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1953 - acc: 0.9180 - val_loss: 0.2376 - val_acc: 0.8938\n",
      "Epoch 885/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1953 - acc: 0.9182 - val_loss: 0.2391 - val_acc: 0.8979\n",
      "Epoch 886/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1969 - acc: 0.9177 - val_loss: 0.2376 - val_acc: 0.8974\n",
      "Epoch 887/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1970 - acc: 0.9170 - val_loss: 0.2359 - val_acc: 0.8961\n",
      "Epoch 888/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9172 - val_loss: 0.2366 - val_acc: 0.8979\n",
      "Epoch 889/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9174 - val_loss: 0.2372 - val_acc: 0.8955\n",
      "Epoch 890/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1964 - acc: 0.9176 - val_loss: 0.2395 - val_acc: 0.8944\n",
      "Epoch 891/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9180 - val_loss: 0.2369 - val_acc: 0.8960\n",
      "Epoch 892/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9188 - val_loss: 0.2364 - val_acc: 0.8981\n",
      "Epoch 893/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9194 - val_loss: 0.2360 - val_acc: 0.8952\n",
      "Epoch 894/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9189 - val_loss: 0.2359 - val_acc: 0.8980\n",
      "Epoch 895/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9183 - val_loss: 0.2353 - val_acc: 0.8955\n",
      "Epoch 896/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9176 - val_loss: 0.2396 - val_acc: 0.8958\n",
      "Epoch 897/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1957 - acc: 0.9179 - val_loss: 0.2365 - val_acc: 0.8961\n",
      "Epoch 898/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9167 - val_loss: 0.2358 - val_acc: 0.8973\n",
      "Epoch 899/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1942 - acc: 0.9188 - val_loss: 0.2333 - val_acc: 0.8971\n",
      "Epoch 900/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1958 - acc: 0.9179 - val_loss: 0.2370 - val_acc: 0.8968\n",
      "Epoch 901/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9184 - val_loss: 0.2368 - val_acc: 0.8968\n",
      "Epoch 902/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1956 - acc: 0.9180 - val_loss: 0.2393 - val_acc: 0.8968\n",
      "Epoch 903/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1953 - acc: 0.9184 - val_loss: 0.2369 - val_acc: 0.8976\n",
      "Epoch 904/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9180 - val_loss: 0.2412 - val_acc: 0.8925\n",
      "Epoch 905/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9179 - val_loss: 0.2379 - val_acc: 0.8960\n",
      "Epoch 906/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1950 - acc: 0.9177 - val_loss: 0.2349 - val_acc: 0.8981\n",
      "Epoch 907/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1944 - acc: 0.9176 - val_loss: 0.2444 - val_acc: 0.8945\n",
      "Epoch 908/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9169 - val_loss: 0.2392 - val_acc: 0.8963\n",
      "Epoch 909/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9184 - val_loss: 0.2351 - val_acc: 0.8979\n",
      "Epoch 910/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1962 - acc: 0.9171 - val_loss: 0.2369 - val_acc: 0.8951\n",
      "Epoch 911/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9185 - val_loss: 0.2370 - val_acc: 0.8973\n",
      "Epoch 912/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9170 - val_loss: 0.2396 - val_acc: 0.8957\n",
      "Epoch 913/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1961 - acc: 0.9165 - val_loss: 0.2381 - val_acc: 0.8948\n",
      "Epoch 914/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1958 - acc: 0.9172 - val_loss: 0.2356 - val_acc: 0.8966\n",
      "Epoch 915/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9176 - val_loss: 0.2370 - val_acc: 0.8970\n",
      "Epoch 916/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9178 - val_loss: 0.2417 - val_acc: 0.8945\n",
      "Epoch 917/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9177 - val_loss: 0.2367 - val_acc: 0.8968\n",
      "Epoch 918/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9179 - val_loss: 0.2353 - val_acc: 0.8967\n",
      "Epoch 919/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9177 - val_loss: 0.2351 - val_acc: 0.8967\n",
      "Epoch 920/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9187 - val_loss: 0.2365 - val_acc: 0.8974\n",
      "Epoch 921/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9174 - val_loss: 0.2371 - val_acc: 0.8967\n",
      "Epoch 922/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9185 - val_loss: 0.2383 - val_acc: 0.8980\n",
      "Epoch 923/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9180 - val_loss: 0.2354 - val_acc: 0.8979\n",
      "Epoch 924/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9178 - val_loss: 0.2368 - val_acc: 0.8989\n",
      "Epoch 925/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9172 - val_loss: 0.2380 - val_acc: 0.8957\n",
      "Epoch 926/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9176 - val_loss: 0.2391 - val_acc: 0.8931\n",
      "Epoch 927/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1955 - acc: 0.9179 - val_loss: 0.2359 - val_acc: 0.8963\n",
      "Epoch 928/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9178 - val_loss: 0.2350 - val_acc: 0.8981\n",
      "Epoch 929/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9171 - val_loss: 0.2372 - val_acc: 0.8955\n",
      "Epoch 930/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1990 - acc: 0.9152 - val_loss: 0.2397 - val_acc: 0.8964\n",
      "Epoch 931/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9176 - val_loss: 0.2404 - val_acc: 0.8950\n",
      "Epoch 932/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1965 - acc: 0.9169 - val_loss: 0.2365 - val_acc: 0.8945\n",
      "Epoch 933/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1958 - acc: 0.9170 - val_loss: 0.2383 - val_acc: 0.8921\n",
      "Epoch 934/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9176 - val_loss: 0.2390 - val_acc: 0.8945\n",
      "Epoch 935/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1967 - acc: 0.9172 - val_loss: 0.2345 - val_acc: 0.8983\n",
      "Epoch 936/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9190 - val_loss: 0.2363 - val_acc: 0.8966\n",
      "Epoch 937/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9179 - val_loss: 0.2367 - val_acc: 0.8973\n",
      "Epoch 938/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9185 - val_loss: 0.2354 - val_acc: 0.8947\n",
      "Epoch 939/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9186 - val_loss: 0.2383 - val_acc: 0.8952\n",
      "Epoch 940/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1955 - acc: 0.9181 - val_loss: 0.2388 - val_acc: 0.8935\n",
      "Epoch 941/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9177 - val_loss: 0.2393 - val_acc: 0.8955\n",
      "Epoch 942/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1960 - acc: 0.9169 - val_loss: 0.2399 - val_acc: 0.8945\n",
      "Epoch 943/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9178 - val_loss: 0.2375 - val_acc: 0.8970\n",
      "Epoch 944/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1956 - acc: 0.9177 - val_loss: 0.2348 - val_acc: 0.8963\n",
      "Epoch 945/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9188 - val_loss: 0.2370 - val_acc: 0.8981\n",
      "Epoch 946/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9188 - val_loss: 0.2400 - val_acc: 0.8960\n",
      "Epoch 947/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9182 - val_loss: 0.2368 - val_acc: 0.8973\n",
      "Epoch 948/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9183 - val_loss: 0.2384 - val_acc: 0.8947\n",
      "Epoch 949/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9177 - val_loss: 0.2383 - val_acc: 0.8970\n",
      "Epoch 950/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1955 - acc: 0.9172 - val_loss: 0.2412 - val_acc: 0.8934\n",
      "Epoch 951/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1971 - acc: 0.9171 - val_loss: 0.2356 - val_acc: 0.8974\n",
      "Epoch 952/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9180 - val_loss: 0.2357 - val_acc: 0.8983\n",
      "Epoch 953/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9175 - val_loss: 0.2380 - val_acc: 0.8966\n",
      "Epoch 954/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9187 - val_loss: 0.2379 - val_acc: 0.8960\n",
      "Epoch 955/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1961 - acc: 0.9179 - val_loss: 0.2357 - val_acc: 0.8979\n",
      "Epoch 956/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1975 - acc: 0.9164 - val_loss: 0.2368 - val_acc: 0.8979\n",
      "Epoch 957/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1983 - acc: 0.9162 - val_loss: 0.2439 - val_acc: 0.8919\n",
      "Epoch 958/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1955 - acc: 0.9188 - val_loss: 0.2364 - val_acc: 0.8971\n",
      "Epoch 959/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9185 - val_loss: 0.2361 - val_acc: 0.8970\n",
      "Epoch 960/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9179 - val_loss: 0.2396 - val_acc: 0.8955\n",
      "Epoch 961/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9183 - val_loss: 0.2361 - val_acc: 0.8983\n",
      "Epoch 962/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9189 - val_loss: 0.2365 - val_acc: 0.8968\n",
      "Epoch 963/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9186 - val_loss: 0.2375 - val_acc: 0.8958\n",
      "Epoch 964/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1956 - acc: 0.9179 - val_loss: 0.2429 - val_acc: 0.8939\n",
      "Epoch 965/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1960 - acc: 0.9177 - val_loss: 0.2386 - val_acc: 0.8970\n",
      "Epoch 966/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1958 - acc: 0.9178 - val_loss: 0.2379 - val_acc: 0.8964\n",
      "Epoch 967/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1965 - acc: 0.9164 - val_loss: 0.2373 - val_acc: 0.8952\n",
      "Epoch 968/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9186 - val_loss: 0.2368 - val_acc: 0.8970\n",
      "Epoch 969/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9175 - val_loss: 0.2345 - val_acc: 0.8992\n",
      "Epoch 970/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9180 - val_loss: 0.2379 - val_acc: 0.8954\n",
      "Epoch 971/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9186 - val_loss: 0.2374 - val_acc: 0.8958\n",
      "Epoch 972/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1969 - acc: 0.9176 - val_loss: 0.2367 - val_acc: 0.8951\n",
      "Epoch 973/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9177 - val_loss: 0.2370 - val_acc: 0.8954\n",
      "Epoch 974/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9184 - val_loss: 0.2359 - val_acc: 0.8980\n",
      "Epoch 975/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9184 - val_loss: 0.2363 - val_acc: 0.8958\n",
      "Epoch 976/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9184 - val_loss: 0.2352 - val_acc: 0.8977\n",
      "Epoch 977/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9190 - val_loss: 0.2356 - val_acc: 0.8984\n",
      "Epoch 978/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1942 - acc: 0.9191 - val_loss: 0.2346 - val_acc: 0.8981\n",
      "Epoch 979/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9179 - val_loss: 0.2406 - val_acc: 0.8968\n",
      "Epoch 980/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9191 - val_loss: 0.2364 - val_acc: 0.8970\n",
      "Epoch 981/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9176 - val_loss: 0.2362 - val_acc: 0.8957\n",
      "Epoch 982/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9181 - val_loss: 0.2366 - val_acc: 0.8952\n",
      "Epoch 983/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1956 - acc: 0.9180 - val_loss: 0.2358 - val_acc: 0.8955\n",
      "Epoch 984/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9183 - val_loss: 0.2360 - val_acc: 0.8964\n",
      "Epoch 985/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9182 - val_loss: 0.2346 - val_acc: 0.8984\n",
      "Epoch 986/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9180 - val_loss: 0.2387 - val_acc: 0.8986\n",
      "Epoch 987/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9182 - val_loss: 0.2374 - val_acc: 0.8958\n",
      "Epoch 988/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9174 - val_loss: 0.2385 - val_acc: 0.8957\n",
      "Epoch 989/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9188 - val_loss: 0.2369 - val_acc: 0.8952\n",
      "Epoch 990/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9180 - val_loss: 0.2387 - val_acc: 0.8971\n",
      "Epoch 991/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9172 - val_loss: 0.2378 - val_acc: 0.8957\n",
      "Epoch 992/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1972 - acc: 0.9169 - val_loss: 0.2376 - val_acc: 0.8963\n",
      "Epoch 993/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9173 - val_loss: 0.2366 - val_acc: 0.8966\n",
      "Epoch 994/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9187 - val_loss: 0.2373 - val_acc: 0.8979\n",
      "Epoch 995/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9174 - val_loss: 0.2376 - val_acc: 0.8964\n",
      "Epoch 996/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1957 - acc: 0.9183 - val_loss: 0.2352 - val_acc: 0.8976\n",
      "Epoch 997/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9190 - val_loss: 0.2371 - val_acc: 0.8968\n",
      "Epoch 998/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9174 - val_loss: 0.2359 - val_acc: 0.8952\n",
      "Epoch 999/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1939 - acc: 0.9185 - val_loss: 0.2345 - val_acc: 0.8984\n",
      "Epoch 1000/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9178 - val_loss: 0.2398 - val_acc: 0.8942\n",
      "Epoch 1001/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9183 - val_loss: 0.2388 - val_acc: 0.8973\n",
      "Epoch 1002/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9186 - val_loss: 0.2372 - val_acc: 0.8977\n",
      "Epoch 1003/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9173 - val_loss: 0.2376 - val_acc: 0.8963\n",
      "Epoch 1004/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9184 - val_loss: 0.2383 - val_acc: 0.8980\n",
      "Epoch 1005/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9184 - val_loss: 0.2362 - val_acc: 0.8980\n",
      "Epoch 1006/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9180 - val_loss: 0.2352 - val_acc: 0.8967\n",
      "Epoch 1007/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9180 - val_loss: 0.2345 - val_acc: 0.8961\n",
      "Epoch 1008/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9181 - val_loss: 0.2357 - val_acc: 0.8976\n",
      "Epoch 1009/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9180 - val_loss: 0.2345 - val_acc: 0.8981\n",
      "Epoch 1010/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9169 - val_loss: 0.2379 - val_acc: 0.8966\n",
      "Epoch 1011/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9175 - val_loss: 0.2350 - val_acc: 0.8961\n",
      "Epoch 1012/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9185 - val_loss: 0.2355 - val_acc: 0.8967\n",
      "Epoch 1013/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9190 - val_loss: 0.2363 - val_acc: 0.8974\n",
      "Epoch 1014/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1954 - acc: 0.9174 - val_loss: 0.2352 - val_acc: 0.8954\n",
      "Epoch 1015/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1953 - acc: 0.9176 - val_loss: 0.2371 - val_acc: 0.8948\n",
      "Epoch 1016/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9184 - val_loss: 0.2385 - val_acc: 0.8971\n",
      "Epoch 1017/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1947 - acc: 0.9187 - val_loss: 0.2378 - val_acc: 0.8980\n",
      "Epoch 1018/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1946 - acc: 0.9185 - val_loss: 0.2375 - val_acc: 0.8981\n",
      "Epoch 1019/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1956 - acc: 0.9180 - val_loss: 0.2448 - val_acc: 0.8929\n",
      "Epoch 1020/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9164 - val_loss: 0.2397 - val_acc: 0.8971\n",
      "Epoch 1021/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9169 - val_loss: 0.2405 - val_acc: 0.8981\n",
      "Epoch 1022/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9186 - val_loss: 0.2409 - val_acc: 0.8976\n",
      "Epoch 1023/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9173 - val_loss: 0.2361 - val_acc: 0.8977\n",
      "Epoch 1024/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9180 - val_loss: 0.2356 - val_acc: 0.8966\n",
      "Epoch 1025/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9183 - val_loss: 0.2366 - val_acc: 0.8970\n",
      "Epoch 1026/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9184 - val_loss: 0.2358 - val_acc: 0.8973\n",
      "Epoch 1027/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9176 - val_loss: 0.2348 - val_acc: 0.8968\n",
      "Epoch 1028/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1985 - acc: 0.9162 - val_loss: 0.2410 - val_acc: 0.8980\n",
      "Epoch 1029/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1968 - acc: 0.9172 - val_loss: 0.2381 - val_acc: 0.8964\n",
      "Epoch 1030/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1988 - acc: 0.9152 - val_loss: 0.2441 - val_acc: 0.8916\n",
      "Epoch 1031/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1994 - acc: 0.9150 - val_loss: 0.2414 - val_acc: 0.8970\n",
      "Epoch 1032/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1968 - acc: 0.9177 - val_loss: 0.2366 - val_acc: 0.8980\n",
      "Epoch 1033/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9185 - val_loss: 0.2369 - val_acc: 0.8971\n",
      "Epoch 1034/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1942 - acc: 0.9181 - val_loss: 0.2369 - val_acc: 0.8968\n",
      "Epoch 1035/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1950 - acc: 0.9180 - val_loss: 0.2355 - val_acc: 0.8960\n",
      "Epoch 1036/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1948 - acc: 0.9178 - val_loss: 0.2357 - val_acc: 0.8970\n",
      "Epoch 1037/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1950 - acc: 0.9188 - val_loss: 0.2352 - val_acc: 0.8970\n",
      "Epoch 1038/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1945 - acc: 0.9186 - val_loss: 0.2389 - val_acc: 0.8955\n",
      "Epoch 1039/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9183 - val_loss: 0.2360 - val_acc: 0.8960\n",
      "Epoch 1040/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1945 - acc: 0.9177 - val_loss: 0.2352 - val_acc: 0.8979\n",
      "Epoch 1041/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9178 - val_loss: 0.2364 - val_acc: 0.8970\n",
      "Epoch 1042/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9176 - val_loss: 0.2363 - val_acc: 0.8977\n",
      "Epoch 1043/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9180 - val_loss: 0.2375 - val_acc: 0.8939\n",
      "Epoch 1044/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9185 - val_loss: 0.2345 - val_acc: 0.8957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1045/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9182 - val_loss: 0.2395 - val_acc: 0.8980\n",
      "Epoch 1046/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9182 - val_loss: 0.2353 - val_acc: 0.8986\n",
      "Epoch 1047/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1954 - acc: 0.9177 - val_loss: 0.2375 - val_acc: 0.8964\n",
      "Epoch 1048/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1950 - acc: 0.9180 - val_loss: 0.2389 - val_acc: 0.8929\n",
      "Epoch 1049/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1953 - acc: 0.9181 - val_loss: 0.2378 - val_acc: 0.8966\n",
      "Epoch 1050/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9184 - val_loss: 0.2376 - val_acc: 0.8947\n",
      "Epoch 1051/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1958 - acc: 0.9186 - val_loss: 0.2381 - val_acc: 0.8958\n",
      "Epoch 1052/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9182 - val_loss: 0.2395 - val_acc: 0.8955\n",
      "Epoch 1053/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9183 - val_loss: 0.2366 - val_acc: 0.8993\n",
      "Epoch 1054/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9178 - val_loss: 0.2379 - val_acc: 0.8948\n",
      "Epoch 1055/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9184 - val_loss: 0.2370 - val_acc: 0.8974\n",
      "Epoch 1056/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1969 - acc: 0.9172 - val_loss: 0.2366 - val_acc: 0.8954\n",
      "Epoch 1057/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9179 - val_loss: 0.2404 - val_acc: 0.8951\n",
      "Epoch 1058/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9184 - val_loss: 0.2368 - val_acc: 0.8967\n",
      "Epoch 1059/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9171 - val_loss: 0.2358 - val_acc: 0.8961\n",
      "Epoch 1060/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9184 - val_loss: 0.2370 - val_acc: 0.8971\n",
      "Epoch 1061/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1942 - acc: 0.9182 - val_loss: 0.2378 - val_acc: 0.8980\n",
      "Epoch 1062/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9190 - val_loss: 0.2378 - val_acc: 0.8971\n",
      "Epoch 1063/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9182 - val_loss: 0.2354 - val_acc: 0.8974\n",
      "Epoch 1064/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1964 - acc: 0.9179 - val_loss: 0.2392 - val_acc: 0.8939\n",
      "Epoch 1065/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9176 - val_loss: 0.2381 - val_acc: 0.8966\n",
      "Epoch 1066/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9177 - val_loss: 0.2369 - val_acc: 0.8986\n",
      "Epoch 1067/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1945 - acc: 0.9192 - val_loss: 0.2373 - val_acc: 0.8966\n",
      "Epoch 1068/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9186 - val_loss: 0.2399 - val_acc: 0.8967\n",
      "Epoch 1069/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1968 - acc: 0.9164 - val_loss: 0.2401 - val_acc: 0.8964\n",
      "Epoch 1070/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9176 - val_loss: 0.2371 - val_acc: 0.8977\n",
      "Epoch 1071/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1940 - acc: 0.9181 - val_loss: 0.2376 - val_acc: 0.8954\n",
      "Epoch 1072/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9182 - val_loss: 0.2372 - val_acc: 0.8958\n",
      "Epoch 1073/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9176 - val_loss: 0.2389 - val_acc: 0.8937\n",
      "Epoch 1074/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9175 - val_loss: 0.2377 - val_acc: 0.8958\n",
      "Epoch 1075/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9179 - val_loss: 0.2381 - val_acc: 0.8984\n",
      "Epoch 1076/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1935 - acc: 0.9180 - val_loss: 0.2364 - val_acc: 0.9008\n",
      "Epoch 1077/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1945 - acc: 0.9199 - val_loss: 0.2373 - val_acc: 0.8961\n",
      "Epoch 1078/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9186 - val_loss: 0.2351 - val_acc: 0.8971\n",
      "Epoch 1079/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1942 - acc: 0.9188 - val_loss: 0.2359 - val_acc: 0.8979\n",
      "Epoch 1080/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9176 - val_loss: 0.2367 - val_acc: 0.8963\n",
      "Epoch 1081/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9182 - val_loss: 0.2359 - val_acc: 0.8974\n",
      "Epoch 1082/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9182 - val_loss: 0.2362 - val_acc: 0.8967\n",
      "Epoch 1083/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1970 - acc: 0.9172 - val_loss: 0.2463 - val_acc: 0.8895\n",
      "Epoch 1084/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9188 - val_loss: 0.2363 - val_acc: 0.8970\n",
      "Epoch 1085/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9174 - val_loss: 0.2464 - val_acc: 0.8931\n",
      "Epoch 1086/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9173 - val_loss: 0.2372 - val_acc: 0.8987\n",
      "Epoch 1087/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9185 - val_loss: 0.2378 - val_acc: 0.8961\n",
      "Epoch 1088/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9183 - val_loss: 0.2371 - val_acc: 0.8964\n",
      "Epoch 1089/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9181 - val_loss: 0.2377 - val_acc: 0.8986\n",
      "Epoch 1090/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9190 - val_loss: 0.2387 - val_acc: 0.8984\n",
      "Epoch 1091/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1953 - acc: 0.9173 - val_loss: 0.2367 - val_acc: 0.8990\n",
      "Epoch 1092/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1952 - acc: 0.9177 - val_loss: 0.2363 - val_acc: 0.8973\n",
      "Epoch 1093/1500\n",
      "20704/20704 [==============================] - 1s 26us/step - loss: 0.1939 - acc: 0.9191 - val_loss: 0.2354 - val_acc: 0.8961\n",
      "Epoch 1094/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1956 - acc: 0.9177 - val_loss: 0.2376 - val_acc: 0.8948\n",
      "Epoch 1095/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9176 - val_loss: 0.2401 - val_acc: 0.8932\n",
      "Epoch 1096/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9180 - val_loss: 0.2379 - val_acc: 0.8961\n",
      "Epoch 1097/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9177 - val_loss: 0.2362 - val_acc: 0.8981\n",
      "Epoch 1098/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9175 - val_loss: 0.2380 - val_acc: 0.8961\n",
      "Epoch 1099/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9174 - val_loss: 0.2366 - val_acc: 0.8960\n",
      "Epoch 1100/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1963 - acc: 0.9181 - val_loss: 0.2374 - val_acc: 0.8968\n",
      "Epoch 1101/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9174 - val_loss: 0.2373 - val_acc: 0.8983\n",
      "Epoch 1102/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9177 - val_loss: 0.2376 - val_acc: 0.8976\n",
      "Epoch 1103/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9180 - val_loss: 0.2395 - val_acc: 0.8950\n",
      "Epoch 1104/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9174 - val_loss: 0.2401 - val_acc: 0.8958\n",
      "Epoch 1105/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9171 - val_loss: 0.2386 - val_acc: 0.8971\n",
      "Epoch 1106/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9180 - val_loss: 0.2389 - val_acc: 0.8974\n",
      "Epoch 1107/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9176 - val_loss: 0.2376 - val_acc: 0.8963\n",
      "Epoch 1108/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9182 - val_loss: 0.2381 - val_acc: 0.8967\n",
      "Epoch 1109/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9181 - val_loss: 0.2359 - val_acc: 0.8990\n",
      "Epoch 1110/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9184 - val_loss: 0.2370 - val_acc: 0.8976\n",
      "Epoch 1111/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9178 - val_loss: 0.2368 - val_acc: 0.8963\n",
      "Epoch 1112/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9183 - val_loss: 0.2388 - val_acc: 0.8960\n",
      "Epoch 1113/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9179 - val_loss: 0.2366 - val_acc: 0.8971\n",
      "Epoch 1114/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9178 - val_loss: 0.2369 - val_acc: 0.8947\n",
      "Epoch 1115/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9188 - val_loss: 0.2356 - val_acc: 0.8967\n",
      "Epoch 1116/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1940 - acc: 0.9191 - val_loss: 0.2356 - val_acc: 0.8968\n",
      "Epoch 1117/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1974 - acc: 0.9165 - val_loss: 0.2424 - val_acc: 0.8915\n",
      "Epoch 1118/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1974 - acc: 0.9155 - val_loss: 0.2367 - val_acc: 0.8973\n",
      "Epoch 1119/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9182 - val_loss: 0.2369 - val_acc: 0.8963\n",
      "Epoch 1120/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1943 - acc: 0.9187 - val_loss: 0.2372 - val_acc: 0.8979\n",
      "Epoch 1121/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9183 - val_loss: 0.2374 - val_acc: 0.8955\n",
      "Epoch 1122/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1958 - acc: 0.9168 - val_loss: 0.2377 - val_acc: 0.8955\n",
      "Epoch 1123/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9178 - val_loss: 0.2357 - val_acc: 0.8984\n",
      "Epoch 1124/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1936 - acc: 0.9183 - val_loss: 0.2372 - val_acc: 0.8964\n",
      "Epoch 1125/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1943 - acc: 0.9186 - val_loss: 0.2397 - val_acc: 0.8970\n",
      "Epoch 1126/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9177 - val_loss: 0.2366 - val_acc: 0.8971\n",
      "Epoch 1127/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9187 - val_loss: 0.2361 - val_acc: 0.8976\n",
      "Epoch 1128/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9175 - val_loss: 0.2408 - val_acc: 0.8924\n",
      "Epoch 1129/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9168 - val_loss: 0.2368 - val_acc: 0.8981\n",
      "Epoch 1130/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1942 - acc: 0.9187 - val_loss: 0.2359 - val_acc: 0.8971\n",
      "Epoch 1131/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9183 - val_loss: 0.2374 - val_acc: 0.8973\n",
      "Epoch 1132/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9183 - val_loss: 0.2455 - val_acc: 0.8897\n",
      "Epoch 1133/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9178 - val_loss: 0.2343 - val_acc: 0.9003\n",
      "Epoch 1134/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9176 - val_loss: 0.2367 - val_acc: 0.8964\n",
      "Epoch 1135/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1942 - acc: 0.9183 - val_loss: 0.2369 - val_acc: 0.8971\n",
      "Epoch 1136/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9180 - val_loss: 0.2360 - val_acc: 0.8973\n",
      "Epoch 1137/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1942 - acc: 0.9185 - val_loss: 0.2356 - val_acc: 0.8976\n",
      "Epoch 1138/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9187 - val_loss: 0.2366 - val_acc: 0.8984\n",
      "Epoch 1139/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1983 - acc: 0.9168 - val_loss: 0.2370 - val_acc: 0.8970\n",
      "Epoch 1140/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9182 - val_loss: 0.2359 - val_acc: 0.8984\n",
      "Epoch 1141/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1955 - acc: 0.9183 - val_loss: 0.2370 - val_acc: 0.8971\n",
      "Epoch 1142/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1966 - acc: 0.9169 - val_loss: 0.2384 - val_acc: 0.8948\n",
      "Epoch 1143/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9179 - val_loss: 0.2385 - val_acc: 0.8947\n",
      "Epoch 1144/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9182 - val_loss: 0.2352 - val_acc: 0.8967\n",
      "Epoch 1145/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1941 - acc: 0.9185 - val_loss: 0.2360 - val_acc: 0.8971\n",
      "Epoch 1146/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9184 - val_loss: 0.2368 - val_acc: 0.8964\n",
      "Epoch 1147/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9183 - val_loss: 0.2349 - val_acc: 0.8984\n",
      "Epoch 1148/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9181 - val_loss: 0.2375 - val_acc: 0.8961\n",
      "Epoch 1149/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9183 - val_loss: 0.2397 - val_acc: 0.8938\n",
      "Epoch 1150/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9184 - val_loss: 0.2373 - val_acc: 0.8968\n",
      "Epoch 1151/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1941 - acc: 0.9190 - val_loss: 0.2359 - val_acc: 0.8987\n",
      "Epoch 1152/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9161 - val_loss: 0.2449 - val_acc: 0.8919\n",
      "Epoch 1153/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9186 - val_loss: 0.2375 - val_acc: 0.8966\n",
      "Epoch 1154/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9177 - val_loss: 0.2373 - val_acc: 0.8979\n",
      "Epoch 1155/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9180 - val_loss: 0.2373 - val_acc: 0.8954\n",
      "Epoch 1156/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9180 - val_loss: 0.2383 - val_acc: 0.8948\n",
      "Epoch 1157/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9176 - val_loss: 0.2369 - val_acc: 0.8963\n",
      "Epoch 1158/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9186 - val_loss: 0.2498 - val_acc: 0.8876\n",
      "Epoch 1159/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9184 - val_loss: 0.2376 - val_acc: 0.8984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1160/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9180 - val_loss: 0.2379 - val_acc: 0.8970\n",
      "Epoch 1161/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1963 - acc: 0.9167 - val_loss: 0.2451 - val_acc: 0.8912\n",
      "Epoch 1162/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1966 - acc: 0.9167 - val_loss: 0.2383 - val_acc: 0.8976\n",
      "Epoch 1163/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9187 - val_loss: 0.2381 - val_acc: 0.8954\n",
      "Epoch 1164/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9176 - val_loss: 0.2371 - val_acc: 0.8970\n",
      "Epoch 1165/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9186 - val_loss: 0.2385 - val_acc: 0.8968\n",
      "Epoch 1166/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9172 - val_loss: 0.2364 - val_acc: 0.8971\n",
      "Epoch 1167/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1959 - acc: 0.9173 - val_loss: 0.2361 - val_acc: 0.8960\n",
      "Epoch 1168/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9182 - val_loss: 0.2388 - val_acc: 0.8932\n",
      "Epoch 1169/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9183 - val_loss: 0.2377 - val_acc: 0.8960\n",
      "Epoch 1170/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1941 - acc: 0.9184 - val_loss: 0.2373 - val_acc: 0.8952\n",
      "Epoch 1171/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9181 - val_loss: 0.2352 - val_acc: 0.8970\n",
      "Epoch 1172/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1962 - acc: 0.9180 - val_loss: 0.2397 - val_acc: 0.8964\n",
      "Epoch 1173/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1964 - acc: 0.9183 - val_loss: 0.2390 - val_acc: 0.8957\n",
      "Epoch 1174/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1969 - acc: 0.9160 - val_loss: 0.2402 - val_acc: 0.8926\n",
      "Epoch 1175/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9183 - val_loss: 0.2368 - val_acc: 0.8963\n",
      "Epoch 1176/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9176 - val_loss: 0.2366 - val_acc: 0.8963\n",
      "Epoch 1177/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9188 - val_loss: 0.2371 - val_acc: 0.8958\n",
      "Epoch 1178/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9183 - val_loss: 0.2383 - val_acc: 0.8958\n",
      "Epoch 1179/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9181 - val_loss: 0.2383 - val_acc: 0.8963\n",
      "Epoch 1180/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1962 - acc: 0.9165 - val_loss: 0.2428 - val_acc: 0.8945\n",
      "Epoch 1181/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1968 - acc: 0.9165 - val_loss: 0.2440 - val_acc: 0.8887\n",
      "Epoch 1182/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9179 - val_loss: 0.2377 - val_acc: 0.8964\n",
      "Epoch 1183/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9175 - val_loss: 0.2402 - val_acc: 0.8966\n",
      "Epoch 1184/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9186 - val_loss: 0.2387 - val_acc: 0.8964\n",
      "Epoch 1185/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1957 - acc: 0.9177 - val_loss: 0.2382 - val_acc: 0.8955\n",
      "Epoch 1186/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9179 - val_loss: 0.2394 - val_acc: 0.8974\n",
      "Epoch 1187/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9184 - val_loss: 0.2391 - val_acc: 0.8976\n",
      "Epoch 1188/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9179 - val_loss: 0.2370 - val_acc: 0.8981\n",
      "Epoch 1189/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1939 - acc: 0.9184 - val_loss: 0.2393 - val_acc: 0.8955\n",
      "Epoch 1190/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9183 - val_loss: 0.2370 - val_acc: 0.8966\n",
      "Epoch 1191/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9193 - val_loss: 0.2399 - val_acc: 0.8950\n",
      "Epoch 1192/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9182 - val_loss: 0.2380 - val_acc: 0.8955\n",
      "Epoch 1193/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9188 - val_loss: 0.2363 - val_acc: 0.8973\n",
      "Epoch 1194/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1951 - acc: 0.9171 - val_loss: 0.2369 - val_acc: 0.8961\n",
      "Epoch 1195/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9184 - val_loss: 0.2372 - val_acc: 0.8979\n",
      "Epoch 1196/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1943 - acc: 0.9186 - val_loss: 0.2359 - val_acc: 0.8958\n",
      "Epoch 1197/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9180 - val_loss: 0.2367 - val_acc: 0.8979\n",
      "Epoch 1198/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9190 - val_loss: 0.2389 - val_acc: 0.8968\n",
      "Epoch 1199/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9186 - val_loss: 0.2371 - val_acc: 0.8944\n",
      "Epoch 1200/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1940 - acc: 0.9185 - val_loss: 0.2377 - val_acc: 0.8989\n",
      "Epoch 1201/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9188 - val_loss: 0.2367 - val_acc: 0.8983\n",
      "Epoch 1202/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9173 - val_loss: 0.2348 - val_acc: 0.8984\n",
      "Epoch 1203/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9182 - val_loss: 0.2362 - val_acc: 0.8966\n",
      "Epoch 1204/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9186 - val_loss: 0.2360 - val_acc: 0.8971\n",
      "Epoch 1205/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1935 - acc: 0.9191 - val_loss: 0.2357 - val_acc: 0.8981\n",
      "Epoch 1206/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1942 - acc: 0.9187 - val_loss: 0.2377 - val_acc: 0.8990\n",
      "Epoch 1207/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9185 - val_loss: 0.2385 - val_acc: 0.8973\n",
      "Epoch 1208/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1965 - acc: 0.9168 - val_loss: 0.2389 - val_acc: 0.8966\n",
      "Epoch 1209/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9176 - val_loss: 0.2376 - val_acc: 0.8977\n",
      "Epoch 1210/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9180 - val_loss: 0.2361 - val_acc: 0.8957\n",
      "Epoch 1211/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1938 - acc: 0.9191 - val_loss: 0.2366 - val_acc: 0.8941\n",
      "Epoch 1212/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1949 - acc: 0.9181 - val_loss: 0.2394 - val_acc: 0.8977\n",
      "Epoch 1213/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1973 - acc: 0.9169 - val_loss: 0.2374 - val_acc: 0.8984\n",
      "Epoch 1214/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1964 - acc: 0.9175 - val_loss: 0.2365 - val_acc: 0.8963\n",
      "Epoch 1215/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1949 - acc: 0.9182 - val_loss: 0.2348 - val_acc: 0.8983\n",
      "Epoch 1216/1500\n",
      "20704/20704 [==============================] - 1s 26us/step - loss: 0.1945 - acc: 0.9183 - val_loss: 0.2362 - val_acc: 0.8971\n",
      "Epoch 1217/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1949 - acc: 0.9184 - val_loss: 0.2400 - val_acc: 0.8929\n",
      "Epoch 1218/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9180 - val_loss: 0.2373 - val_acc: 0.8987\n",
      "Epoch 1219/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9186 - val_loss: 0.2360 - val_acc: 0.8973\n",
      "Epoch 1220/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1943 - acc: 0.9184 - val_loss: 0.2365 - val_acc: 0.8967\n",
      "Epoch 1221/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9185 - val_loss: 0.2366 - val_acc: 0.8981\n",
      "Epoch 1222/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9187 - val_loss: 0.2366 - val_acc: 0.8963\n",
      "Epoch 1223/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1941 - acc: 0.9182 - val_loss: 0.2365 - val_acc: 0.8968\n",
      "Epoch 1224/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9179 - val_loss: 0.2346 - val_acc: 0.8984\n",
      "Epoch 1225/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9172 - val_loss: 0.2369 - val_acc: 0.8971\n",
      "Epoch 1226/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9178 - val_loss: 0.2353 - val_acc: 0.8979\n",
      "Epoch 1227/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1945 - acc: 0.9176 - val_loss: 0.2368 - val_acc: 0.8952\n",
      "Epoch 1228/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9180 - val_loss: 0.2386 - val_acc: 0.8964\n",
      "Epoch 1229/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9183 - val_loss: 0.2360 - val_acc: 0.8981\n",
      "Epoch 1230/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1940 - acc: 0.9190 - val_loss: 0.2376 - val_acc: 0.8954\n",
      "Epoch 1231/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9180 - val_loss: 0.2357 - val_acc: 0.8980\n",
      "Epoch 1232/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9181 - val_loss: 0.2368 - val_acc: 0.8968\n",
      "Epoch 1233/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9181 - val_loss: 0.2350 - val_acc: 0.8976\n",
      "Epoch 1234/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9186 - val_loss: 0.2340 - val_acc: 0.8971\n",
      "Epoch 1235/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9178 - val_loss: 0.2350 - val_acc: 0.8977\n",
      "Epoch 1236/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9176 - val_loss: 0.2374 - val_acc: 0.8964\n",
      "Epoch 1237/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9179 - val_loss: 0.2381 - val_acc: 0.8961\n",
      "Epoch 1238/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9178 - val_loss: 0.2387 - val_acc: 0.8944\n",
      "Epoch 1239/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9179 - val_loss: 0.2367 - val_acc: 0.8980\n",
      "Epoch 1240/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9181 - val_loss: 0.2362 - val_acc: 0.8976\n",
      "Epoch 1241/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9189 - val_loss: 0.2369 - val_acc: 0.8952\n",
      "Epoch 1242/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9185 - val_loss: 0.2360 - val_acc: 0.8973\n",
      "Epoch 1243/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9181 - val_loss: 0.2369 - val_acc: 0.8977\n",
      "Epoch 1244/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1939 - acc: 0.9196 - val_loss: 0.2360 - val_acc: 0.8994\n",
      "Epoch 1245/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9183 - val_loss: 0.2361 - val_acc: 0.8980\n",
      "Epoch 1246/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1940 - acc: 0.9188 - val_loss: 0.2373 - val_acc: 0.8971\n",
      "Epoch 1247/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1938 - acc: 0.9189 - val_loss: 0.2368 - val_acc: 0.8981\n",
      "Epoch 1248/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9179 - val_loss: 0.2366 - val_acc: 0.8961\n",
      "Epoch 1249/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1942 - acc: 0.9192 - val_loss: 0.2410 - val_acc: 0.8954\n",
      "Epoch 1250/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9174 - val_loss: 0.2373 - val_acc: 0.8952\n",
      "Epoch 1251/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1945 - acc: 0.9185 - val_loss: 0.2361 - val_acc: 0.8964\n",
      "Epoch 1252/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9189 - val_loss: 0.2361 - val_acc: 0.8983\n",
      "Epoch 1253/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1961 - acc: 0.9173 - val_loss: 0.2375 - val_acc: 0.8967\n",
      "Epoch 1254/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9185 - val_loss: 0.2376 - val_acc: 0.8971\n",
      "Epoch 1255/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9193 - val_loss: 0.2374 - val_acc: 0.8957\n",
      "Epoch 1256/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9184 - val_loss: 0.2415 - val_acc: 0.8955\n",
      "Epoch 1257/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9188 - val_loss: 0.2375 - val_acc: 0.8961\n",
      "Epoch 1258/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1945 - acc: 0.9185 - val_loss: 0.2376 - val_acc: 0.8980\n",
      "Epoch 1259/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9191 - val_loss: 0.2376 - val_acc: 0.8970\n",
      "Epoch 1260/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1950 - acc: 0.9178 - val_loss: 0.2373 - val_acc: 0.8968\n",
      "Epoch 1261/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9180 - val_loss: 0.2360 - val_acc: 0.8963\n",
      "Epoch 1262/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1943 - acc: 0.9190 - val_loss: 0.2389 - val_acc: 0.8967\n",
      "Epoch 1263/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9195 - val_loss: 0.2402 - val_acc: 0.8986\n",
      "Epoch 1264/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1941 - acc: 0.9184 - val_loss: 0.2401 - val_acc: 0.8945\n",
      "Epoch 1265/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1937 - acc: 0.9187 - val_loss: 0.2372 - val_acc: 0.8980\n",
      "Epoch 1266/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9181 - val_loss: 0.2403 - val_acc: 0.8971\n",
      "Epoch 1267/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9178 - val_loss: 0.2364 - val_acc: 0.8976\n",
      "Epoch 1268/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9184 - val_loss: 0.2363 - val_acc: 0.8966\n",
      "Epoch 1269/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9182 - val_loss: 0.2385 - val_acc: 0.8958\n",
      "Epoch 1270/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9189 - val_loss: 0.2379 - val_acc: 0.8979\n",
      "Epoch 1271/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1939 - acc: 0.9197 - val_loss: 0.2388 - val_acc: 0.8952\n",
      "Epoch 1272/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9181 - val_loss: 0.2369 - val_acc: 0.8979\n",
      "Epoch 1273/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9180 - val_loss: 0.2399 - val_acc: 0.8971\n",
      "Epoch 1274/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9178 - val_loss: 0.2379 - val_acc: 0.8971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1275/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9180 - val_loss: 0.2359 - val_acc: 0.8984\n",
      "Epoch 1276/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9180 - val_loss: 0.2420 - val_acc: 0.8944\n",
      "Epoch 1277/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9191 - val_loss: 0.2346 - val_acc: 0.8994\n",
      "Epoch 1278/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1933 - acc: 0.9190 - val_loss: 0.2373 - val_acc: 0.8955\n",
      "Epoch 1279/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9185 - val_loss: 0.2403 - val_acc: 0.8974\n",
      "Epoch 1280/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1945 - acc: 0.9184 - val_loss: 0.2374 - val_acc: 0.8976\n",
      "Epoch 1281/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1945 - acc: 0.9181 - val_loss: 0.2363 - val_acc: 0.8970\n",
      "Epoch 1282/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1941 - acc: 0.9185 - val_loss: 0.2391 - val_acc: 0.8955\n",
      "Epoch 1283/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9186 - val_loss: 0.2362 - val_acc: 0.8950\n",
      "Epoch 1284/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9177 - val_loss: 0.2377 - val_acc: 0.8945\n",
      "Epoch 1285/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1942 - acc: 0.9192 - val_loss: 0.2388 - val_acc: 0.8970\n",
      "Epoch 1286/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1967 - acc: 0.9185 - val_loss: 0.2363 - val_acc: 0.8973\n",
      "Epoch 1287/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9179 - val_loss: 0.2365 - val_acc: 0.8976\n",
      "Epoch 1288/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9191 - val_loss: 0.2355 - val_acc: 0.8964\n",
      "Epoch 1289/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9177 - val_loss: 0.2371 - val_acc: 0.8976\n",
      "Epoch 1290/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9189 - val_loss: 0.2377 - val_acc: 0.8963\n",
      "Epoch 1291/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9190 - val_loss: 0.2368 - val_acc: 0.8986\n",
      "Epoch 1292/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1954 - acc: 0.9186 - val_loss: 0.2370 - val_acc: 0.8981\n",
      "Epoch 1293/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9185 - val_loss: 0.2374 - val_acc: 0.8974\n",
      "Epoch 1294/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1943 - acc: 0.9186 - val_loss: 0.2383 - val_acc: 0.8968\n",
      "Epoch 1295/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1940 - acc: 0.9190 - val_loss: 0.2370 - val_acc: 0.8952\n",
      "Epoch 1296/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1940 - acc: 0.9189 - val_loss: 0.2377 - val_acc: 0.8957\n",
      "Epoch 1297/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9181 - val_loss: 0.2389 - val_acc: 0.8977\n",
      "Epoch 1298/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1945 - acc: 0.9187 - val_loss: 0.2355 - val_acc: 0.8961\n",
      "Epoch 1299/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9187 - val_loss: 0.2393 - val_acc: 0.8968\n",
      "Epoch 1300/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9181 - val_loss: 0.2386 - val_acc: 0.8944\n",
      "Epoch 1301/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9183 - val_loss: 0.2382 - val_acc: 0.8951\n",
      "Epoch 1302/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9193 - val_loss: 0.2364 - val_acc: 0.8976\n",
      "Epoch 1303/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1986 - acc: 0.9163 - val_loss: 0.2404 - val_acc: 0.8970\n",
      "Epoch 1304/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9178 - val_loss: 0.2400 - val_acc: 0.8954\n",
      "Epoch 1305/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1956 - acc: 0.9177 - val_loss: 0.2379 - val_acc: 0.8976\n",
      "Epoch 1306/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1951 - acc: 0.9179 - val_loss: 0.2372 - val_acc: 0.8977\n",
      "Epoch 1307/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9180 - val_loss: 0.2392 - val_acc: 0.8963\n",
      "Epoch 1308/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9183 - val_loss: 0.2366 - val_acc: 0.8967\n",
      "Epoch 1309/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1958 - acc: 0.9172 - val_loss: 0.2378 - val_acc: 0.8960\n",
      "Epoch 1310/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1950 - acc: 0.9189 - val_loss: 0.2370 - val_acc: 0.8954\n",
      "Epoch 1311/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1964 - acc: 0.9167 - val_loss: 0.2386 - val_acc: 0.8958\n",
      "Epoch 1312/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1940 - acc: 0.9190 - val_loss: 0.2365 - val_acc: 0.8968\n",
      "Epoch 1313/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1938 - acc: 0.9189 - val_loss: 0.2366 - val_acc: 0.8971\n",
      "Epoch 1314/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1942 - acc: 0.9196 - val_loss: 0.2361 - val_acc: 0.8964\n",
      "Epoch 1315/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1943 - acc: 0.9186 - val_loss: 0.2355 - val_acc: 0.8971\n",
      "Epoch 1316/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1944 - acc: 0.9190 - val_loss: 0.2369 - val_acc: 0.8974\n",
      "Epoch 1317/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9181 - val_loss: 0.2406 - val_acc: 0.8944\n",
      "Epoch 1318/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1964 - acc: 0.9170 - val_loss: 0.2411 - val_acc: 0.8922\n",
      "Epoch 1319/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1958 - acc: 0.9168 - val_loss: 0.2382 - val_acc: 0.8958\n",
      "Epoch 1320/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9175 - val_loss: 0.2361 - val_acc: 0.8976\n",
      "Epoch 1321/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9177 - val_loss: 0.2396 - val_acc: 0.8944\n",
      "Epoch 1322/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9186 - val_loss: 0.2372 - val_acc: 0.8966\n",
      "Epoch 1323/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1940 - acc: 0.9189 - val_loss: 0.2376 - val_acc: 0.8958\n",
      "Epoch 1324/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1940 - acc: 0.9186 - val_loss: 0.2371 - val_acc: 0.8960\n",
      "Epoch 1325/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9186 - val_loss: 0.2372 - val_acc: 0.8971\n",
      "Epoch 1326/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1953 - acc: 0.9182 - val_loss: 0.2363 - val_acc: 0.8976\n",
      "Epoch 1327/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1945 - acc: 0.9188 - val_loss: 0.2380 - val_acc: 0.8970\n",
      "Epoch 1328/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9176 - val_loss: 0.2387 - val_acc: 0.8951\n",
      "Epoch 1329/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1954 - acc: 0.9177 - val_loss: 0.2409 - val_acc: 0.8931\n",
      "Epoch 1330/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1958 - acc: 0.9177 - val_loss: 0.2374 - val_acc: 0.8958\n",
      "Epoch 1331/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1941 - acc: 0.9182 - val_loss: 0.2369 - val_acc: 0.8976\n",
      "Epoch 1332/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1941 - acc: 0.9186 - val_loss: 0.2370 - val_acc: 0.8964\n",
      "Epoch 1333/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1941 - acc: 0.9189 - val_loss: 0.2378 - val_acc: 0.8950\n",
      "Epoch 1334/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1968 - acc: 0.9170 - val_loss: 0.2397 - val_acc: 0.8945\n",
      "Epoch 1335/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9183 - val_loss: 0.2369 - val_acc: 0.8976\n",
      "Epoch 1336/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9185 - val_loss: 0.2359 - val_acc: 0.8960\n",
      "Epoch 1337/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1934 - acc: 0.9189 - val_loss: 0.2365 - val_acc: 0.8968\n",
      "Epoch 1338/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9181 - val_loss: 0.2372 - val_acc: 0.8952\n",
      "Epoch 1339/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9184 - val_loss: 0.2359 - val_acc: 0.8971\n",
      "Epoch 1340/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9181 - val_loss: 0.2364 - val_acc: 0.8966\n",
      "Epoch 1341/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1937 - acc: 0.9194 - val_loss: 0.2378 - val_acc: 0.8970\n",
      "Epoch 1342/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9181 - val_loss: 0.2376 - val_acc: 0.8968\n",
      "Epoch 1343/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9178 - val_loss: 0.2371 - val_acc: 0.8958\n",
      "Epoch 1344/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9181 - val_loss: 0.2380 - val_acc: 0.8958\n",
      "Epoch 1345/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9179 - val_loss: 0.2373 - val_acc: 0.8973\n",
      "Epoch 1346/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9190 - val_loss: 0.2355 - val_acc: 0.8980\n",
      "Epoch 1347/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9186 - val_loss: 0.2357 - val_acc: 0.8992\n",
      "Epoch 1348/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9173 - val_loss: 0.2368 - val_acc: 0.8971\n",
      "Epoch 1349/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9188 - val_loss: 0.2390 - val_acc: 0.8961\n",
      "Epoch 1350/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1942 - acc: 0.9186 - val_loss: 0.2374 - val_acc: 0.8971\n",
      "Epoch 1351/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1942 - acc: 0.9192 - val_loss: 0.2368 - val_acc: 0.8960\n",
      "Epoch 1352/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9183 - val_loss: 0.2373 - val_acc: 0.8970\n",
      "Epoch 1353/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9183 - val_loss: 0.2374 - val_acc: 0.8984\n",
      "Epoch 1354/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1941 - acc: 0.9190 - val_loss: 0.2373 - val_acc: 0.8983\n",
      "Epoch 1355/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1941 - acc: 0.9190 - val_loss: 0.2377 - val_acc: 0.8968\n",
      "Epoch 1356/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9182 - val_loss: 0.2353 - val_acc: 0.8974\n",
      "Epoch 1357/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9184 - val_loss: 0.2374 - val_acc: 0.8974\n",
      "Epoch 1358/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9185 - val_loss: 0.2379 - val_acc: 0.8971\n",
      "Epoch 1359/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9186 - val_loss: 0.2393 - val_acc: 0.8970\n",
      "Epoch 1360/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9188 - val_loss: 0.2378 - val_acc: 0.8960\n",
      "Epoch 1361/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1940 - acc: 0.9193 - val_loss: 0.2386 - val_acc: 0.8974\n",
      "Epoch 1362/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9181 - val_loss: 0.2376 - val_acc: 0.8966\n",
      "Epoch 1363/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1956 - acc: 0.9183 - val_loss: 0.2368 - val_acc: 0.8968\n",
      "Epoch 1364/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9190 - val_loss: 0.2352 - val_acc: 0.8986\n",
      "Epoch 1365/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9187 - val_loss: 0.2374 - val_acc: 0.8974\n",
      "Epoch 1366/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9174 - val_loss: 0.2369 - val_acc: 0.8955\n",
      "Epoch 1367/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1962 - acc: 0.9176 - val_loss: 0.2368 - val_acc: 0.8966\n",
      "Epoch 1368/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9187 - val_loss: 0.2364 - val_acc: 0.8952\n",
      "Epoch 1369/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9184 - val_loss: 0.2353 - val_acc: 0.8970\n",
      "Epoch 1370/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1935 - acc: 0.9190 - val_loss: 0.2357 - val_acc: 0.8966\n",
      "Epoch 1371/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1957 - acc: 0.9194 - val_loss: 0.2362 - val_acc: 0.8963\n",
      "Epoch 1372/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9189 - val_loss: 0.2357 - val_acc: 0.8966\n",
      "Epoch 1373/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9180 - val_loss: 0.2356 - val_acc: 0.8971\n",
      "Epoch 1374/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1939 - acc: 0.9190 - val_loss: 0.2362 - val_acc: 0.8957\n",
      "Epoch 1375/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1936 - acc: 0.9191 - val_loss: 0.2377 - val_acc: 0.8935\n",
      "Epoch 1376/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9183 - val_loss: 0.2365 - val_acc: 0.8955\n",
      "Epoch 1377/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1936 - acc: 0.9194 - val_loss: 0.2369 - val_acc: 0.8976\n",
      "Epoch 1378/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1954 - acc: 0.9185 - val_loss: 0.2396 - val_acc: 0.8964\n",
      "Epoch 1379/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9181 - val_loss: 0.2385 - val_acc: 0.8954\n",
      "Epoch 1380/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9182 - val_loss: 0.2406 - val_acc: 0.8922\n",
      "Epoch 1381/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1960 - acc: 0.9179 - val_loss: 0.2400 - val_acc: 0.8941\n",
      "Epoch 1382/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1960 - acc: 0.9180 - val_loss: 0.2374 - val_acc: 0.8954\n",
      "Epoch 1383/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9193 - val_loss: 0.2389 - val_acc: 0.8954\n",
      "Epoch 1384/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1939 - acc: 0.9182 - val_loss: 0.2378 - val_acc: 0.8970\n",
      "Epoch 1385/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1939 - acc: 0.9182 - val_loss: 0.2369 - val_acc: 0.8966\n",
      "Epoch 1386/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1936 - acc: 0.9191 - val_loss: 0.2364 - val_acc: 0.8974\n",
      "Epoch 1387/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1928 - acc: 0.9196 - val_loss: 0.2367 - val_acc: 0.8957\n",
      "Epoch 1388/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9182 - val_loss: 0.2371 - val_acc: 0.8980\n",
      "Epoch 1389/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9186 - val_loss: 0.2374 - val_acc: 0.8966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1390/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1945 - acc: 0.9191 - val_loss: 0.2379 - val_acc: 0.8966\n",
      "Epoch 1391/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1942 - acc: 0.9181 - val_loss: 0.2384 - val_acc: 0.8979\n",
      "Epoch 1392/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9183 - val_loss: 0.2362 - val_acc: 0.8968\n",
      "Epoch 1393/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9181 - val_loss: 0.2371 - val_acc: 0.8961\n",
      "Epoch 1394/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9181 - val_loss: 0.2423 - val_acc: 0.8921\n",
      "Epoch 1395/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9168 - val_loss: 0.2405 - val_acc: 0.8952\n",
      "Epoch 1396/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9184 - val_loss: 0.2370 - val_acc: 0.8974\n",
      "Epoch 1397/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1941 - acc: 0.9184 - val_loss: 0.2376 - val_acc: 0.8964\n",
      "Epoch 1398/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1940 - acc: 0.9188 - val_loss: 0.2375 - val_acc: 0.8950\n",
      "Epoch 1399/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9180 - val_loss: 0.2367 - val_acc: 0.8983\n",
      "Epoch 1400/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9183 - val_loss: 0.2369 - val_acc: 0.8970\n",
      "Epoch 1401/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1941 - acc: 0.9190 - val_loss: 0.2379 - val_acc: 0.8963\n",
      "Epoch 1402/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9184 - val_loss: 0.2377 - val_acc: 0.8990\n",
      "Epoch 1403/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1932 - acc: 0.9188 - val_loss: 0.2392 - val_acc: 0.8967\n",
      "Epoch 1404/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1939 - acc: 0.9187 - val_loss: 0.2387 - val_acc: 0.8948\n",
      "Epoch 1405/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9188 - val_loss: 0.2377 - val_acc: 0.8967\n",
      "Epoch 1406/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9181 - val_loss: 0.2371 - val_acc: 0.8944\n",
      "Epoch 1407/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1941 - acc: 0.9181 - val_loss: 0.2388 - val_acc: 0.8970\n",
      "Epoch 1408/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1939 - acc: 0.9193 - val_loss: 0.2414 - val_acc: 0.8977\n",
      "Epoch 1409/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1939 - acc: 0.9193 - val_loss: 0.2367 - val_acc: 0.8973\n",
      "Epoch 1410/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1945 - acc: 0.9191 - val_loss: 0.2372 - val_acc: 0.8952\n",
      "Epoch 1411/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9187 - val_loss: 0.2377 - val_acc: 0.8980\n",
      "Epoch 1412/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1935 - acc: 0.9194 - val_loss: 0.2369 - val_acc: 0.8987\n",
      "Epoch 1413/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9195 - val_loss: 0.2371 - val_acc: 0.8957\n",
      "Epoch 1414/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1954 - acc: 0.9179 - val_loss: 0.2370 - val_acc: 0.8980\n",
      "Epoch 1415/1500\n",
      "20704/20704 [==============================] - 1s 24us/step - loss: 0.1955 - acc: 0.9184 - val_loss: 0.2380 - val_acc: 0.8983\n",
      "Epoch 1416/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1943 - acc: 0.9186 - val_loss: 0.2371 - val_acc: 0.8973\n",
      "Epoch 1417/1500\n",
      "20704/20704 [==============================] - 1s 25us/step - loss: 0.1943 - acc: 0.9188 - val_loss: 0.2363 - val_acc: 0.8979\n",
      "Epoch 1418/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9187 - val_loss: 0.2392 - val_acc: 0.8964\n",
      "Epoch 1419/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9179 - val_loss: 0.2365 - val_acc: 0.8981\n",
      "Epoch 1420/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1936 - acc: 0.9190 - val_loss: 0.2366 - val_acc: 0.8992\n",
      "Epoch 1421/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1938 - acc: 0.9191 - val_loss: 0.2360 - val_acc: 0.8968\n",
      "Epoch 1422/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1936 - acc: 0.9187 - val_loss: 0.2390 - val_acc: 0.8964\n",
      "Epoch 1423/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1943 - acc: 0.9179 - val_loss: 0.2383 - val_acc: 0.8983\n",
      "Epoch 1424/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9181 - val_loss: 0.2408 - val_acc: 0.8963\n",
      "Epoch 1425/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9178 - val_loss: 0.2368 - val_acc: 0.8979\n",
      "Epoch 1426/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1959 - acc: 0.9186 - val_loss: 0.2360 - val_acc: 0.8973\n",
      "Epoch 1427/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1949 - acc: 0.9184 - val_loss: 0.2393 - val_acc: 0.8950\n",
      "Epoch 1428/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1951 - acc: 0.9190 - val_loss: 0.2378 - val_acc: 0.8961\n",
      "Epoch 1429/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9182 - val_loss: 0.2387 - val_acc: 0.8947\n",
      "Epoch 1430/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9183 - val_loss: 0.2383 - val_acc: 0.8951\n",
      "Epoch 1431/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9186 - val_loss: 0.2376 - val_acc: 0.8968\n",
      "Epoch 1432/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9188 - val_loss: 0.2403 - val_acc: 0.8963\n",
      "Epoch 1433/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.9189 - val_loss: 0.2396 - val_acc: 0.8980\n",
      "Epoch 1434/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9189 - val_loss: 0.2366 - val_acc: 0.8979\n",
      "Epoch 1435/1500\n",
      "20704/20704 [==============================] - 0s 24us/step - loss: 0.1945 - acc: 0.9180 - val_loss: 0.2404 - val_acc: 0.8952\n",
      "Epoch 1436/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9182 - val_loss: 0.2381 - val_acc: 0.8963\n",
      "Epoch 1437/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9179 - val_loss: 0.2353 - val_acc: 0.8977\n",
      "Epoch 1438/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1954 - acc: 0.9175 - val_loss: 0.2437 - val_acc: 0.8929\n",
      "Epoch 1439/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1960 - acc: 0.9165 - val_loss: 0.2408 - val_acc: 0.8945\n",
      "Epoch 1440/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9182 - val_loss: 0.2420 - val_acc: 0.8935\n",
      "Epoch 1441/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1943 - acc: 0.9185 - val_loss: 0.2398 - val_acc: 0.8955\n",
      "Epoch 1442/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1937 - acc: 0.9192 - val_loss: 0.2370 - val_acc: 0.8966\n",
      "Epoch 1443/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1942 - acc: 0.9179 - val_loss: 0.2371 - val_acc: 0.8952\n",
      "Epoch 1444/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1948 - acc: 0.9180 - val_loss: 0.2362 - val_acc: 0.8968\n",
      "Epoch 1445/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1947 - acc: 0.9186 - val_loss: 0.2353 - val_acc: 0.8983\n",
      "Epoch 1446/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9181 - val_loss: 0.2352 - val_acc: 0.8986\n",
      "Epoch 1447/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1940 - acc: 0.9179 - val_loss: 0.2362 - val_acc: 0.8966\n",
      "Epoch 1448/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9189 - val_loss: 0.2358 - val_acc: 0.8966\n",
      "Epoch 1449/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9188 - val_loss: 0.2389 - val_acc: 0.8957\n",
      "Epoch 1450/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9186 - val_loss: 0.2385 - val_acc: 0.8964\n",
      "Epoch 1451/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9183 - val_loss: 0.2370 - val_acc: 0.8964\n",
      "Epoch 1452/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1938 - acc: 0.9195 - val_loss: 0.2359 - val_acc: 0.8977\n",
      "Epoch 1453/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1942 - acc: 0.9189 - val_loss: 0.2388 - val_acc: 0.8954\n",
      "Epoch 1454/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1942 - acc: 0.9185 - val_loss: 0.2385 - val_acc: 0.8976\n",
      "Epoch 1455/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9189 - val_loss: 0.2369 - val_acc: 0.8971\n",
      "Epoch 1456/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9185 - val_loss: 0.2385 - val_acc: 0.8957\n",
      "Epoch 1457/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1955 - acc: 0.9177 - val_loss: 0.2375 - val_acc: 0.8961\n",
      "Epoch 1458/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9174 - val_loss: 0.2375 - val_acc: 0.8968\n",
      "Epoch 1459/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1938 - acc: 0.9181 - val_loss: 0.2350 - val_acc: 0.8966\n",
      "Epoch 1460/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1942 - acc: 0.9198 - val_loss: 0.2387 - val_acc: 0.8980\n",
      "Epoch 1461/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1930 - acc: 0.9194 - val_loss: 0.2373 - val_acc: 0.8967\n",
      "Epoch 1462/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1934 - acc: 0.9190 - val_loss: 0.2358 - val_acc: 0.8977\n",
      "Epoch 1463/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1955 - acc: 0.9186 - val_loss: 0.2368 - val_acc: 0.8974\n",
      "Epoch 1464/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1938 - acc: 0.9184 - val_loss: 0.2365 - val_acc: 0.8980\n",
      "Epoch 1465/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9189 - val_loss: 0.2382 - val_acc: 0.8963\n",
      "Epoch 1466/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9185 - val_loss: 0.2375 - val_acc: 0.8957\n",
      "Epoch 1467/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1950 - acc: 0.9178 - val_loss: 0.2378 - val_acc: 0.8942\n",
      "Epoch 1468/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1942 - acc: 0.9188 - val_loss: 0.2395 - val_acc: 0.8960\n",
      "Epoch 1469/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1950 - acc: 0.9182 - val_loss: 0.2365 - val_acc: 0.8970\n",
      "Epoch 1470/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1940 - acc: 0.9191 - val_loss: 0.2374 - val_acc: 0.8964\n",
      "Epoch 1471/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.9181 - val_loss: 0.2386 - val_acc: 0.8955\n",
      "Epoch 1472/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1952 - acc: 0.9173 - val_loss: 0.2390 - val_acc: 0.8950\n",
      "Epoch 1473/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9181 - val_loss: 0.2387 - val_acc: 0.8948\n",
      "Epoch 1474/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1953 - acc: 0.9183 - val_loss: 0.2384 - val_acc: 0.8976\n",
      "Epoch 1475/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9186 - val_loss: 0.2369 - val_acc: 0.8952\n",
      "Epoch 1476/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1937 - acc: 0.9191 - val_loss: 0.2377 - val_acc: 0.8968\n",
      "Epoch 1477/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1946 - acc: 0.9183 - val_loss: 0.2374 - val_acc: 0.8966\n",
      "Epoch 1478/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1953 - acc: 0.9181 - val_loss: 0.2382 - val_acc: 0.8961\n",
      "Epoch 1479/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9190 - val_loss: 0.2353 - val_acc: 0.8967\n",
      "Epoch 1480/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9177 - val_loss: 0.2528 - val_acc: 0.8886\n",
      "Epoch 1481/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.2001 - acc: 0.9152 - val_loss: 0.2482 - val_acc: 0.8871\n",
      "Epoch 1482/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1986 - acc: 0.9165 - val_loss: 0.2394 - val_acc: 0.8958\n",
      "Epoch 1483/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9183 - val_loss: 0.2387 - val_acc: 0.8963\n",
      "Epoch 1484/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1944 - acc: 0.9181 - val_loss: 0.2363 - val_acc: 0.8973\n",
      "Epoch 1485/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9177 - val_loss: 0.2382 - val_acc: 0.8967\n",
      "Epoch 1486/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1948 - acc: 0.9186 - val_loss: 0.2371 - val_acc: 0.8973\n",
      "Epoch 1487/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1940 - acc: 0.9187 - val_loss: 0.2364 - val_acc: 0.8970\n",
      "Epoch 1488/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1941 - acc: 0.9188 - val_loss: 0.2371 - val_acc: 0.8973\n",
      "Epoch 1489/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1956 - acc: 0.9191 - val_loss: 0.2376 - val_acc: 0.8976\n",
      "Epoch 1490/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1943 - acc: 0.9185 - val_loss: 0.2378 - val_acc: 0.8967\n",
      "Epoch 1491/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9187 - val_loss: 0.2377 - val_acc: 0.8961\n",
      "Epoch 1492/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1945 - acc: 0.9183 - val_loss: 0.2380 - val_acc: 0.8955\n",
      "Epoch 1493/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1946 - acc: 0.9188 - val_loss: 0.2386 - val_acc: 0.8954\n",
      "Epoch 1494/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1955 - acc: 0.9175 - val_loss: 0.2386 - val_acc: 0.8957\n",
      "Epoch 1495/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1955 - acc: 0.9173 - val_loss: 0.2409 - val_acc: 0.8973\n",
      "Epoch 1496/1500\n",
      "20704/20704 [==============================] - 0s 22us/step - loss: 0.1941 - acc: 0.9181 - val_loss: 0.2380 - val_acc: 0.8961\n",
      "Epoch 1497/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1945 - acc: 0.9184 - val_loss: 0.2393 - val_acc: 0.8950\n",
      "Epoch 1498/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1947 - acc: 0.9184 - val_loss: 0.2383 - val_acc: 0.8945\n",
      "Epoch 1499/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1952 - acc: 0.9186 - val_loss: 0.2346 - val_acc: 0.8971\n",
      "Epoch 1500/1500\n",
      "20704/20704 [==============================] - 0s 23us/step - loss: 0.1949 - acc: 0.9184 - val_loss: 0.2386 - val_acc: 0.8954\n"
     ]
    }
   ],
   "source": [
    "h = model_TPS.fit(train_X_TPS[:], train_Y_TPS[:], \n",
    "          epochs=1500, \n",
    "          batch_size=32, \n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          #validation_split=0.1)\n",
    "          validation_data=([test_X_TPS, test_Y_TPS]))\n",
    "\n",
    "history_TPS = {k : history_TPS[k] + h.history[k] for k in hist_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcddabb9cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history_TPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('URZ_model_TPS.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6902/6902 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23861501366115936, 0.895392639900905]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_TPS.evaluate(test_X_TPS, test_Y_TPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2161  171]\n",
      " [ 547 4023]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = numpy.reshape(numpy.argmax(model_TPS.predict(test_X_TPS), axis=1), (test_X_TPS.shape[0],1))\n",
    "\n",
    "# calculate confusion matrix\n",
    "conf_mat = confusion_matrix(test_Y_TPS_, Y_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11610608020698578"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(547+171)/(2161+4023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just for curiosity -  Manual associations confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1822  180]\n",
      " [ 983 3021]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred_man = numpy.argmax(model_TPS.predict(manual_X), axis=1)\n",
    "\n",
    "# calculate confusion matrix\n",
    "conf_mat = confusion_matrix(manual_Y_TPS_, Y_pred_man)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network T vs regP \n",
    "\n",
    "* we need a new dataset for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for T vs regP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude regS\n",
    "TP_train = TPS_train[TPS_train['CLASS_PHASE'] != 'regS']\n",
    "TP_test  = TPS_test [TPS_test ['CLASS_PHASE'] != 'regS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13834, 15) (13834, 2) (4570, 15) (4570, 2)\n"
     ]
    }
   ],
   "source": [
    "train_X_TP = TP_train[x_indices].values.astype(float)\n",
    "train_Y_TP = TP_train[y_indices]\n",
    "\n",
    "test_X_TP = TP_test[x_indices].values.astype(float)\n",
    "test_Y_TP = TP_test[y_indices]\n",
    "\n",
    "#regS = 0, T/regP = 1\n",
    "train_Y_TP_ = numpy.array(numpy.where(train_Y_TP['CLASS_PHASE'] == 'regP', 0, 1), dtype=float)\n",
    "test_Y_TP_ = numpy.array(numpy.where(test_Y_TP['CLASS_PHASE'] == 'regP', 0, 1), dtype=float)\n",
    "\n",
    "#convert to categorical\n",
    "train_Y_TP = keras.utils.to_categorical(train_Y_TP_)\n",
    "test_Y_TP = keras.utils.to_categorical(test_Y_TP_)\n",
    "\n",
    "print(train_X_TP.shape, train_Y_TP.shape, test_X_TP.shape, test_Y_TP.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_TP = {k : [] for k in hist_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = len(x_indices)\n",
    "numpy.random.seed(11)\n",
    "\n",
    "# create model\n",
    "model_TP = Sequential()\n",
    "model_TP.add(Dense(n_input, input_dim=n_input, activation='sigmoid'))\n",
    "model_TP.add(Dense(6, activation='sigmoid'))\n",
    "model_TP.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model_TP.compile(\n",
    "    loss = 'binary_crossentropy', \n",
    "    optimizer = 'adam',  # adam, sgd\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13834 samples, validate on 4570 samples\n",
      "Epoch 1/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.6833 - acc: 0.5641 - val_loss: 0.6627 - val_acc: 0.5985\n",
      "Epoch 2/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.6475 - acc: 0.6080 - val_loss: 0.6276 - val_acc: 0.6094\n",
      "Epoch 3/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.6154 - acc: 0.6514 - val_loss: 0.5984 - val_acc: 0.7055\n",
      "Epoch 4/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.5866 - acc: 0.7056 - val_loss: 0.5669 - val_acc: 0.7373\n",
      "Epoch 5/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.5563 - acc: 0.7323 - val_loss: 0.5350 - val_acc: 0.7503\n",
      "Epoch 6/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.5274 - acc: 0.7521 - val_loss: 0.5133 - val_acc: 0.7624\n",
      "Epoch 7/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.5131 - acc: 0.7544 - val_loss: 0.5045 - val_acc: 0.7648\n",
      "Epoch 8/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.5053 - acc: 0.7602 - val_loss: 0.4983 - val_acc: 0.7659\n",
      "Epoch 9/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.5009 - acc: 0.7625 - val_loss: 0.4944 - val_acc: 0.7700\n",
      "Epoch 10/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4961 - acc: 0.7666 - val_loss: 0.4928 - val_acc: 0.7708\n",
      "Epoch 11/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4910 - acc: 0.7741 - val_loss: 0.4888 - val_acc: 0.7729\n",
      "Epoch 12/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4889 - acc: 0.7728 - val_loss: 0.4903 - val_acc: 0.7742\n",
      "Epoch 13/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4850 - acc: 0.7752 - val_loss: 0.4871 - val_acc: 0.7744\n",
      "Epoch 14/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4824 - acc: 0.7761 - val_loss: 0.4832 - val_acc: 0.7800\n",
      "Epoch 15/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4790 - acc: 0.7767 - val_loss: 0.4808 - val_acc: 0.7801\n",
      "Epoch 16/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4761 - acc: 0.7792 - val_loss: 0.4797 - val_acc: 0.7798\n",
      "Epoch 17/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4760 - acc: 0.7779 - val_loss: 0.4786 - val_acc: 0.7792\n",
      "Epoch 18/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4727 - acc: 0.7811 - val_loss: 0.4835 - val_acc: 0.7786\n",
      "Epoch 19/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4717 - acc: 0.7821 - val_loss: 0.4813 - val_acc: 0.7840\n",
      "Epoch 20/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4696 - acc: 0.7846 - val_loss: 0.4836 - val_acc: 0.7763\n",
      "Epoch 21/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4681 - acc: 0.7837 - val_loss: 0.4733 - val_acc: 0.7872\n",
      "Epoch 22/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4671 - acc: 0.7855 - val_loss: 0.4771 - val_acc: 0.7791\n",
      "Epoch 23/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4657 - acc: 0.7867 - val_loss: 0.4757 - val_acc: 0.7823\n",
      "Epoch 24/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4658 - acc: 0.7853 - val_loss: 0.4736 - val_acc: 0.7793\n",
      "Epoch 25/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4638 - acc: 0.7878 - val_loss: 0.4735 - val_acc: 0.7804\n",
      "Epoch 26/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4639 - acc: 0.7854 - val_loss: 0.4703 - val_acc: 0.7837\n",
      "Epoch 27/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4643 - acc: 0.7869 - val_loss: 0.4879 - val_acc: 0.7704\n",
      "Epoch 28/2000\n",
      "13834/13834 [==============================] - 0s 29us/step - loss: 0.4624 - acc: 0.7871 - val_loss: 0.4700 - val_acc: 0.7908\n",
      "Epoch 29/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4623 - acc: 0.7872 - val_loss: 0.4726 - val_acc: 0.7900\n",
      "Epoch 30/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4617 - acc: 0.7886 - val_loss: 0.4698 - val_acc: 0.7868\n",
      "Epoch 31/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4602 - acc: 0.7879 - val_loss: 0.4688 - val_acc: 0.7900\n",
      "Epoch 32/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4607 - acc: 0.7886 - val_loss: 0.4682 - val_acc: 0.7910\n",
      "Epoch 33/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4598 - acc: 0.7869 - val_loss: 0.4679 - val_acc: 0.7895\n",
      "Epoch 34/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4596 - acc: 0.7905 - val_loss: 0.4673 - val_acc: 0.7914\n",
      "Epoch 35/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4581 - acc: 0.7899 - val_loss: 0.4684 - val_acc: 0.7837\n",
      "Epoch 36/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4576 - acc: 0.7911 - val_loss: 0.4720 - val_acc: 0.7870\n",
      "Epoch 37/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4579 - acc: 0.7885 - val_loss: 0.4653 - val_acc: 0.7934\n",
      "Epoch 38/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4580 - acc: 0.7901 - val_loss: 0.4645 - val_acc: 0.7917\n",
      "Epoch 39/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4579 - acc: 0.7905 - val_loss: 0.4666 - val_acc: 0.7876\n",
      "Epoch 40/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4564 - acc: 0.7919 - val_loss: 0.4679 - val_acc: 0.7868\n",
      "Epoch 41/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4565 - acc: 0.7913 - val_loss: 0.4643 - val_acc: 0.7906\n",
      "Epoch 42/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4569 - acc: 0.7914 - val_loss: 0.4682 - val_acc: 0.7860\n",
      "Epoch 43/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4561 - acc: 0.7895 - val_loss: 0.4633 - val_acc: 0.7941\n",
      "Epoch 44/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4555 - acc: 0.7916 - val_loss: 0.4650 - val_acc: 0.7920\n",
      "Epoch 45/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4569 - acc: 0.7919 - val_loss: 0.4637 - val_acc: 0.7931\n",
      "Epoch 46/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4561 - acc: 0.7898 - val_loss: 0.4650 - val_acc: 0.7892\n",
      "Epoch 47/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4554 - acc: 0.7906 - val_loss: 0.4633 - val_acc: 0.7896\n",
      "Epoch 48/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4561 - acc: 0.7925 - val_loss: 0.4717 - val_acc: 0.7828\n",
      "Epoch 49/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4550 - acc: 0.7928 - val_loss: 0.4653 - val_acc: 0.7886\n",
      "Epoch 50/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4534 - acc: 0.7912 - val_loss: 0.4645 - val_acc: 0.7864\n",
      "Epoch 51/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4548 - acc: 0.7922 - val_loss: 0.4693 - val_acc: 0.7832\n",
      "Epoch 52/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4545 - acc: 0.7941 - val_loss: 0.4642 - val_acc: 0.7867\n",
      "Epoch 53/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4533 - acc: 0.7941 - val_loss: 0.4623 - val_acc: 0.7903\n",
      "Epoch 54/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4529 - acc: 0.7931 - val_loss: 0.4665 - val_acc: 0.7848\n",
      "Epoch 55/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4522 - acc: 0.7934 - val_loss: 0.4722 - val_acc: 0.7851\n",
      "Epoch 56/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4527 - acc: 0.7945 - val_loss: 0.4615 - val_acc: 0.7895\n",
      "Epoch 57/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4523 - acc: 0.7949 - val_loss: 0.4630 - val_acc: 0.7875\n",
      "Epoch 58/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4517 - acc: 0.7939 - val_loss: 0.4678 - val_acc: 0.7816\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4518 - acc: 0.7930 - val_loss: 0.4683 - val_acc: 0.7864\n",
      "Epoch 60/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4516 - acc: 0.7934 - val_loss: 0.4611 - val_acc: 0.7917\n",
      "Epoch 61/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4518 - acc: 0.7934 - val_loss: 0.4587 - val_acc: 0.7907\n",
      "Epoch 62/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4526 - acc: 0.7930 - val_loss: 0.4637 - val_acc: 0.7879\n",
      "Epoch 63/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4519 - acc: 0.7930 - val_loss: 0.4614 - val_acc: 0.7927\n",
      "Epoch 64/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4512 - acc: 0.7944 - val_loss: 0.4601 - val_acc: 0.7896\n",
      "Epoch 65/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4514 - acc: 0.7957 - val_loss: 0.4612 - val_acc: 0.7915\n",
      "Epoch 66/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4507 - acc: 0.7946 - val_loss: 0.4612 - val_acc: 0.7902\n",
      "Epoch 67/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4500 - acc: 0.7937 - val_loss: 0.4591 - val_acc: 0.7930\n",
      "Epoch 68/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4503 - acc: 0.7949 - val_loss: 0.4671 - val_acc: 0.7868\n",
      "Epoch 69/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4501 - acc: 0.7954 - val_loss: 0.4592 - val_acc: 0.7909\n",
      "Epoch 70/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4500 - acc: 0.7934 - val_loss: 0.4616 - val_acc: 0.7869\n",
      "Epoch 71/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4512 - acc: 0.7946 - val_loss: 0.4593 - val_acc: 0.7921\n",
      "Epoch 72/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4516 - acc: 0.7929 - val_loss: 0.4715 - val_acc: 0.7884\n",
      "Epoch 73/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4496 - acc: 0.7948 - val_loss: 0.4676 - val_acc: 0.7893\n",
      "Epoch 74/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4507 - acc: 0.7953 - val_loss: 0.4631 - val_acc: 0.7907\n",
      "Epoch 75/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4513 - acc: 0.7958 - val_loss: 0.4585 - val_acc: 0.7918\n",
      "Epoch 76/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4503 - acc: 0.7941 - val_loss: 0.4573 - val_acc: 0.7920\n",
      "Epoch 77/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4487 - acc: 0.7953 - val_loss: 0.4602 - val_acc: 0.7927\n",
      "Epoch 78/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4489 - acc: 0.7959 - val_loss: 0.4579 - val_acc: 0.7929\n",
      "Epoch 79/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4488 - acc: 0.7955 - val_loss: 0.4584 - val_acc: 0.7906\n",
      "Epoch 80/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4476 - acc: 0.7977 - val_loss: 0.4636 - val_acc: 0.7918\n",
      "Epoch 81/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4494 - acc: 0.7942 - val_loss: 0.4578 - val_acc: 0.7935\n",
      "Epoch 82/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4490 - acc: 0.7957 - val_loss: 0.4574 - val_acc: 0.7918\n",
      "Epoch 83/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4481 - acc: 0.7961 - val_loss: 0.4609 - val_acc: 0.7895\n",
      "Epoch 84/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4489 - acc: 0.7976 - val_loss: 0.4590 - val_acc: 0.7905\n",
      "Epoch 85/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4480 - acc: 0.7982 - val_loss: 0.4581 - val_acc: 0.7933\n",
      "Epoch 86/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4476 - acc: 0.7983 - val_loss: 0.4558 - val_acc: 0.7905\n",
      "Epoch 87/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4476 - acc: 0.7983 - val_loss: 0.4606 - val_acc: 0.7952\n",
      "Epoch 88/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4475 - acc: 0.7977 - val_loss: 0.4590 - val_acc: 0.7933\n",
      "Epoch 89/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4474 - acc: 0.7966 - val_loss: 0.4563 - val_acc: 0.7939\n",
      "Epoch 90/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4479 - acc: 0.7963 - val_loss: 0.4585 - val_acc: 0.7916\n",
      "Epoch 91/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4466 - acc: 0.7985 - val_loss: 0.4664 - val_acc: 0.7925\n",
      "Epoch 92/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4464 - acc: 0.7976 - val_loss: 0.4575 - val_acc: 0.7920\n",
      "Epoch 93/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4488 - acc: 0.7969 - val_loss: 0.4559 - val_acc: 0.7945\n",
      "Epoch 94/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4487 - acc: 0.7959 - val_loss: 0.4607 - val_acc: 0.7966\n",
      "Epoch 95/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4461 - acc: 0.7977 - val_loss: 0.4552 - val_acc: 0.7940\n",
      "Epoch 96/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4480 - acc: 0.7968 - val_loss: 0.4625 - val_acc: 0.7871\n",
      "Epoch 97/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4459 - acc: 0.7985 - val_loss: 0.4578 - val_acc: 0.7935\n",
      "Epoch 98/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4458 - acc: 0.7991 - val_loss: 0.4595 - val_acc: 0.7925\n",
      "Epoch 99/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4481 - acc: 0.7959 - val_loss: 0.4562 - val_acc: 0.7920\n",
      "Epoch 100/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4461 - acc: 0.7992 - val_loss: 0.4580 - val_acc: 0.7949\n",
      "Epoch 101/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4457 - acc: 0.7975 - val_loss: 0.4563 - val_acc: 0.7945\n",
      "Epoch 102/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4463 - acc: 0.7993 - val_loss: 0.4569 - val_acc: 0.7939\n",
      "Epoch 103/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4458 - acc: 0.7976 - val_loss: 0.4563 - val_acc: 0.7947\n",
      "Epoch 104/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4459 - acc: 0.7980 - val_loss: 0.4599 - val_acc: 0.7906\n",
      "Epoch 105/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4461 - acc: 0.7982 - val_loss: 0.4588 - val_acc: 0.7945\n",
      "Epoch 106/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4445 - acc: 0.7994 - val_loss: 0.4554 - val_acc: 0.7963\n",
      "Epoch 107/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4449 - acc: 0.7996 - val_loss: 0.4590 - val_acc: 0.7917\n",
      "Epoch 108/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4451 - acc: 0.7992 - val_loss: 0.4556 - val_acc: 0.7932\n",
      "Epoch 109/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4440 - acc: 0.7994 - val_loss: 0.4593 - val_acc: 0.7880\n",
      "Epoch 110/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4455 - acc: 0.7990 - val_loss: 0.4548 - val_acc: 0.7955\n",
      "Epoch 111/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4457 - acc: 0.7976 - val_loss: 0.4560 - val_acc: 0.7928\n",
      "Epoch 112/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4448 - acc: 0.8013 - val_loss: 0.4580 - val_acc: 0.7906\n",
      "Epoch 113/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4446 - acc: 0.7980 - val_loss: 0.4597 - val_acc: 0.7896\n",
      "Epoch 114/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4446 - acc: 0.8004 - val_loss: 0.4570 - val_acc: 0.7911\n",
      "Epoch 115/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4450 - acc: 0.8010 - val_loss: 0.4570 - val_acc: 0.7951\n",
      "Epoch 116/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4439 - acc: 0.8011 - val_loss: 0.4580 - val_acc: 0.7937\n",
      "Epoch 117/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4440 - acc: 0.7981 - val_loss: 0.4569 - val_acc: 0.7922\n",
      "Epoch 118/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4430 - acc: 0.8010 - val_loss: 0.4594 - val_acc: 0.7942\n",
      "Epoch 119/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4450 - acc: 0.7985 - val_loss: 0.4573 - val_acc: 0.7950\n",
      "Epoch 120/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4438 - acc: 0.8019 - val_loss: 0.4550 - val_acc: 0.7921\n",
      "Epoch 121/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4450 - acc: 0.8005 - val_loss: 0.4549 - val_acc: 0.7955\n",
      "Epoch 122/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4433 - acc: 0.8011 - val_loss: 0.4539 - val_acc: 0.7946\n",
      "Epoch 123/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4449 - acc: 0.7988 - val_loss: 0.4547 - val_acc: 0.7962\n",
      "Epoch 124/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4426 - acc: 0.7994 - val_loss: 0.4636 - val_acc: 0.7888\n",
      "Epoch 125/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4434 - acc: 0.8021 - val_loss: 0.4558 - val_acc: 0.7962\n",
      "Epoch 126/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4438 - acc: 0.8025 - val_loss: 0.4560 - val_acc: 0.7944\n",
      "Epoch 127/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4441 - acc: 0.8013 - val_loss: 0.4564 - val_acc: 0.7941\n",
      "Epoch 128/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4436 - acc: 0.7999 - val_loss: 0.4594 - val_acc: 0.7909\n",
      "Epoch 129/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4430 - acc: 0.8015 - val_loss: 0.4524 - val_acc: 0.7941\n",
      "Epoch 130/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4433 - acc: 0.8010 - val_loss: 0.4593 - val_acc: 0.7978\n",
      "Epoch 131/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4427 - acc: 0.7998 - val_loss: 0.4562 - val_acc: 0.7946\n",
      "Epoch 132/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4424 - acc: 0.8008 - val_loss: 0.4549 - val_acc: 0.7914\n",
      "Epoch 133/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4433 - acc: 0.8017 - val_loss: 0.4540 - val_acc: 0.7941\n",
      "Epoch 134/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4436 - acc: 0.8005 - val_loss: 0.4536 - val_acc: 0.7951\n",
      "Epoch 135/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4428 - acc: 0.7992 - val_loss: 0.4544 - val_acc: 0.7957\n",
      "Epoch 136/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4414 - acc: 0.8035 - val_loss: 0.4528 - val_acc: 0.7958\n",
      "Epoch 137/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4412 - acc: 0.8031 - val_loss: 0.4563 - val_acc: 0.7903\n",
      "Epoch 138/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4423 - acc: 0.8020 - val_loss: 0.4545 - val_acc: 0.7985\n",
      "Epoch 139/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4426 - acc: 0.8015 - val_loss: 0.4549 - val_acc: 0.7947\n",
      "Epoch 140/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4436 - acc: 0.7988 - val_loss: 0.4559 - val_acc: 0.7944\n",
      "Epoch 141/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4425 - acc: 0.8037 - val_loss: 0.4530 - val_acc: 0.7958\n",
      "Epoch 142/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4440 - acc: 0.7981 - val_loss: 0.4516 - val_acc: 0.7967\n",
      "Epoch 143/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4413 - acc: 0.8007 - val_loss: 0.4532 - val_acc: 0.7976\n",
      "Epoch 144/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4410 - acc: 0.8022 - val_loss: 0.4615 - val_acc: 0.7945\n",
      "Epoch 145/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4429 - acc: 0.8017 - val_loss: 0.4539 - val_acc: 0.7967\n",
      "Epoch 146/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4416 - acc: 0.8006 - val_loss: 0.4547 - val_acc: 0.7951\n",
      "Epoch 147/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4413 - acc: 0.8016 - val_loss: 0.4563 - val_acc: 0.7945\n",
      "Epoch 148/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4423 - acc: 0.8004 - val_loss: 0.4569 - val_acc: 0.7896\n",
      "Epoch 149/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4422 - acc: 0.8000 - val_loss: 0.4534 - val_acc: 0.7934\n",
      "Epoch 150/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4417 - acc: 0.8006 - val_loss: 0.4523 - val_acc: 0.7988\n",
      "Epoch 151/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4415 - acc: 0.8010 - val_loss: 0.4556 - val_acc: 0.7978\n",
      "Epoch 152/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4411 - acc: 0.7992 - val_loss: 0.4579 - val_acc: 0.7970\n",
      "Epoch 153/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4416 - acc: 0.7991 - val_loss: 0.4541 - val_acc: 0.7976\n",
      "Epoch 154/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4414 - acc: 0.8040 - val_loss: 0.4625 - val_acc: 0.7961\n",
      "Epoch 155/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4418 - acc: 0.8010 - val_loss: 0.4528 - val_acc: 0.7966\n",
      "Epoch 156/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4405 - acc: 0.8008 - val_loss: 0.4516 - val_acc: 0.7966\n",
      "Epoch 157/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4412 - acc: 0.8015 - val_loss: 0.4589 - val_acc: 0.7976\n",
      "Epoch 158/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4395 - acc: 0.8040 - val_loss: 0.4528 - val_acc: 0.7964\n",
      "Epoch 159/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4403 - acc: 0.8034 - val_loss: 0.4525 - val_acc: 0.7972\n",
      "Epoch 160/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4400 - acc: 0.8036 - val_loss: 0.4538 - val_acc: 0.7967\n",
      "Epoch 161/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4419 - acc: 0.8010 - val_loss: 0.4534 - val_acc: 0.7956\n",
      "Epoch 162/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4410 - acc: 0.8017 - val_loss: 0.4525 - val_acc: 0.7962\n",
      "Epoch 163/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4405 - acc: 0.8037 - val_loss: 0.4528 - val_acc: 0.7962\n",
      "Epoch 164/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4401 - acc: 0.8037 - val_loss: 0.4543 - val_acc: 0.7967\n",
      "Epoch 165/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4403 - acc: 0.8023 - val_loss: 0.4514 - val_acc: 0.7968\n",
      "Epoch 166/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4397 - acc: 0.8025 - val_loss: 0.4533 - val_acc: 0.7982\n",
      "Epoch 167/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4397 - acc: 0.8033 - val_loss: 0.4530 - val_acc: 0.7977\n",
      "Epoch 168/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4400 - acc: 0.8029 - val_loss: 0.4543 - val_acc: 0.7972\n",
      "Epoch 169/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4408 - acc: 0.8028 - val_loss: 0.4535 - val_acc: 0.7966\n",
      "Epoch 170/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4404 - acc: 0.8043 - val_loss: 0.4541 - val_acc: 0.7980\n",
      "Epoch 171/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4405 - acc: 0.8009 - val_loss: 0.4523 - val_acc: 0.7968\n",
      "Epoch 172/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4402 - acc: 0.8000 - val_loss: 0.4548 - val_acc: 0.7935\n",
      "Epoch 173/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4406 - acc: 0.8019 - val_loss: 0.4534 - val_acc: 0.7946\n",
      "Epoch 174/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4402 - acc: 0.8010 - val_loss: 0.4602 - val_acc: 0.7920\n",
      "Epoch 175/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4386 - acc: 0.8031 - val_loss: 0.4557 - val_acc: 0.7933\n",
      "Epoch 176/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4405 - acc: 0.8026 - val_loss: 0.4523 - val_acc: 0.7986\n",
      "Epoch 177/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4385 - acc: 0.8034 - val_loss: 0.4539 - val_acc: 0.7989\n",
      "Epoch 178/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4392 - acc: 0.8025 - val_loss: 0.4541 - val_acc: 0.7957\n",
      "Epoch 179/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4386 - acc: 0.8034 - val_loss: 0.4616 - val_acc: 0.7902\n",
      "Epoch 180/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4387 - acc: 0.8036 - val_loss: 0.4531 - val_acc: 0.7963\n",
      "Epoch 181/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4398 - acc: 0.8031 - val_loss: 0.4536 - val_acc: 0.7950\n",
      "Epoch 182/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4391 - acc: 0.8022 - val_loss: 0.4552 - val_acc: 0.7940\n",
      "Epoch 183/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4390 - acc: 0.8048 - val_loss: 0.4537 - val_acc: 0.7935\n",
      "Epoch 184/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4383 - acc: 0.8043 - val_loss: 0.4539 - val_acc: 0.7973\n",
      "Epoch 185/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4388 - acc: 0.8032 - val_loss: 0.4546 - val_acc: 0.7957\n",
      "Epoch 186/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4385 - acc: 0.8023 - val_loss: 0.4528 - val_acc: 0.7980\n",
      "Epoch 187/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4386 - acc: 0.8034 - val_loss: 0.4516 - val_acc: 0.7960\n",
      "Epoch 188/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4384 - acc: 0.8025 - val_loss: 0.4534 - val_acc: 0.7979\n",
      "Epoch 189/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4377 - acc: 0.8035 - val_loss: 0.4527 - val_acc: 0.7961\n",
      "Epoch 190/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4387 - acc: 0.8027 - val_loss: 0.4542 - val_acc: 0.7947\n",
      "Epoch 191/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4383 - acc: 0.8031 - val_loss: 0.4525 - val_acc: 0.7960\n",
      "Epoch 192/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4385 - acc: 0.8028 - val_loss: 0.4515 - val_acc: 0.7997\n",
      "Epoch 193/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4386 - acc: 0.8029 - val_loss: 0.4547 - val_acc: 0.7947\n",
      "Epoch 194/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4383 - acc: 0.8021 - val_loss: 0.4516 - val_acc: 0.7988\n",
      "Epoch 195/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4387 - acc: 0.8039 - val_loss: 0.4523 - val_acc: 0.7964\n",
      "Epoch 196/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4381 - acc: 0.8044 - val_loss: 0.4514 - val_acc: 0.7998\n",
      "Epoch 197/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4372 - acc: 0.8037 - val_loss: 0.4541 - val_acc: 0.7972\n",
      "Epoch 198/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4384 - acc: 0.8033 - val_loss: 0.4529 - val_acc: 0.7981\n",
      "Epoch 199/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4376 - acc: 0.8064 - val_loss: 0.4522 - val_acc: 0.7992\n",
      "Epoch 200/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4387 - acc: 0.8020 - val_loss: 0.4504 - val_acc: 0.7999\n",
      "Epoch 201/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4375 - acc: 0.8048 - val_loss: 0.4554 - val_acc: 0.7981\n",
      "Epoch 202/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4382 - acc: 0.8053 - val_loss: 0.4523 - val_acc: 0.7933\n",
      "Epoch 203/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4382 - acc: 0.8043 - val_loss: 0.4518 - val_acc: 0.7978\n",
      "Epoch 204/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4378 - acc: 0.8031 - val_loss: 0.4534 - val_acc: 0.7976\n",
      "Epoch 205/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4386 - acc: 0.8023 - val_loss: 0.4522 - val_acc: 0.7997\n",
      "Epoch 206/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4372 - acc: 0.8039 - val_loss: 0.4510 - val_acc: 0.8004\n",
      "Epoch 207/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4374 - acc: 0.8061 - val_loss: 0.4514 - val_acc: 0.7986\n",
      "Epoch 208/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4378 - acc: 0.8046 - val_loss: 0.4524 - val_acc: 0.7962\n",
      "Epoch 209/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4377 - acc: 0.8044 - val_loss: 0.4532 - val_acc: 0.7979\n",
      "Epoch 210/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4381 - acc: 0.8021 - val_loss: 0.4504 - val_acc: 0.7989\n",
      "Epoch 211/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4371 - acc: 0.8033 - val_loss: 0.4523 - val_acc: 0.7974\n",
      "Epoch 212/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4362 - acc: 0.8042 - val_loss: 0.4648 - val_acc: 0.7940\n",
      "Epoch 213/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4373 - acc: 0.8042 - val_loss: 0.4520 - val_acc: 0.7969\n",
      "Epoch 214/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4370 - acc: 0.8042 - val_loss: 0.4538 - val_acc: 0.7965\n",
      "Epoch 215/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4380 - acc: 0.8037 - val_loss: 0.4695 - val_acc: 0.7856\n",
      "Epoch 216/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4387 - acc: 0.8044 - val_loss: 0.4530 - val_acc: 0.7967\n",
      "Epoch 217/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4369 - acc: 0.8069 - val_loss: 0.4530 - val_acc: 0.7981\n",
      "Epoch 218/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4378 - acc: 0.8029 - val_loss: 0.4610 - val_acc: 0.7938\n",
      "Epoch 219/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4378 - acc: 0.8029 - val_loss: 0.4525 - val_acc: 0.7998\n",
      "Epoch 220/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4368 - acc: 0.8051 - val_loss: 0.4501 - val_acc: 0.7989\n",
      "Epoch 221/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4365 - acc: 0.8061 - val_loss: 0.4521 - val_acc: 0.7957\n",
      "Epoch 222/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4362 - acc: 0.8038 - val_loss: 0.4502 - val_acc: 0.7988\n",
      "Epoch 223/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4367 - acc: 0.8041 - val_loss: 0.4531 - val_acc: 0.7957\n",
      "Epoch 224/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4367 - acc: 0.8060 - val_loss: 0.4535 - val_acc: 0.7989\n",
      "Epoch 225/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4368 - acc: 0.8045 - val_loss: 0.4522 - val_acc: 0.7974\n",
      "Epoch 226/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4360 - acc: 0.8052 - val_loss: 0.4519 - val_acc: 0.7991\n",
      "Epoch 227/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4370 - acc: 0.8035 - val_loss: 0.4503 - val_acc: 0.8001\n",
      "Epoch 228/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4360 - acc: 0.8033 - val_loss: 0.4511 - val_acc: 0.8012\n",
      "Epoch 229/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4368 - acc: 0.8057 - val_loss: 0.4539 - val_acc: 0.7976\n",
      "Epoch 230/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4360 - acc: 0.8034 - val_loss: 0.4506 - val_acc: 0.8002\n",
      "Epoch 231/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4358 - acc: 0.8060 - val_loss: 0.4513 - val_acc: 0.7980\n",
      "Epoch 232/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4361 - acc: 0.8061 - val_loss: 0.4511 - val_acc: 0.7960\n",
      "Epoch 233/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4353 - acc: 0.8070 - val_loss: 0.4522 - val_acc: 0.7953\n",
      "Epoch 234/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4362 - acc: 0.8041 - val_loss: 0.4619 - val_acc: 0.7938\n",
      "Epoch 235/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4358 - acc: 0.8043 - val_loss: 0.4522 - val_acc: 0.7962\n",
      "Epoch 236/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4364 - acc: 0.8065 - val_loss: 0.4496 - val_acc: 0.8005\n",
      "Epoch 237/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4358 - acc: 0.8046 - val_loss: 0.4516 - val_acc: 0.7978\n",
      "Epoch 238/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4380 - acc: 0.8048 - val_loss: 0.4520 - val_acc: 0.7965\n",
      "Epoch 239/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4356 - acc: 0.8055 - val_loss: 0.4530 - val_acc: 0.7992\n",
      "Epoch 240/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4373 - acc: 0.8042 - val_loss: 0.4511 - val_acc: 0.7980\n",
      "Epoch 241/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4359 - acc: 0.8068 - val_loss: 0.4519 - val_acc: 0.7956\n",
      "Epoch 242/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4354 - acc: 0.8049 - val_loss: 0.4516 - val_acc: 0.7978\n",
      "Epoch 243/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4359 - acc: 0.8041 - val_loss: 0.4527 - val_acc: 0.7935\n",
      "Epoch 244/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4354 - acc: 0.8062 - val_loss: 0.4571 - val_acc: 0.7974\n",
      "Epoch 245/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4355 - acc: 0.8054 - val_loss: 0.4503 - val_acc: 0.7987\n",
      "Epoch 246/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4350 - acc: 0.8066 - val_loss: 0.4527 - val_acc: 0.8007\n",
      "Epoch 247/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4347 - acc: 0.8063 - val_loss: 0.4516 - val_acc: 0.7949\n",
      "Epoch 248/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4358 - acc: 0.8053 - val_loss: 0.4491 - val_acc: 0.8019\n",
      "Epoch 249/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4352 - acc: 0.8058 - val_loss: 0.4518 - val_acc: 0.7990\n",
      "Epoch 250/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4347 - acc: 0.8067 - val_loss: 0.4518 - val_acc: 0.7977\n",
      "Epoch 251/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4357 - acc: 0.8051 - val_loss: 0.4519 - val_acc: 0.7973\n",
      "Epoch 252/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4353 - acc: 0.8057 - val_loss: 0.4497 - val_acc: 0.7974\n",
      "Epoch 253/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4378 - acc: 0.8046 - val_loss: 0.4521 - val_acc: 0.7930\n",
      "Epoch 254/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4348 - acc: 0.8073 - val_loss: 0.4503 - val_acc: 0.8019\n",
      "Epoch 255/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4354 - acc: 0.8019 - val_loss: 0.4507 - val_acc: 0.7973\n",
      "Epoch 256/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4359 - acc: 0.8063 - val_loss: 0.4583 - val_acc: 0.7887\n",
      "Epoch 257/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4349 - acc: 0.8051 - val_loss: 0.4499 - val_acc: 0.7984\n",
      "Epoch 258/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4339 - acc: 0.8063 - val_loss: 0.4552 - val_acc: 0.7920\n",
      "Epoch 259/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4353 - acc: 0.8061 - val_loss: 0.4541 - val_acc: 0.7933\n",
      "Epoch 260/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4354 - acc: 0.8053 - val_loss: 0.4545 - val_acc: 0.7989\n",
      "Epoch 261/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4352 - acc: 0.8044 - val_loss: 0.4546 - val_acc: 0.7964\n",
      "Epoch 262/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4351 - acc: 0.8071 - val_loss: 0.4551 - val_acc: 0.7982\n",
      "Epoch 263/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4359 - acc: 0.8055 - val_loss: 0.4504 - val_acc: 0.7981\n",
      "Epoch 264/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4355 - acc: 0.8064 - val_loss: 0.4558 - val_acc: 0.7922\n",
      "Epoch 265/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4342 - acc: 0.8069 - val_loss: 0.4518 - val_acc: 0.7977\n",
      "Epoch 266/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4350 - acc: 0.8056 - val_loss: 0.4523 - val_acc: 0.7998\n",
      "Epoch 267/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4348 - acc: 0.8061 - val_loss: 0.4522 - val_acc: 0.7986\n",
      "Epoch 268/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4343 - acc: 0.8075 - val_loss: 0.4549 - val_acc: 0.7970\n",
      "Epoch 269/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4342 - acc: 0.8069 - val_loss: 0.4528 - val_acc: 0.7947\n",
      "Epoch 270/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4341 - acc: 0.8073 - val_loss: 0.4503 - val_acc: 0.8016\n",
      "Epoch 271/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4337 - acc: 0.8065 - val_loss: 0.4495 - val_acc: 0.7940\n",
      "Epoch 272/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4341 - acc: 0.8081 - val_loss: 0.4552 - val_acc: 0.7968\n",
      "Epoch 273/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4352 - acc: 0.8050 - val_loss: 0.4543 - val_acc: 0.7934\n",
      "Epoch 274/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4356 - acc: 0.8051 - val_loss: 0.4492 - val_acc: 0.7987\n",
      "Epoch 275/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4345 - acc: 0.8058 - val_loss: 0.4493 - val_acc: 0.7996\n",
      "Epoch 276/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4343 - acc: 0.8066 - val_loss: 0.4503 - val_acc: 0.7954\n",
      "Epoch 277/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4346 - acc: 0.8061 - val_loss: 0.4504 - val_acc: 0.7982\n",
      "Epoch 278/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4345 - acc: 0.8076 - val_loss: 0.4506 - val_acc: 0.8012\n",
      "Epoch 279/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4347 - acc: 0.8067 - val_loss: 0.4535 - val_acc: 0.7933\n",
      "Epoch 280/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4341 - acc: 0.8066 - val_loss: 0.4634 - val_acc: 0.7965\n",
      "Epoch 281/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4343 - acc: 0.8048 - val_loss: 0.4510 - val_acc: 0.7977\n",
      "Epoch 282/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4340 - acc: 0.8069 - val_loss: 0.4584 - val_acc: 0.7980\n",
      "Epoch 283/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4334 - acc: 0.8060 - val_loss: 0.4514 - val_acc: 0.7987\n",
      "Epoch 284/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4347 - acc: 0.8075 - val_loss: 0.4491 - val_acc: 0.7986\n",
      "Epoch 285/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4338 - acc: 0.8059 - val_loss: 0.4490 - val_acc: 0.7975\n",
      "Epoch 286/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4343 - acc: 0.8079 - val_loss: 0.4554 - val_acc: 0.7920\n",
      "Epoch 287/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4341 - acc: 0.8065 - val_loss: 0.4492 - val_acc: 0.7977\n",
      "Epoch 288/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4331 - acc: 0.8066 - val_loss: 0.4516 - val_acc: 0.7945\n",
      "Epoch 289/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4330 - acc: 0.8083 - val_loss: 0.4547 - val_acc: 0.8004\n",
      "Epoch 290/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4341 - acc: 0.8063 - val_loss: 0.4511 - val_acc: 0.7968\n",
      "Epoch 291/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4337 - acc: 0.8057 - val_loss: 0.4508 - val_acc: 0.7953\n",
      "Epoch 292/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4339 - acc: 0.8057 - val_loss: 0.4490 - val_acc: 0.7968\n",
      "Epoch 293/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4336 - acc: 0.8052 - val_loss: 0.4508 - val_acc: 0.7967\n",
      "Epoch 294/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4337 - acc: 0.8083 - val_loss: 0.4507 - val_acc: 0.7984\n",
      "Epoch 295/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4345 - acc: 0.8079 - val_loss: 0.4536 - val_acc: 0.7968\n",
      "Epoch 296/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4337 - acc: 0.8067 - val_loss: 0.4500 - val_acc: 0.8005\n",
      "Epoch 297/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4342 - acc: 0.8062 - val_loss: 0.4545 - val_acc: 0.7993\n",
      "Epoch 298/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4340 - acc: 0.8070 - val_loss: 0.4523 - val_acc: 0.7943\n",
      "Epoch 299/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4336 - acc: 0.8076 - val_loss: 0.4493 - val_acc: 0.8014\n",
      "Epoch 300/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4341 - acc: 0.8075 - val_loss: 0.4556 - val_acc: 0.7945\n",
      "Epoch 301/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4324 - acc: 0.8075 - val_loss: 0.4512 - val_acc: 0.7968\n",
      "Epoch 302/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4339 - acc: 0.8052 - val_loss: 0.4486 - val_acc: 0.8007\n",
      "Epoch 303/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4337 - acc: 0.8062 - val_loss: 0.4633 - val_acc: 0.7867\n",
      "Epoch 304/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4338 - acc: 0.8046 - val_loss: 0.4503 - val_acc: 0.8016\n",
      "Epoch 305/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4336 - acc: 0.8063 - val_loss: 0.4490 - val_acc: 0.8034\n",
      "Epoch 306/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4333 - acc: 0.8062 - val_loss: 0.4514 - val_acc: 0.7996\n",
      "Epoch 307/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4336 - acc: 0.8061 - val_loss: 0.4586 - val_acc: 0.7912\n",
      "Epoch 308/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4335 - acc: 0.8068 - val_loss: 0.4575 - val_acc: 0.7930\n",
      "Epoch 309/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4337 - acc: 0.8090 - val_loss: 0.4510 - val_acc: 0.7944\n",
      "Epoch 310/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4332 - acc: 0.8065 - val_loss: 0.4579 - val_acc: 0.8000\n",
      "Epoch 311/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4332 - acc: 0.8071 - val_loss: 0.4508 - val_acc: 0.7981\n",
      "Epoch 312/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4334 - acc: 0.8056 - val_loss: 0.4478 - val_acc: 0.7992\n",
      "Epoch 313/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4325 - acc: 0.8072 - val_loss: 0.4540 - val_acc: 0.7961\n",
      "Epoch 314/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4331 - acc: 0.8055 - val_loss: 0.4493 - val_acc: 0.7997\n",
      "Epoch 315/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4337 - acc: 0.8056 - val_loss: 0.4524 - val_acc: 0.7961\n",
      "Epoch 316/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4327 - acc: 0.8076 - val_loss: 0.4495 - val_acc: 0.7978\n",
      "Epoch 317/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4334 - acc: 0.8083 - val_loss: 0.4543 - val_acc: 0.7937\n",
      "Epoch 318/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4321 - acc: 0.8057 - val_loss: 0.4516 - val_acc: 0.7952\n",
      "Epoch 319/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4330 - acc: 0.8068 - val_loss: 0.4505 - val_acc: 0.7956\n",
      "Epoch 320/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4313 - acc: 0.8080 - val_loss: 0.4523 - val_acc: 0.7955\n",
      "Epoch 321/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4322 - acc: 0.8079 - val_loss: 0.4479 - val_acc: 0.8004\n",
      "Epoch 322/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4321 - acc: 0.8070 - val_loss: 0.4485 - val_acc: 0.7976\n",
      "Epoch 323/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4322 - acc: 0.8070 - val_loss: 0.4480 - val_acc: 0.7991\n",
      "Epoch 324/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4323 - acc: 0.8046 - val_loss: 0.4508 - val_acc: 0.8003\n",
      "Epoch 325/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4314 - acc: 0.8093 - val_loss: 0.4495 - val_acc: 0.7999\n",
      "Epoch 326/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4316 - acc: 0.8091 - val_loss: 0.4507 - val_acc: 0.7969\n",
      "Epoch 327/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4324 - acc: 0.8066 - val_loss: 0.4513 - val_acc: 0.7966\n",
      "Epoch 328/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4323 - acc: 0.8071 - val_loss: 0.4513 - val_acc: 0.8020\n",
      "Epoch 329/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4322 - acc: 0.8072 - val_loss: 0.4488 - val_acc: 0.7979\n",
      "Epoch 330/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4326 - acc: 0.8083 - val_loss: 0.4475 - val_acc: 0.7993\n",
      "Epoch 331/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4319 - acc: 0.8063 - val_loss: 0.4564 - val_acc: 0.7972\n",
      "Epoch 332/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4327 - acc: 0.8043 - val_loss: 0.4492 - val_acc: 0.7965\n",
      "Epoch 333/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4321 - acc: 0.8059 - val_loss: 0.4513 - val_acc: 0.7958\n",
      "Epoch 334/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4320 - acc: 0.8071 - val_loss: 0.4489 - val_acc: 0.7988\n",
      "Epoch 335/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4317 - acc: 0.8078 - val_loss: 0.4489 - val_acc: 0.7990\n",
      "Epoch 336/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4325 - acc: 0.8083 - val_loss: 0.4500 - val_acc: 0.7947\n",
      "Epoch 337/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4318 - acc: 0.8081 - val_loss: 0.4485 - val_acc: 0.7992\n",
      "Epoch 338/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4312 - acc: 0.8066 - val_loss: 0.4486 - val_acc: 0.7957\n",
      "Epoch 339/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4325 - acc: 0.8072 - val_loss: 0.4516 - val_acc: 0.7958\n",
      "Epoch 340/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4320 - acc: 0.8073 - val_loss: 0.4489 - val_acc: 0.7987\n",
      "Epoch 341/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4315 - acc: 0.8078 - val_loss: 0.4498 - val_acc: 0.7962\n",
      "Epoch 342/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4314 - acc: 0.8069 - val_loss: 0.4512 - val_acc: 0.7989\n",
      "Epoch 343/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4312 - acc: 0.8077 - val_loss: 0.4543 - val_acc: 0.7972\n",
      "Epoch 344/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4304 - acc: 0.8080 - val_loss: 0.4553 - val_acc: 0.7987\n",
      "Epoch 345/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4325 - acc: 0.8067 - val_loss: 0.4498 - val_acc: 0.7974\n",
      "Epoch 346/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4315 - acc: 0.8075 - val_loss: 0.4478 - val_acc: 0.7987\n",
      "Epoch 347/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4316 - acc: 0.8078 - val_loss: 0.4556 - val_acc: 0.7970\n",
      "Epoch 348/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4320 - acc: 0.8053 - val_loss: 0.4520 - val_acc: 0.7973\n",
      "Epoch 349/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4317 - acc: 0.8083 - val_loss: 0.4560 - val_acc: 0.7940\n",
      "Epoch 350/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4316 - acc: 0.8090 - val_loss: 0.4477 - val_acc: 0.8000\n",
      "Epoch 351/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4314 - acc: 0.8081 - val_loss: 0.4463 - val_acc: 0.7992\n",
      "Epoch 352/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4308 - acc: 0.8091 - val_loss: 0.4531 - val_acc: 0.7941\n",
      "Epoch 353/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4314 - acc: 0.8093 - val_loss: 0.4544 - val_acc: 0.7934\n",
      "Epoch 354/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4316 - acc: 0.8053 - val_loss: 0.4514 - val_acc: 0.7980\n",
      "Epoch 355/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4296 - acc: 0.8073 - val_loss: 0.4493 - val_acc: 0.7987\n",
      "Epoch 356/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4318 - acc: 0.8076 - val_loss: 0.4469 - val_acc: 0.8024\n",
      "Epoch 357/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4306 - acc: 0.8088 - val_loss: 0.4479 - val_acc: 0.8008\n",
      "Epoch 358/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4319 - acc: 0.8065 - val_loss: 0.4480 - val_acc: 0.7990\n",
      "Epoch 359/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4315 - acc: 0.8065 - val_loss: 0.4462 - val_acc: 0.8023\n",
      "Epoch 360/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4314 - acc: 0.8077 - val_loss: 0.4495 - val_acc: 0.7981\n",
      "Epoch 361/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4308 - acc: 0.8063 - val_loss: 0.4478 - val_acc: 0.8007\n",
      "Epoch 362/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4301 - acc: 0.8087 - val_loss: 0.4470 - val_acc: 0.7981\n",
      "Epoch 363/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4309 - acc: 0.8079 - val_loss: 0.4488 - val_acc: 0.8031\n",
      "Epoch 364/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4306 - acc: 0.8084 - val_loss: 0.4472 - val_acc: 0.7978\n",
      "Epoch 365/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4314 - acc: 0.8071 - val_loss: 0.4463 - val_acc: 0.7997\n",
      "Epoch 366/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4305 - acc: 0.8068 - val_loss: 0.4486 - val_acc: 0.8015\n",
      "Epoch 367/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4309 - acc: 0.8091 - val_loss: 0.4490 - val_acc: 0.7986\n",
      "Epoch 368/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4302 - acc: 0.8091 - val_loss: 0.4479 - val_acc: 0.8003\n",
      "Epoch 369/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4304 - acc: 0.8063 - val_loss: 0.4467 - val_acc: 0.8013\n",
      "Epoch 370/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4307 - acc: 0.8065 - val_loss: 0.4485 - val_acc: 0.8010\n",
      "Epoch 371/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4310 - acc: 0.8055 - val_loss: 0.4485 - val_acc: 0.7964\n",
      "Epoch 372/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4311 - acc: 0.8088 - val_loss: 0.4474 - val_acc: 0.7981\n",
      "Epoch 373/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4306 - acc: 0.8080 - val_loss: 0.4517 - val_acc: 0.7938\n",
      "Epoch 374/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4299 - acc: 0.8099 - val_loss: 0.4513 - val_acc: 0.7976\n",
      "Epoch 375/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4308 - acc: 0.8097 - val_loss: 0.4485 - val_acc: 0.7970\n",
      "Epoch 376/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4306 - acc: 0.8084 - val_loss: 0.4543 - val_acc: 0.7988\n",
      "Epoch 377/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4312 - acc: 0.8081 - val_loss: 0.4497 - val_acc: 0.7973\n",
      "Epoch 378/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4301 - acc: 0.8075 - val_loss: 0.4485 - val_acc: 0.7979\n",
      "Epoch 379/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4308 - acc: 0.8082 - val_loss: 0.4486 - val_acc: 0.7980\n",
      "Epoch 380/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4303 - acc: 0.8073 - val_loss: 0.4482 - val_acc: 0.7999\n",
      "Epoch 381/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4306 - acc: 0.8082 - val_loss: 0.4483 - val_acc: 0.7972\n",
      "Epoch 382/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4303 - acc: 0.8078 - val_loss: 0.4460 - val_acc: 0.8026\n",
      "Epoch 383/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4295 - acc: 0.8074 - val_loss: 0.4489 - val_acc: 0.7985\n",
      "Epoch 384/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4304 - acc: 0.8092 - val_loss: 0.4453 - val_acc: 0.8005\n",
      "Epoch 385/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4300 - acc: 0.8082 - val_loss: 0.4479 - val_acc: 0.8000\n",
      "Epoch 386/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4292 - acc: 0.8104 - val_loss: 0.4459 - val_acc: 0.7999\n",
      "Epoch 387/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4305 - acc: 0.8104 - val_loss: 0.4457 - val_acc: 0.8010\n",
      "Epoch 388/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4297 - acc: 0.8079 - val_loss: 0.4493 - val_acc: 0.8001\n",
      "Epoch 389/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4312 - acc: 0.8076 - val_loss: 0.4512 - val_acc: 0.7949\n",
      "Epoch 390/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4317 - acc: 0.8059 - val_loss: 0.4460 - val_acc: 0.7985\n",
      "Epoch 391/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4312 - acc: 0.8065 - val_loss: 0.4453 - val_acc: 0.8030\n",
      "Epoch 392/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4297 - acc: 0.8084 - val_loss: 0.4473 - val_acc: 0.7986\n",
      "Epoch 393/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4299 - acc: 0.8081 - val_loss: 0.4465 - val_acc: 0.7993\n",
      "Epoch 394/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4300 - acc: 0.8089 - val_loss: 0.4500 - val_acc: 0.7998\n",
      "Epoch 395/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4296 - acc: 0.8095 - val_loss: 0.4498 - val_acc: 0.8012\n",
      "Epoch 396/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4294 - acc: 0.8084 - val_loss: 0.4547 - val_acc: 0.7938\n",
      "Epoch 397/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4304 - acc: 0.8095 - val_loss: 0.4482 - val_acc: 0.7988\n",
      "Epoch 398/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4288 - acc: 0.8080 - val_loss: 0.4486 - val_acc: 0.8016\n",
      "Epoch 399/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4289 - acc: 0.8082 - val_loss: 0.4510 - val_acc: 0.7992\n",
      "Epoch 400/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4301 - acc: 0.8069 - val_loss: 0.4470 - val_acc: 0.8002\n",
      "Epoch 401/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4291 - acc: 0.8082 - val_loss: 0.4461 - val_acc: 0.7988\n",
      "Epoch 402/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4288 - acc: 0.8103 - val_loss: 0.4502 - val_acc: 0.8014\n",
      "Epoch 403/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4292 - acc: 0.8086 - val_loss: 0.4465 - val_acc: 0.8022\n",
      "Epoch 404/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4292 - acc: 0.8096 - val_loss: 0.4524 - val_acc: 0.7976\n",
      "Epoch 405/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4292 - acc: 0.8069 - val_loss: 0.4496 - val_acc: 0.7973\n",
      "Epoch 406/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4298 - acc: 0.8084 - val_loss: 0.4462 - val_acc: 0.8028\n",
      "Epoch 407/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4299 - acc: 0.8097 - val_loss: 0.4465 - val_acc: 0.7990\n",
      "Epoch 408/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4297 - acc: 0.8086 - val_loss: 0.4448 - val_acc: 0.8021\n",
      "Epoch 409/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4293 - acc: 0.8110 - val_loss: 0.4461 - val_acc: 0.8012\n",
      "Epoch 410/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4292 - acc: 0.8086 - val_loss: 0.4491 - val_acc: 0.8001\n",
      "Epoch 411/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4292 - acc: 0.8076 - val_loss: 0.4463 - val_acc: 0.8012\n",
      "Epoch 412/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4302 - acc: 0.8095 - val_loss: 0.4498 - val_acc: 0.8010\n",
      "Epoch 413/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4307 - acc: 0.8070 - val_loss: 0.4507 - val_acc: 0.7964\n",
      "Epoch 414/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4291 - acc: 0.8079 - val_loss: 0.4495 - val_acc: 0.7995\n",
      "Epoch 415/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4294 - acc: 0.8076 - val_loss: 0.4452 - val_acc: 0.8011\n",
      "Epoch 416/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4297 - acc: 0.8095 - val_loss: 0.4486 - val_acc: 0.8003\n",
      "Epoch 417/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4305 - acc: 0.8062 - val_loss: 0.4503 - val_acc: 0.7995\n",
      "Epoch 418/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4293 - acc: 0.8089 - val_loss: 0.4459 - val_acc: 0.7999\n",
      "Epoch 419/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4294 - acc: 0.8082 - val_loss: 0.4470 - val_acc: 0.8002\n",
      "Epoch 420/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4289 - acc: 0.8086 - val_loss: 0.4472 - val_acc: 0.8015\n",
      "Epoch 421/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4295 - acc: 0.8075 - val_loss: 0.4485 - val_acc: 0.7979\n",
      "Epoch 422/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4286 - acc: 0.8102 - val_loss: 0.4476 - val_acc: 0.8002\n",
      "Epoch 423/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4291 - acc: 0.8092 - val_loss: 0.4477 - val_acc: 0.7981\n",
      "Epoch 424/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4287 - acc: 0.8092 - val_loss: 0.4476 - val_acc: 0.7987\n",
      "Epoch 425/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4290 - acc: 0.8106 - val_loss: 0.4484 - val_acc: 0.7998\n",
      "Epoch 426/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4290 - acc: 0.8103 - val_loss: 0.4467 - val_acc: 0.7999\n",
      "Epoch 427/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4294 - acc: 0.8087 - val_loss: 0.4451 - val_acc: 0.8004\n",
      "Epoch 428/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4285 - acc: 0.8073 - val_loss: 0.4594 - val_acc: 0.7892\n",
      "Epoch 429/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4285 - acc: 0.8095 - val_loss: 0.4457 - val_acc: 0.8020\n",
      "Epoch 430/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4284 - acc: 0.8094 - val_loss: 0.4478 - val_acc: 0.7993\n",
      "Epoch 431/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4285 - acc: 0.8074 - val_loss: 0.4470 - val_acc: 0.8008\n",
      "Epoch 432/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4282 - acc: 0.8090 - val_loss: 0.4462 - val_acc: 0.8024\n",
      "Epoch 433/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4281 - acc: 0.8093 - val_loss: 0.4460 - val_acc: 0.8007\n",
      "Epoch 434/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4282 - acc: 0.8092 - val_loss: 0.4467 - val_acc: 0.7988\n",
      "Epoch 435/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4286 - acc: 0.8103 - val_loss: 0.4442 - val_acc: 0.8004\n",
      "Epoch 436/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4279 - acc: 0.8099 - val_loss: 0.4458 - val_acc: 0.8011\n",
      "Epoch 437/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4287 - acc: 0.8103 - val_loss: 0.4479 - val_acc: 0.8025\n",
      "Epoch 438/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4276 - acc: 0.8107 - val_loss: 0.4477 - val_acc: 0.8019\n",
      "Epoch 439/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4298 - acc: 0.8065 - val_loss: 0.4470 - val_acc: 0.8012\n",
      "Epoch 440/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4292 - acc: 0.8083 - val_loss: 0.4446 - val_acc: 0.8030\n",
      "Epoch 441/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4299 - acc: 0.8073 - val_loss: 0.4474 - val_acc: 0.7979\n",
      "Epoch 442/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4277 - acc: 0.8096 - val_loss: 0.4461 - val_acc: 0.8003\n",
      "Epoch 443/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4288 - acc: 0.8099 - val_loss: 0.4475 - val_acc: 0.8000\n",
      "Epoch 444/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4302 - acc: 0.8061 - val_loss: 0.4486 - val_acc: 0.7985\n",
      "Epoch 445/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4288 - acc: 0.8101 - val_loss: 0.4462 - val_acc: 0.8010\n",
      "Epoch 446/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4288 - acc: 0.8072 - val_loss: 0.4460 - val_acc: 0.8033\n",
      "Epoch 447/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4290 - acc: 0.8079 - val_loss: 0.4485 - val_acc: 0.8024\n",
      "Epoch 448/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4283 - acc: 0.8095 - val_loss: 0.4471 - val_acc: 0.8001\n",
      "Epoch 449/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4284 - acc: 0.8071 - val_loss: 0.4457 - val_acc: 0.8009\n",
      "Epoch 450/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4283 - acc: 0.8106 - val_loss: 0.4469 - val_acc: 0.8013\n",
      "Epoch 451/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4289 - acc: 0.8083 - val_loss: 0.4458 - val_acc: 0.8019\n",
      "Epoch 452/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4277 - acc: 0.8093 - val_loss: 0.4515 - val_acc: 0.7950\n",
      "Epoch 453/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4292 - acc: 0.8087 - val_loss: 0.4456 - val_acc: 0.8023\n",
      "Epoch 454/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4280 - acc: 0.8104 - val_loss: 0.4488 - val_acc: 0.8009\n",
      "Epoch 455/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4279 - acc: 0.8096 - val_loss: 0.4454 - val_acc: 0.8044\n",
      "Epoch 456/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4280 - acc: 0.8108 - val_loss: 0.4507 - val_acc: 0.8015\n",
      "Epoch 457/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4274 - acc: 0.8082 - val_loss: 0.4475 - val_acc: 0.8002\n",
      "Epoch 458/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4279 - acc: 0.8088 - val_loss: 0.4478 - val_acc: 0.7984\n",
      "Epoch 459/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4291 - acc: 0.8086 - val_loss: 0.4467 - val_acc: 0.8004\n",
      "Epoch 460/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4281 - acc: 0.8103 - val_loss: 0.4445 - val_acc: 0.8004\n",
      "Epoch 461/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4293 - acc: 0.8080 - val_loss: 0.4459 - val_acc: 0.7992\n",
      "Epoch 462/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4276 - acc: 0.8099 - val_loss: 0.4447 - val_acc: 0.7992\n",
      "Epoch 463/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4273 - acc: 0.8079 - val_loss: 0.4473 - val_acc: 0.8002\n",
      "Epoch 464/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4281 - acc: 0.8094 - val_loss: 0.4482 - val_acc: 0.7981\n",
      "Epoch 465/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4288 - acc: 0.8098 - val_loss: 0.4453 - val_acc: 0.8007\n",
      "Epoch 466/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4280 - acc: 0.8094 - val_loss: 0.4457 - val_acc: 0.8027\n",
      "Epoch 467/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4276 - acc: 0.8112 - val_loss: 0.4457 - val_acc: 0.8031\n",
      "Epoch 468/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4280 - acc: 0.8092 - val_loss: 0.4482 - val_acc: 0.8013\n",
      "Epoch 469/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4283 - acc: 0.8072 - val_loss: 0.4460 - val_acc: 0.7992\n",
      "Epoch 470/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4281 - acc: 0.8106 - val_loss: 0.4454 - val_acc: 0.7999\n",
      "Epoch 471/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4273 - acc: 0.8103 - val_loss: 0.4462 - val_acc: 0.8007\n",
      "Epoch 472/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4278 - acc: 0.8093 - val_loss: 0.4465 - val_acc: 0.8001\n",
      "Epoch 473/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4272 - acc: 0.8111 - val_loss: 0.4464 - val_acc: 0.8005\n",
      "Epoch 474/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4277 - acc: 0.8074 - val_loss: 0.4483 - val_acc: 0.7980\n",
      "Epoch 475/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4267 - acc: 0.8094 - val_loss: 0.4472 - val_acc: 0.8003\n",
      "Epoch 476/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4280 - acc: 0.8092 - val_loss: 0.4449 - val_acc: 0.8018\n",
      "Epoch 477/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4281 - acc: 0.8089 - val_loss: 0.4449 - val_acc: 0.8023\n",
      "Epoch 478/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4283 - acc: 0.8073 - val_loss: 0.4515 - val_acc: 0.7974\n",
      "Epoch 479/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4277 - acc: 0.8106 - val_loss: 0.4426 - val_acc: 0.8046\n",
      "Epoch 480/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4277 - acc: 0.8093 - val_loss: 0.4518 - val_acc: 0.7982\n",
      "Epoch 481/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4285 - acc: 0.8077 - val_loss: 0.4436 - val_acc: 0.8037\n",
      "Epoch 482/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4277 - acc: 0.8101 - val_loss: 0.4476 - val_acc: 0.8009\n",
      "Epoch 483/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4270 - acc: 0.8097 - val_loss: 0.4443 - val_acc: 0.8034\n",
      "Epoch 484/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4276 - acc: 0.8104 - val_loss: 0.4453 - val_acc: 0.8034\n",
      "Epoch 485/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4270 - acc: 0.8087 - val_loss: 0.4455 - val_acc: 0.8016\n",
      "Epoch 486/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4274 - acc: 0.8114 - val_loss: 0.4460 - val_acc: 0.8011\n",
      "Epoch 487/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4277 - acc: 0.8096 - val_loss: 0.4471 - val_acc: 0.7993\n",
      "Epoch 488/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4268 - acc: 0.8105 - val_loss: 0.4547 - val_acc: 0.7972\n",
      "Epoch 489/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4276 - acc: 0.8083 - val_loss: 0.4489 - val_acc: 0.7980\n",
      "Epoch 490/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4276 - acc: 0.8087 - val_loss: 0.4438 - val_acc: 0.8024\n",
      "Epoch 491/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4266 - acc: 0.8092 - val_loss: 0.4456 - val_acc: 0.8009\n",
      "Epoch 492/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4285 - acc: 0.8084 - val_loss: 0.4458 - val_acc: 0.8022\n",
      "Epoch 493/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4273 - acc: 0.8086 - val_loss: 0.4442 - val_acc: 0.8036\n",
      "Epoch 494/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4271 - acc: 0.8098 - val_loss: 0.4443 - val_acc: 0.8026\n",
      "Epoch 495/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4272 - acc: 0.8097 - val_loss: 0.4444 - val_acc: 0.8032\n",
      "Epoch 496/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4272 - acc: 0.8098 - val_loss: 0.4475 - val_acc: 0.8013\n",
      "Epoch 497/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4286 - acc: 0.8093 - val_loss: 0.4452 - val_acc: 0.8010\n",
      "Epoch 498/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4272 - acc: 0.8096 - val_loss: 0.4467 - val_acc: 0.7995\n",
      "Epoch 499/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4272 - acc: 0.8096 - val_loss: 0.4467 - val_acc: 0.8023\n",
      "Epoch 500/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4266 - acc: 0.8119 - val_loss: 0.4449 - val_acc: 0.8004\n",
      "Epoch 501/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4277 - acc: 0.8093 - val_loss: 0.4458 - val_acc: 0.8028\n",
      "Epoch 502/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4279 - acc: 0.8087 - val_loss: 0.4458 - val_acc: 0.8026\n",
      "Epoch 503/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4277 - acc: 0.8088 - val_loss: 0.4466 - val_acc: 0.8001\n",
      "Epoch 504/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4261 - acc: 0.8118 - val_loss: 0.4473 - val_acc: 0.7991\n",
      "Epoch 505/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4267 - acc: 0.8101 - val_loss: 0.4429 - val_acc: 0.8038\n",
      "Epoch 506/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4261 - acc: 0.8113 - val_loss: 0.4491 - val_acc: 0.8005\n",
      "Epoch 507/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4274 - acc: 0.8085 - val_loss: 0.4450 - val_acc: 0.8021\n",
      "Epoch 508/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4269 - acc: 0.8113 - val_loss: 0.4488 - val_acc: 0.8002\n",
      "Epoch 509/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4270 - acc: 0.8104 - val_loss: 0.4486 - val_acc: 0.7989\n",
      "Epoch 510/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4275 - acc: 0.8082 - val_loss: 0.4452 - val_acc: 0.8015\n",
      "Epoch 511/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4265 - acc: 0.8089 - val_loss: 0.4458 - val_acc: 0.8020\n",
      "Epoch 512/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4274 - acc: 0.8092 - val_loss: 0.4446 - val_acc: 0.8051\n",
      "Epoch 513/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4272 - acc: 0.8105 - val_loss: 0.4447 - val_acc: 0.8012\n",
      "Epoch 514/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4264 - acc: 0.8099 - val_loss: 0.4454 - val_acc: 0.8023\n",
      "Epoch 515/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4270 - acc: 0.8097 - val_loss: 0.4463 - val_acc: 0.8031\n",
      "Epoch 516/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4279 - acc: 0.8083 - val_loss: 0.4461 - val_acc: 0.8028\n",
      "Epoch 517/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4268 - acc: 0.8085 - val_loss: 0.4537 - val_acc: 0.7954\n",
      "Epoch 518/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4270 - acc: 0.8124 - val_loss: 0.4446 - val_acc: 0.8032\n",
      "Epoch 519/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4276 - acc: 0.8079 - val_loss: 0.4445 - val_acc: 0.8038\n",
      "Epoch 520/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4271 - acc: 0.8093 - val_loss: 0.4497 - val_acc: 0.8008\n",
      "Epoch 521/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4263 - acc: 0.8085 - val_loss: 0.4449 - val_acc: 0.8046\n",
      "Epoch 522/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4272 - acc: 0.8120 - val_loss: 0.4471 - val_acc: 0.8019\n",
      "Epoch 523/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4263 - acc: 0.8111 - val_loss: 0.4445 - val_acc: 0.8035\n",
      "Epoch 524/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4268 - acc: 0.8085 - val_loss: 0.4475 - val_acc: 0.8025\n",
      "Epoch 525/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4273 - acc: 0.8088 - val_loss: 0.4480 - val_acc: 0.8007\n",
      "Epoch 526/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4283 - acc: 0.8086 - val_loss: 0.4452 - val_acc: 0.8033\n",
      "Epoch 527/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4273 - acc: 0.8095 - val_loss: 0.4474 - val_acc: 0.8011\n",
      "Epoch 528/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4262 - acc: 0.8086 - val_loss: 0.4527 - val_acc: 0.8000\n",
      "Epoch 529/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4269 - acc: 0.8108 - val_loss: 0.4447 - val_acc: 0.8043\n",
      "Epoch 530/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4268 - acc: 0.8094 - val_loss: 0.4446 - val_acc: 0.7992\n",
      "Epoch 531/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4267 - acc: 0.8106 - val_loss: 0.4448 - val_acc: 0.8018\n",
      "Epoch 532/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4262 - acc: 0.8101 - val_loss: 0.4428 - val_acc: 0.8037\n",
      "Epoch 533/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4266 - acc: 0.8096 - val_loss: 0.4457 - val_acc: 0.8004\n",
      "Epoch 534/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4261 - acc: 0.8111 - val_loss: 0.4473 - val_acc: 0.7997\n",
      "Epoch 535/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4263 - acc: 0.8079 - val_loss: 0.4472 - val_acc: 0.8019\n",
      "Epoch 536/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4269 - acc: 0.8096 - val_loss: 0.4460 - val_acc: 0.7990\n",
      "Epoch 537/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4262 - acc: 0.8091 - val_loss: 0.4459 - val_acc: 0.8015\n",
      "Epoch 538/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4268 - acc: 0.8086 - val_loss: 0.4459 - val_acc: 0.8014\n",
      "Epoch 539/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4272 - acc: 0.8095 - val_loss: 0.4447 - val_acc: 0.8016\n",
      "Epoch 540/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4275 - acc: 0.8094 - val_loss: 0.4481 - val_acc: 0.8004\n",
      "Epoch 541/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4274 - acc: 0.8098 - val_loss: 0.4450 - val_acc: 0.8020\n",
      "Epoch 542/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4265 - acc: 0.8093 - val_loss: 0.4444 - val_acc: 0.8044\n",
      "Epoch 543/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4268 - acc: 0.8097 - val_loss: 0.4552 - val_acc: 0.7950\n",
      "Epoch 544/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4260 - acc: 0.8112 - val_loss: 0.4475 - val_acc: 0.7989\n",
      "Epoch 545/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4263 - acc: 0.8077 - val_loss: 0.4464 - val_acc: 0.8010\n",
      "Epoch 546/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4268 - acc: 0.8087 - val_loss: 0.4446 - val_acc: 0.8030\n",
      "Epoch 547/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4256 - acc: 0.8101 - val_loss: 0.4498 - val_acc: 0.7974\n",
      "Epoch 548/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4276 - acc: 0.8093 - val_loss: 0.4447 - val_acc: 0.8033\n",
      "Epoch 549/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4266 - acc: 0.8105 - val_loss: 0.4457 - val_acc: 0.7993\n",
      "Epoch 550/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4261 - acc: 0.8113 - val_loss: 0.4490 - val_acc: 0.7975\n",
      "Epoch 551/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4268 - acc: 0.8117 - val_loss: 0.4473 - val_acc: 0.8011\n",
      "Epoch 552/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4261 - acc: 0.8101 - val_loss: 0.4475 - val_acc: 0.8002\n",
      "Epoch 553/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4279 - acc: 0.8082 - val_loss: 0.4448 - val_acc: 0.8026\n",
      "Epoch 554/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4260 - acc: 0.8114 - val_loss: 0.4461 - val_acc: 0.8015\n",
      "Epoch 555/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4270 - acc: 0.8103 - val_loss: 0.4451 - val_acc: 0.7995\n",
      "Epoch 556/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4267 - acc: 0.8101 - val_loss: 0.4448 - val_acc: 0.8015\n",
      "Epoch 557/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4268 - acc: 0.8093 - val_loss: 0.4463 - val_acc: 0.7999\n",
      "Epoch 558/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4263 - acc: 0.8114 - val_loss: 0.4490 - val_acc: 0.7980\n",
      "Epoch 559/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4262 - acc: 0.8089 - val_loss: 0.4461 - val_acc: 0.8027\n",
      "Epoch 560/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4258 - acc: 0.8117 - val_loss: 0.4466 - val_acc: 0.8001\n",
      "Epoch 561/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4257 - acc: 0.8082 - val_loss: 0.4463 - val_acc: 0.7980\n",
      "Epoch 562/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4265 - acc: 0.8093 - val_loss: 0.4448 - val_acc: 0.7992\n",
      "Epoch 563/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4265 - acc: 0.8110 - val_loss: 0.4506 - val_acc: 0.7986\n",
      "Epoch 564/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4269 - acc: 0.8089 - val_loss: 0.4443 - val_acc: 0.8001\n",
      "Epoch 565/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4263 - acc: 0.8087 - val_loss: 0.4437 - val_acc: 0.8009\n",
      "Epoch 566/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4263 - acc: 0.8104 - val_loss: 0.4455 - val_acc: 0.8008\n",
      "Epoch 567/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4260 - acc: 0.8094 - val_loss: 0.4440 - val_acc: 0.8007\n",
      "Epoch 568/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4265 - acc: 0.8097 - val_loss: 0.4461 - val_acc: 0.8021\n",
      "Epoch 569/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4256 - acc: 0.8097 - val_loss: 0.4462 - val_acc: 0.8001\n",
      "Epoch 570/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4251 - acc: 0.8099 - val_loss: 0.4473 - val_acc: 0.8010\n",
      "Epoch 571/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4271 - acc: 0.8097 - val_loss: 0.4530 - val_acc: 0.7981\n",
      "Epoch 572/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4264 - acc: 0.8121 - val_loss: 0.4538 - val_acc: 0.7975\n",
      "Epoch 573/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4260 - acc: 0.8082 - val_loss: 0.4451 - val_acc: 0.8005\n",
      "Epoch 574/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4260 - acc: 0.8084 - val_loss: 0.4466 - val_acc: 0.8032\n",
      "Epoch 575/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4258 - acc: 0.8108 - val_loss: 0.4581 - val_acc: 0.7940\n",
      "Epoch 576/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4265 - acc: 0.8089 - val_loss: 0.4471 - val_acc: 0.7988\n",
      "Epoch 577/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4262 - acc: 0.8105 - val_loss: 0.4460 - val_acc: 0.8024\n",
      "Epoch 578/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4264 - acc: 0.8084 - val_loss: 0.4470 - val_acc: 0.8001\n",
      "Epoch 579/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4256 - acc: 0.8105 - val_loss: 0.4466 - val_acc: 0.8001\n",
      "Epoch 580/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4253 - acc: 0.8105 - val_loss: 0.4466 - val_acc: 0.8001\n",
      "Epoch 581/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4262 - acc: 0.8090 - val_loss: 0.4448 - val_acc: 0.8028\n",
      "Epoch 582/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4259 - acc: 0.8100 - val_loss: 0.4446 - val_acc: 0.7995\n",
      "Epoch 583/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4262 - acc: 0.8104 - val_loss: 0.4449 - val_acc: 0.8030\n",
      "Epoch 584/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4266 - acc: 0.8119 - val_loss: 0.4513 - val_acc: 0.7972\n",
      "Epoch 585/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4245 - acc: 0.8122 - val_loss: 0.4489 - val_acc: 0.7982\n",
      "Epoch 586/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4258 - acc: 0.8119 - val_loss: 0.4595 - val_acc: 0.7903\n",
      "Epoch 587/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4267 - acc: 0.8110 - val_loss: 0.4450 - val_acc: 0.8010\n",
      "Epoch 588/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4262 - acc: 0.8094 - val_loss: 0.4430 - val_acc: 0.8013\n",
      "Epoch 589/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4258 - acc: 0.8093 - val_loss: 0.4481 - val_acc: 0.7982\n",
      "Epoch 590/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4258 - acc: 0.8100 - val_loss: 0.4489 - val_acc: 0.8018\n",
      "Epoch 591/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4251 - acc: 0.8106 - val_loss: 0.4495 - val_acc: 0.7977\n",
      "Epoch 592/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4263 - acc: 0.8107 - val_loss: 0.4452 - val_acc: 0.8016\n",
      "Epoch 593/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4262 - acc: 0.8108 - val_loss: 0.4453 - val_acc: 0.7984\n",
      "Epoch 594/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4265 - acc: 0.8100 - val_loss: 0.4441 - val_acc: 0.8013\n",
      "Epoch 595/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4260 - acc: 0.8105 - val_loss: 0.4450 - val_acc: 0.8015\n",
      "Epoch 596/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4259 - acc: 0.8097 - val_loss: 0.4461 - val_acc: 0.8016\n",
      "Epoch 597/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4251 - acc: 0.8108 - val_loss: 0.4446 - val_acc: 0.8022\n",
      "Epoch 598/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4257 - acc: 0.8100 - val_loss: 0.4445 - val_acc: 0.8014\n",
      "Epoch 599/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4255 - acc: 0.8110 - val_loss: 0.4455 - val_acc: 0.7999\n",
      "Epoch 600/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4258 - acc: 0.8084 - val_loss: 0.4466 - val_acc: 0.7990\n",
      "Epoch 601/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4250 - acc: 0.8108 - val_loss: 0.4472 - val_acc: 0.8000\n",
      "Epoch 602/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4261 - acc: 0.8097 - val_loss: 0.4471 - val_acc: 0.7998\n",
      "Epoch 603/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4253 - acc: 0.8096 - val_loss: 0.4495 - val_acc: 0.8024\n",
      "Epoch 604/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4257 - acc: 0.8096 - val_loss: 0.4514 - val_acc: 0.7967\n",
      "Epoch 605/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4257 - acc: 0.8113 - val_loss: 0.4476 - val_acc: 0.7998\n",
      "Epoch 606/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4250 - acc: 0.8106 - val_loss: 0.4470 - val_acc: 0.8003\n",
      "Epoch 607/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4260 - acc: 0.8110 - val_loss: 0.4454 - val_acc: 0.7981\n",
      "Epoch 608/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4254 - acc: 0.8102 - val_loss: 0.4558 - val_acc: 0.7972\n",
      "Epoch 609/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4254 - acc: 0.8095 - val_loss: 0.4475 - val_acc: 0.7999\n",
      "Epoch 610/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4244 - acc: 0.8138 - val_loss: 0.4503 - val_acc: 0.7975\n",
      "Epoch 611/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4254 - acc: 0.8116 - val_loss: 0.4453 - val_acc: 0.8030\n",
      "Epoch 612/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4244 - acc: 0.8098 - val_loss: 0.4473 - val_acc: 0.8010\n",
      "Epoch 613/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4259 - acc: 0.8101 - val_loss: 0.4463 - val_acc: 0.8003\n",
      "Epoch 614/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4250 - acc: 0.8085 - val_loss: 0.4471 - val_acc: 0.8001\n",
      "Epoch 615/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4254 - acc: 0.8119 - val_loss: 0.4450 - val_acc: 0.8002\n",
      "Epoch 616/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4252 - acc: 0.8106 - val_loss: 0.4469 - val_acc: 0.8013\n",
      "Epoch 617/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4255 - acc: 0.8113 - val_loss: 0.4476 - val_acc: 0.7985\n",
      "Epoch 618/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4259 - acc: 0.8103 - val_loss: 0.4443 - val_acc: 0.8031\n",
      "Epoch 619/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4254 - acc: 0.8118 - val_loss: 0.4469 - val_acc: 0.8008\n",
      "Epoch 620/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4247 - acc: 0.8116 - val_loss: 0.4447 - val_acc: 0.8034\n",
      "Epoch 621/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4253 - acc: 0.8110 - val_loss: 0.4448 - val_acc: 0.8018\n",
      "Epoch 622/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4251 - acc: 0.8091 - val_loss: 0.4491 - val_acc: 0.7958\n",
      "Epoch 623/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4244 - acc: 0.8099 - val_loss: 0.4459 - val_acc: 0.7989\n",
      "Epoch 624/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4251 - acc: 0.8119 - val_loss: 0.4484 - val_acc: 0.8027\n",
      "Epoch 625/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4247 - acc: 0.8107 - val_loss: 0.4540 - val_acc: 0.7968\n",
      "Epoch 626/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4243 - acc: 0.8116 - val_loss: 0.4491 - val_acc: 0.7999\n",
      "Epoch 627/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4249 - acc: 0.8104 - val_loss: 0.4481 - val_acc: 0.7998\n",
      "Epoch 628/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4253 - acc: 0.8102 - val_loss: 0.4471 - val_acc: 0.8008\n",
      "Epoch 629/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4252 - acc: 0.8102 - val_loss: 0.4450 - val_acc: 0.8009\n",
      "Epoch 630/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4269 - acc: 0.8102 - val_loss: 0.4459 - val_acc: 0.8016\n",
      "Epoch 631/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4251 - acc: 0.8120 - val_loss: 0.4454 - val_acc: 0.8015\n",
      "Epoch 632/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4261 - acc: 0.8100 - val_loss: 0.4461 - val_acc: 0.8005\n",
      "Epoch 633/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4245 - acc: 0.8104 - val_loss: 0.4445 - val_acc: 0.8019\n",
      "Epoch 634/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4251 - acc: 0.8102 - val_loss: 0.4524 - val_acc: 0.8000\n",
      "Epoch 635/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4247 - acc: 0.8100 - val_loss: 0.4417 - val_acc: 0.8025\n",
      "Epoch 636/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4240 - acc: 0.8115 - val_loss: 0.4469 - val_acc: 0.7990\n",
      "Epoch 637/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4246 - acc: 0.8120 - val_loss: 0.4450 - val_acc: 0.8020\n",
      "Epoch 638/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4239 - acc: 0.8114 - val_loss: 0.4454 - val_acc: 0.8031\n",
      "Epoch 639/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4244 - acc: 0.8123 - val_loss: 0.4450 - val_acc: 0.8008\n",
      "Epoch 640/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4239 - acc: 0.8119 - val_loss: 0.4463 - val_acc: 0.7992\n",
      "Epoch 641/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4252 - acc: 0.8098 - val_loss: 0.4513 - val_acc: 0.7969\n",
      "Epoch 642/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4244 - acc: 0.8107 - val_loss: 0.4462 - val_acc: 0.8016\n",
      "Epoch 643/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4249 - acc: 0.8112 - val_loss: 0.4443 - val_acc: 0.8004\n",
      "Epoch 644/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4259 - acc: 0.8106 - val_loss: 0.4454 - val_acc: 0.8031\n",
      "Epoch 645/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4249 - acc: 0.8102 - val_loss: 0.4456 - val_acc: 0.7995\n",
      "Epoch 646/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4249 - acc: 0.8104 - val_loss: 0.4432 - val_acc: 0.8016\n",
      "Epoch 647/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4246 - acc: 0.8109 - val_loss: 0.4464 - val_acc: 0.8004\n",
      "Epoch 648/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4247 - acc: 0.8106 - val_loss: 0.4449 - val_acc: 0.8010\n",
      "Epoch 649/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4249 - acc: 0.8107 - val_loss: 0.4450 - val_acc: 0.8022\n",
      "Epoch 650/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4246 - acc: 0.8125 - val_loss: 0.4481 - val_acc: 0.7989\n",
      "Epoch 651/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4249 - acc: 0.8115 - val_loss: 0.4500 - val_acc: 0.7978\n",
      "Epoch 652/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4258 - acc: 0.8097 - val_loss: 0.4493 - val_acc: 0.7988\n",
      "Epoch 653/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4248 - acc: 0.8123 - val_loss: 0.4452 - val_acc: 0.7999\n",
      "Epoch 654/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4254 - acc: 0.8116 - val_loss: 0.4447 - val_acc: 0.8032\n",
      "Epoch 655/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4240 - acc: 0.8117 - val_loss: 0.4458 - val_acc: 0.7999\n",
      "Epoch 656/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4246 - acc: 0.8117 - val_loss: 0.4446 - val_acc: 0.8005\n",
      "Epoch 657/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4245 - acc: 0.8115 - val_loss: 0.4445 - val_acc: 0.8020\n",
      "Epoch 658/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4243 - acc: 0.8128 - val_loss: 0.4459 - val_acc: 0.8003\n",
      "Epoch 659/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4255 - acc: 0.8107 - val_loss: 0.4481 - val_acc: 0.7981\n",
      "Epoch 660/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4253 - acc: 0.8104 - val_loss: 0.4471 - val_acc: 0.8026\n",
      "Epoch 661/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4247 - acc: 0.8121 - val_loss: 0.4445 - val_acc: 0.8009\n",
      "Epoch 662/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4240 - acc: 0.8127 - val_loss: 0.4458 - val_acc: 0.8005\n",
      "Epoch 663/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4243 - acc: 0.8125 - val_loss: 0.4461 - val_acc: 0.8007\n",
      "Epoch 664/2000\n",
      "13834/13834 [==============================] - 0s 22us/step - loss: 0.4239 - acc: 0.8121 - val_loss: 0.4469 - val_acc: 0.8014\n",
      "Epoch 665/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4245 - acc: 0.8106 - val_loss: 0.4460 - val_acc: 0.8014\n",
      "Epoch 666/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4239 - acc: 0.8112 - val_loss: 0.4460 - val_acc: 0.8001\n",
      "Epoch 667/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4251 - acc: 0.8111 - val_loss: 0.4444 - val_acc: 0.8007\n",
      "Epoch 668/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4243 - acc: 0.8122 - val_loss: 0.4478 - val_acc: 0.8012\n",
      "Epoch 669/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4248 - acc: 0.8123 - val_loss: 0.4440 - val_acc: 0.8019\n",
      "Epoch 670/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4247 - acc: 0.8121 - val_loss: 0.4460 - val_acc: 0.8007\n",
      "Epoch 671/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4245 - acc: 0.8129 - val_loss: 0.4481 - val_acc: 0.7979\n",
      "Epoch 672/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4244 - acc: 0.8103 - val_loss: 0.4511 - val_acc: 0.7980\n",
      "Epoch 673/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4252 - acc: 0.8101 - val_loss: 0.4486 - val_acc: 0.7980\n",
      "Epoch 674/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4243 - acc: 0.8129 - val_loss: 0.4497 - val_acc: 0.7992\n",
      "Epoch 675/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4259 - acc: 0.8129 - val_loss: 0.4459 - val_acc: 0.7998\n",
      "Epoch 676/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4249 - acc: 0.8088 - val_loss: 0.4444 - val_acc: 0.8002\n",
      "Epoch 677/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4236 - acc: 0.8111 - val_loss: 0.4448 - val_acc: 0.8004\n",
      "Epoch 678/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4246 - acc: 0.8112 - val_loss: 0.4436 - val_acc: 0.7999\n",
      "Epoch 679/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4241 - acc: 0.8123 - val_loss: 0.4461 - val_acc: 0.8014\n",
      "Epoch 680/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4243 - acc: 0.8116 - val_loss: 0.4451 - val_acc: 0.8013\n",
      "Epoch 681/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4241 - acc: 0.8095 - val_loss: 0.4470 - val_acc: 0.7979\n",
      "Epoch 682/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4243 - acc: 0.8108 - val_loss: 0.4458 - val_acc: 0.8023\n",
      "Epoch 683/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4239 - acc: 0.8100 - val_loss: 0.4472 - val_acc: 0.7999\n",
      "Epoch 684/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4237 - acc: 0.8123 - val_loss: 0.4458 - val_acc: 0.7993\n",
      "Epoch 685/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4250 - acc: 0.8119 - val_loss: 0.4451 - val_acc: 0.8022\n",
      "Epoch 686/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8125 - val_loss: 0.4426 - val_acc: 0.8016\n",
      "Epoch 687/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4241 - acc: 0.8114 - val_loss: 0.4462 - val_acc: 0.7995\n",
      "Epoch 688/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4248 - acc: 0.8115 - val_loss: 0.4464 - val_acc: 0.8007\n",
      "Epoch 689/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4234 - acc: 0.8129 - val_loss: 0.4467 - val_acc: 0.8002\n",
      "Epoch 690/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4248 - acc: 0.8109 - val_loss: 0.4503 - val_acc: 0.7976\n",
      "Epoch 691/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4246 - acc: 0.8111 - val_loss: 0.4494 - val_acc: 0.7991\n",
      "Epoch 692/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4246 - acc: 0.8130 - val_loss: 0.4471 - val_acc: 0.7996\n",
      "Epoch 693/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4260 - acc: 0.8105 - val_loss: 0.4451 - val_acc: 0.8024\n",
      "Epoch 694/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4248 - acc: 0.8112 - val_loss: 0.4459 - val_acc: 0.8018\n",
      "Epoch 695/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4240 - acc: 0.8110 - val_loss: 0.4444 - val_acc: 0.8015\n",
      "Epoch 696/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8130 - val_loss: 0.4447 - val_acc: 0.8026\n",
      "Epoch 697/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4247 - acc: 0.8098 - val_loss: 0.4473 - val_acc: 0.7992\n",
      "Epoch 698/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4248 - acc: 0.8105 - val_loss: 0.4459 - val_acc: 0.8035\n",
      "Epoch 699/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4243 - acc: 0.8119 - val_loss: 0.4454 - val_acc: 0.8018\n",
      "Epoch 700/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4236 - acc: 0.8114 - val_loss: 0.4458 - val_acc: 0.7978\n",
      "Epoch 701/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4246 - acc: 0.8131 - val_loss: 0.4474 - val_acc: 0.7998\n",
      "Epoch 702/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4248 - acc: 0.8122 - val_loss: 0.4468 - val_acc: 0.8002\n",
      "Epoch 703/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4244 - acc: 0.8107 - val_loss: 0.4460 - val_acc: 0.8004\n",
      "Epoch 704/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4235 - acc: 0.8119 - val_loss: 0.4448 - val_acc: 0.7998\n",
      "Epoch 705/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4229 - acc: 0.8111 - val_loss: 0.4446 - val_acc: 0.8002\n",
      "Epoch 706/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4242 - acc: 0.8118 - val_loss: 0.4431 - val_acc: 0.8014\n",
      "Epoch 707/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4242 - acc: 0.8118 - val_loss: 0.4455 - val_acc: 0.7996\n",
      "Epoch 708/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4246 - acc: 0.8116 - val_loss: 0.4453 - val_acc: 0.8007\n",
      "Epoch 709/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4232 - acc: 0.8139 - val_loss: 0.4444 - val_acc: 0.8010\n",
      "Epoch 710/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4242 - acc: 0.8107 - val_loss: 0.4456 - val_acc: 0.8019\n",
      "Epoch 711/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4241 - acc: 0.8119 - val_loss: 0.4450 - val_acc: 0.8003\n",
      "Epoch 712/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4243 - acc: 0.8103 - val_loss: 0.4468 - val_acc: 0.8004\n",
      "Epoch 713/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4239 - acc: 0.8099 - val_loss: 0.4457 - val_acc: 0.8028\n",
      "Epoch 714/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4250 - acc: 0.8108 - val_loss: 0.4474 - val_acc: 0.8020\n",
      "Epoch 715/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8120 - val_loss: 0.4442 - val_acc: 0.8028\n",
      "Epoch 716/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4248 - acc: 0.8106 - val_loss: 0.4451 - val_acc: 0.8026\n",
      "Epoch 717/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4242 - acc: 0.8114 - val_loss: 0.4462 - val_acc: 0.7980\n",
      "Epoch 718/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4245 - acc: 0.8118 - val_loss: 0.4494 - val_acc: 0.7979\n",
      "Epoch 719/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4239 - acc: 0.8118 - val_loss: 0.4447 - val_acc: 0.8000\n",
      "Epoch 720/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4248 - acc: 0.8104 - val_loss: 0.4466 - val_acc: 0.7997\n",
      "Epoch 721/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8129 - val_loss: 0.4434 - val_acc: 0.8014\n",
      "Epoch 722/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4231 - acc: 0.8129 - val_loss: 0.4460 - val_acc: 0.7990\n",
      "Epoch 723/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8112 - val_loss: 0.4449 - val_acc: 0.8010\n",
      "Epoch 724/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4237 - acc: 0.8106 - val_loss: 0.4523 - val_acc: 0.7952\n",
      "Epoch 725/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8129 - val_loss: 0.4458 - val_acc: 0.8008\n",
      "Epoch 726/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4235 - acc: 0.8116 - val_loss: 0.4464 - val_acc: 0.8011\n",
      "Epoch 727/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8114 - val_loss: 0.4455 - val_acc: 0.8024\n",
      "Epoch 728/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4233 - acc: 0.8099 - val_loss: 0.4457 - val_acc: 0.7999\n",
      "Epoch 729/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4246 - acc: 0.8131 - val_loss: 0.4442 - val_acc: 0.7991\n",
      "Epoch 730/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8118 - val_loss: 0.4452 - val_acc: 0.8005\n",
      "Epoch 731/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4242 - acc: 0.8123 - val_loss: 0.4461 - val_acc: 0.7993\n",
      "Epoch 732/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4233 - acc: 0.8131 - val_loss: 0.4448 - val_acc: 0.8010\n",
      "Epoch 733/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4252 - acc: 0.8129 - val_loss: 0.4455 - val_acc: 0.8009\n",
      "Epoch 734/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8114 - val_loss: 0.4458 - val_acc: 0.7990\n",
      "Epoch 735/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4240 - acc: 0.8124 - val_loss: 0.4465 - val_acc: 0.7993\n",
      "Epoch 736/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4240 - acc: 0.8102 - val_loss: 0.4457 - val_acc: 0.8003\n",
      "Epoch 737/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8125 - val_loss: 0.4451 - val_acc: 0.8009\n",
      "Epoch 738/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4241 - acc: 0.8117 - val_loss: 0.4448 - val_acc: 0.7996\n",
      "Epoch 739/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4249 - acc: 0.8123 - val_loss: 0.4446 - val_acc: 0.8012\n",
      "Epoch 740/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4242 - acc: 0.8112 - val_loss: 0.4446 - val_acc: 0.8026\n",
      "Epoch 741/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4237 - acc: 0.8119 - val_loss: 0.4496 - val_acc: 0.7995\n",
      "Epoch 742/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8122 - val_loss: 0.4521 - val_acc: 0.7968\n",
      "Epoch 743/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4241 - acc: 0.8111 - val_loss: 0.4480 - val_acc: 0.8010\n",
      "Epoch 744/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4238 - acc: 0.8123 - val_loss: 0.4479 - val_acc: 0.8002\n",
      "Epoch 745/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8135 - val_loss: 0.4460 - val_acc: 0.8005\n",
      "Epoch 746/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8121 - val_loss: 0.4449 - val_acc: 0.8012\n",
      "Epoch 747/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4246 - acc: 0.8106 - val_loss: 0.4445 - val_acc: 0.8019\n",
      "Epoch 748/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4242 - acc: 0.8108 - val_loss: 0.4441 - val_acc: 0.8011\n",
      "Epoch 749/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4241 - acc: 0.8130 - val_loss: 0.4483 - val_acc: 0.7984\n",
      "Epoch 750/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4244 - acc: 0.8123 - val_loss: 0.4433 - val_acc: 0.8015\n",
      "Epoch 751/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4236 - acc: 0.8128 - val_loss: 0.4441 - val_acc: 0.8015\n",
      "Epoch 752/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4240 - acc: 0.8119 - val_loss: 0.4443 - val_acc: 0.8025\n",
      "Epoch 753/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8105 - val_loss: 0.4510 - val_acc: 0.7985\n",
      "Epoch 754/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8135 - val_loss: 0.4473 - val_acc: 0.8003\n",
      "Epoch 755/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4240 - acc: 0.8111 - val_loss: 0.4459 - val_acc: 0.8005\n",
      "Epoch 756/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4237 - acc: 0.8121 - val_loss: 0.4449 - val_acc: 0.8004\n",
      "Epoch 757/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8130 - val_loss: 0.4456 - val_acc: 0.8005\n",
      "Epoch 758/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4246 - acc: 0.8103 - val_loss: 0.4464 - val_acc: 0.8012\n",
      "Epoch 759/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4240 - acc: 0.8103 - val_loss: 0.4489 - val_acc: 0.7980\n",
      "Epoch 760/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4260 - acc: 0.8105 - val_loss: 0.4450 - val_acc: 0.8012\n",
      "Epoch 761/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4236 - acc: 0.8131 - val_loss: 0.4476 - val_acc: 0.8000\n",
      "Epoch 762/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4230 - acc: 0.8116 - val_loss: 0.4532 - val_acc: 0.7963\n",
      "Epoch 763/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8127 - val_loss: 0.4488 - val_acc: 0.7986\n",
      "Epoch 764/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8115 - val_loss: 0.4437 - val_acc: 0.8028\n",
      "Epoch 765/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8121 - val_loss: 0.4437 - val_acc: 0.8019\n",
      "Epoch 766/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8125 - val_loss: 0.4476 - val_acc: 0.8031\n",
      "Epoch 767/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8122 - val_loss: 0.4463 - val_acc: 0.8003\n",
      "Epoch 768/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4240 - acc: 0.8114 - val_loss: 0.4465 - val_acc: 0.8009\n",
      "Epoch 769/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4244 - acc: 0.8121 - val_loss: 0.4448 - val_acc: 0.8000\n",
      "Epoch 770/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8121 - val_loss: 0.4454 - val_acc: 0.7998\n",
      "Epoch 771/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4237 - acc: 0.8100 - val_loss: 0.4459 - val_acc: 0.8002\n",
      "Epoch 772/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4241 - acc: 0.8113 - val_loss: 0.4452 - val_acc: 0.8014\n",
      "Epoch 773/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8128 - val_loss: 0.4451 - val_acc: 0.8018\n",
      "Epoch 774/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8107 - val_loss: 0.4449 - val_acc: 0.8004\n",
      "Epoch 775/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4241 - acc: 0.8124 - val_loss: 0.4487 - val_acc: 0.7998\n",
      "Epoch 776/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8101 - val_loss: 0.4462 - val_acc: 0.8031\n",
      "Epoch 777/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4232 - acc: 0.8126 - val_loss: 0.4489 - val_acc: 0.7981\n",
      "Epoch 778/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4239 - acc: 0.8120 - val_loss: 0.4457 - val_acc: 0.7998\n",
      "Epoch 779/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8121 - val_loss: 0.4460 - val_acc: 0.8001\n",
      "Epoch 780/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4227 - acc: 0.8115 - val_loss: 0.4460 - val_acc: 0.7997\n",
      "Epoch 781/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4239 - acc: 0.8128 - val_loss: 0.4465 - val_acc: 0.7982\n",
      "Epoch 782/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4232 - acc: 0.8122 - val_loss: 0.4480 - val_acc: 0.7992\n",
      "Epoch 783/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4241 - acc: 0.8120 - val_loss: 0.4450 - val_acc: 0.8031\n",
      "Epoch 784/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4247 - acc: 0.8100 - val_loss: 0.4446 - val_acc: 0.8012\n",
      "Epoch 785/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4236 - acc: 0.8121 - val_loss: 0.4504 - val_acc: 0.7985\n",
      "Epoch 786/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4246 - acc: 0.8122 - val_loss: 0.4456 - val_acc: 0.8013\n",
      "Epoch 787/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4239 - acc: 0.8118 - val_loss: 0.4446 - val_acc: 0.8028\n",
      "Epoch 788/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8126 - val_loss: 0.4483 - val_acc: 0.8001\n",
      "Epoch 789/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4246 - acc: 0.8112 - val_loss: 0.4449 - val_acc: 0.8018\n",
      "Epoch 790/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4229 - acc: 0.8127 - val_loss: 0.4471 - val_acc: 0.8023\n",
      "Epoch 791/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4237 - acc: 0.8116 - val_loss: 0.4451 - val_acc: 0.8031\n",
      "Epoch 792/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8118 - val_loss: 0.4494 - val_acc: 0.7991\n",
      "Epoch 793/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4238 - acc: 0.8113 - val_loss: 0.4462 - val_acc: 0.8016\n",
      "Epoch 794/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4234 - acc: 0.8120 - val_loss: 0.4464 - val_acc: 0.8008\n",
      "Epoch 795/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4235 - acc: 0.8122 - val_loss: 0.4493 - val_acc: 0.8004\n",
      "Epoch 796/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4240 - acc: 0.8103 - val_loss: 0.4463 - val_acc: 0.8013\n",
      "Epoch 797/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4229 - acc: 0.8133 - val_loss: 0.4478 - val_acc: 0.8004\n",
      "Epoch 798/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8116 - val_loss: 0.4462 - val_acc: 0.8001\n",
      "Epoch 799/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4237 - acc: 0.8118 - val_loss: 0.4486 - val_acc: 0.8004\n",
      "Epoch 800/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4230 - acc: 0.8127 - val_loss: 0.4436 - val_acc: 0.8007\n",
      "Epoch 801/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8125 - val_loss: 0.4455 - val_acc: 0.8007\n",
      "Epoch 802/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4224 - acc: 0.8116 - val_loss: 0.4468 - val_acc: 0.8007\n",
      "Epoch 803/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8117 - val_loss: 0.4457 - val_acc: 0.8022\n",
      "Epoch 804/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4245 - acc: 0.8096 - val_loss: 0.4504 - val_acc: 0.7984\n",
      "Epoch 805/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4232 - acc: 0.8133 - val_loss: 0.4480 - val_acc: 0.8005\n",
      "Epoch 806/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4235 - acc: 0.8138 - val_loss: 0.4441 - val_acc: 0.8022\n",
      "Epoch 807/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4235 - acc: 0.8107 - val_loss: 0.4457 - val_acc: 0.8008\n",
      "Epoch 808/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4230 - acc: 0.8125 - val_loss: 0.4460 - val_acc: 0.8007\n",
      "Epoch 809/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4224 - acc: 0.8112 - val_loss: 0.4458 - val_acc: 0.7993\n",
      "Epoch 810/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4244 - acc: 0.8106 - val_loss: 0.4457 - val_acc: 0.8040\n",
      "Epoch 811/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4240 - acc: 0.8108 - val_loss: 0.4445 - val_acc: 0.8000\n",
      "Epoch 812/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8092 - val_loss: 0.4432 - val_acc: 0.8005\n",
      "Epoch 813/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4244 - acc: 0.8110 - val_loss: 0.4478 - val_acc: 0.8023\n",
      "Epoch 814/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8138 - val_loss: 0.4455 - val_acc: 0.8005\n",
      "Epoch 815/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8134 - val_loss: 0.4455 - val_acc: 0.8008\n",
      "Epoch 816/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4232 - acc: 0.8121 - val_loss: 0.4512 - val_acc: 0.7978\n",
      "Epoch 817/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4245 - acc: 0.8118 - val_loss: 0.4439 - val_acc: 0.8026\n",
      "Epoch 818/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4229 - acc: 0.8108 - val_loss: 0.4464 - val_acc: 0.8023\n",
      "Epoch 819/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8123 - val_loss: 0.4526 - val_acc: 0.7964\n",
      "Epoch 820/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8119 - val_loss: 0.4442 - val_acc: 0.8007\n",
      "Epoch 821/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4244 - acc: 0.8099 - val_loss: 0.4459 - val_acc: 0.8014\n",
      "Epoch 822/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4227 - acc: 0.8113 - val_loss: 0.4461 - val_acc: 0.8009\n",
      "Epoch 823/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4234 - acc: 0.8128 - val_loss: 0.4472 - val_acc: 0.8013\n",
      "Epoch 824/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4236 - acc: 0.8117 - val_loss: 0.4455 - val_acc: 0.7998\n",
      "Epoch 825/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4232 - acc: 0.8124 - val_loss: 0.4481 - val_acc: 0.7981\n",
      "Epoch 826/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4239 - acc: 0.8099 - val_loss: 0.4453 - val_acc: 0.8010\n",
      "Epoch 827/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8125 - val_loss: 0.4491 - val_acc: 0.8009\n",
      "Epoch 828/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4240 - acc: 0.8114 - val_loss: 0.4461 - val_acc: 0.8016\n",
      "Epoch 829/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8120 - val_loss: 0.4479 - val_acc: 0.8007\n",
      "Epoch 830/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8119 - val_loss: 0.4466 - val_acc: 0.7996\n",
      "Epoch 831/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4238 - acc: 0.8122 - val_loss: 0.4438 - val_acc: 0.8021\n",
      "Epoch 832/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8117 - val_loss: 0.4469 - val_acc: 0.8007\n",
      "Epoch 833/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4243 - acc: 0.8100 - val_loss: 0.4512 - val_acc: 0.7977\n",
      "Epoch 834/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4231 - acc: 0.8118 - val_loss: 0.4453 - val_acc: 0.8004\n",
      "Epoch 835/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4226 - acc: 0.8125 - val_loss: 0.4446 - val_acc: 0.8019\n",
      "Epoch 836/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8122 - val_loss: 0.4523 - val_acc: 0.7982\n",
      "Epoch 837/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8127 - val_loss: 0.4447 - val_acc: 0.8024\n",
      "Epoch 838/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8127 - val_loss: 0.4469 - val_acc: 0.8013\n",
      "Epoch 839/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8117 - val_loss: 0.4444 - val_acc: 0.8045\n",
      "Epoch 840/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4231 - acc: 0.8131 - val_loss: 0.4441 - val_acc: 0.8011\n",
      "Epoch 841/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8129 - val_loss: 0.4446 - val_acc: 0.8004\n",
      "Epoch 842/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4223 - acc: 0.8109 - val_loss: 0.4443 - val_acc: 0.8021\n",
      "Epoch 843/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4241 - acc: 0.8131 - val_loss: 0.4449 - val_acc: 0.8015\n",
      "Epoch 844/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4243 - acc: 0.8113 - val_loss: 0.4445 - val_acc: 0.8015\n",
      "Epoch 845/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8114 - val_loss: 0.4469 - val_acc: 0.8014\n",
      "Epoch 846/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8111 - val_loss: 0.4487 - val_acc: 0.7989\n",
      "Epoch 847/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4232 - acc: 0.8123 - val_loss: 0.4449 - val_acc: 0.8000\n",
      "Epoch 848/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4242 - acc: 0.8109 - val_loss: 0.4453 - val_acc: 0.8009\n",
      "Epoch 849/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4223 - acc: 0.8130 - val_loss: 0.4525 - val_acc: 0.7975\n",
      "Epoch 850/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8131 - val_loss: 0.4433 - val_acc: 0.8022\n",
      "Epoch 851/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4237 - acc: 0.8118 - val_loss: 0.4464 - val_acc: 0.8012\n",
      "Epoch 852/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8114 - val_loss: 0.4466 - val_acc: 0.7960\n",
      "Epoch 853/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4237 - acc: 0.8114 - val_loss: 0.4473 - val_acc: 0.7993\n",
      "Epoch 854/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4225 - acc: 0.8126 - val_loss: 0.4442 - val_acc: 0.7997\n",
      "Epoch 855/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8117 - val_loss: 0.4496 - val_acc: 0.7967\n",
      "Epoch 856/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4232 - acc: 0.8112 - val_loss: 0.4457 - val_acc: 0.8008\n",
      "Epoch 857/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8119 - val_loss: 0.4460 - val_acc: 0.8033\n",
      "Epoch 858/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4241 - acc: 0.8117 - val_loss: 0.4438 - val_acc: 0.8004\n",
      "Epoch 859/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4243 - acc: 0.8109 - val_loss: 0.4443 - val_acc: 0.8035\n",
      "Epoch 860/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4231 - acc: 0.8112 - val_loss: 0.4458 - val_acc: 0.8002\n",
      "Epoch 861/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4238 - acc: 0.8109 - val_loss: 0.4517 - val_acc: 0.7976\n",
      "Epoch 862/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4231 - acc: 0.8132 - val_loss: 0.4504 - val_acc: 0.7952\n",
      "Epoch 863/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4240 - acc: 0.8116 - val_loss: 0.4455 - val_acc: 0.8015\n",
      "Epoch 864/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4224 - acc: 0.8127 - val_loss: 0.4521 - val_acc: 0.7985\n",
      "Epoch 865/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4230 - acc: 0.8129 - val_loss: 0.4462 - val_acc: 0.8009\n",
      "Epoch 866/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4238 - acc: 0.8128 - val_loss: 0.4457 - val_acc: 0.8018\n",
      "Epoch 867/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4234 - acc: 0.8122 - val_loss: 0.4456 - val_acc: 0.7980\n",
      "Epoch 868/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8122 - val_loss: 0.4466 - val_acc: 0.8045\n",
      "Epoch 869/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4227 - acc: 0.8125 - val_loss: 0.4481 - val_acc: 0.7969\n",
      "Epoch 870/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4232 - acc: 0.8115 - val_loss: 0.4455 - val_acc: 0.8000\n",
      "Epoch 871/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4238 - acc: 0.8109 - val_loss: 0.4472 - val_acc: 0.8019\n",
      "Epoch 872/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4237 - acc: 0.8113 - val_loss: 0.4470 - val_acc: 0.8007\n",
      "Epoch 873/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4230 - acc: 0.8127 - val_loss: 0.4448 - val_acc: 0.8021\n",
      "Epoch 874/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4227 - acc: 0.8110 - val_loss: 0.4448 - val_acc: 0.8043\n",
      "Epoch 875/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4239 - acc: 0.8121 - val_loss: 0.4465 - val_acc: 0.8012\n",
      "Epoch 876/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4242 - acc: 0.8129 - val_loss: 0.4459 - val_acc: 0.8007\n",
      "Epoch 877/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4241 - acc: 0.8100 - val_loss: 0.4436 - val_acc: 0.8008\n",
      "Epoch 878/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4233 - acc: 0.8108 - val_loss: 0.4467 - val_acc: 0.7997\n",
      "Epoch 879/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4231 - acc: 0.8125 - val_loss: 0.4473 - val_acc: 0.7991\n",
      "Epoch 880/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8099 - val_loss: 0.4472 - val_acc: 0.7987\n",
      "Epoch 881/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8112 - val_loss: 0.4446 - val_acc: 0.8026\n",
      "Epoch 882/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4228 - acc: 0.8102 - val_loss: 0.4455 - val_acc: 0.8035\n",
      "Epoch 883/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4238 - acc: 0.8111 - val_loss: 0.4473 - val_acc: 0.8008\n",
      "Epoch 884/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4230 - acc: 0.8107 - val_loss: 0.4439 - val_acc: 0.7998\n",
      "Epoch 885/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4236 - acc: 0.8101 - val_loss: 0.4433 - val_acc: 0.8007\n",
      "Epoch 886/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4238 - acc: 0.8127 - val_loss: 0.4459 - val_acc: 0.8022\n",
      "Epoch 887/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8119 - val_loss: 0.4481 - val_acc: 0.8011\n",
      "Epoch 888/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4246 - acc: 0.8098 - val_loss: 0.4468 - val_acc: 0.8013\n",
      "Epoch 889/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4230 - acc: 0.8116 - val_loss: 0.4467 - val_acc: 0.8013\n",
      "Epoch 890/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4223 - acc: 0.8131 - val_loss: 0.4589 - val_acc: 0.7954\n",
      "Epoch 891/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4225 - acc: 0.8123 - val_loss: 0.4495 - val_acc: 0.7996\n",
      "Epoch 892/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4229 - acc: 0.8122 - val_loss: 0.4425 - val_acc: 0.8018\n",
      "Epoch 893/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8130 - val_loss: 0.4452 - val_acc: 0.7976\n",
      "Epoch 894/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4242 - acc: 0.8115 - val_loss: 0.4448 - val_acc: 0.7998\n",
      "Epoch 895/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4233 - acc: 0.8121 - val_loss: 0.4452 - val_acc: 0.8013\n",
      "Epoch 896/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4233 - acc: 0.8122 - val_loss: 0.4463 - val_acc: 0.7999\n",
      "Epoch 897/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8102 - val_loss: 0.4445 - val_acc: 0.8009\n",
      "Epoch 898/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4248 - acc: 0.8108 - val_loss: 0.4466 - val_acc: 0.7984\n",
      "Epoch 899/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4234 - acc: 0.8117 - val_loss: 0.4517 - val_acc: 0.7950\n",
      "Epoch 900/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8114 - val_loss: 0.4466 - val_acc: 0.7985\n",
      "Epoch 901/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4230 - acc: 0.8103 - val_loss: 0.4430 - val_acc: 0.8026\n",
      "Epoch 902/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4232 - acc: 0.8135 - val_loss: 0.4454 - val_acc: 0.7974\n",
      "Epoch 903/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4229 - acc: 0.8127 - val_loss: 0.4534 - val_acc: 0.7950\n",
      "Epoch 904/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4230 - acc: 0.8108 - val_loss: 0.4435 - val_acc: 0.8011\n",
      "Epoch 905/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4236 - acc: 0.8120 - val_loss: 0.4435 - val_acc: 0.8021\n",
      "Epoch 906/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4232 - acc: 0.8126 - val_loss: 0.4431 - val_acc: 0.8016\n",
      "Epoch 907/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4251 - acc: 0.8114 - val_loss: 0.4458 - val_acc: 0.8004\n",
      "Epoch 908/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4239 - acc: 0.8121 - val_loss: 0.4498 - val_acc: 0.7982\n",
      "Epoch 909/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4242 - acc: 0.8132 - val_loss: 0.4452 - val_acc: 0.8009\n",
      "Epoch 910/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4243 - acc: 0.8121 - val_loss: 0.4449 - val_acc: 0.8002\n",
      "Epoch 911/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4239 - acc: 0.8105 - val_loss: 0.4435 - val_acc: 0.8020\n",
      "Epoch 912/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4242 - acc: 0.8116 - val_loss: 0.4461 - val_acc: 0.8012\n",
      "Epoch 913/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4229 - acc: 0.8139 - val_loss: 0.4439 - val_acc: 0.8032\n",
      "Epoch 914/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4240 - acc: 0.8125 - val_loss: 0.4432 - val_acc: 0.8037\n",
      "Epoch 915/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4244 - acc: 0.8109 - val_loss: 0.4454 - val_acc: 0.8015\n",
      "Epoch 916/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4227 - acc: 0.8114 - val_loss: 0.4449 - val_acc: 0.8011\n",
      "Epoch 917/2000\n",
      "13834/13834 [==============================] - 0s 29us/step - loss: 0.4231 - acc: 0.8123 - val_loss: 0.4481 - val_acc: 0.7993\n",
      "Epoch 918/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4229 - acc: 0.8119 - val_loss: 0.4443 - val_acc: 0.8042\n",
      "Epoch 919/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4217 - acc: 0.8146 - val_loss: 0.4453 - val_acc: 0.8019\n",
      "Epoch 920/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4225 - acc: 0.8123 - val_loss: 0.4460 - val_acc: 0.8002\n",
      "Epoch 921/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4239 - acc: 0.8117 - val_loss: 0.4458 - val_acc: 0.7995\n",
      "Epoch 922/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4232 - acc: 0.8125 - val_loss: 0.4446 - val_acc: 0.8022\n",
      "Epoch 923/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4237 - acc: 0.8125 - val_loss: 0.4463 - val_acc: 0.8000\n",
      "Epoch 924/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4226 - acc: 0.8103 - val_loss: 0.4460 - val_acc: 0.8008\n",
      "Epoch 925/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4230 - acc: 0.8119 - val_loss: 0.4448 - val_acc: 0.7996\n",
      "Epoch 926/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4225 - acc: 0.8117 - val_loss: 0.4446 - val_acc: 0.8026\n",
      "Epoch 927/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8129 - val_loss: 0.4437 - val_acc: 0.8019\n",
      "Epoch 928/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8134 - val_loss: 0.4438 - val_acc: 0.8023\n",
      "Epoch 929/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4230 - acc: 0.8111 - val_loss: 0.4472 - val_acc: 0.8023\n",
      "Epoch 930/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8115 - val_loss: 0.4483 - val_acc: 0.8005\n",
      "Epoch 931/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4225 - acc: 0.8121 - val_loss: 0.4448 - val_acc: 0.8001\n",
      "Epoch 932/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4231 - acc: 0.8130 - val_loss: 0.4470 - val_acc: 0.8022\n",
      "Epoch 933/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4232 - acc: 0.8132 - val_loss: 0.4490 - val_acc: 0.8002\n",
      "Epoch 934/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4232 - acc: 0.8134 - val_loss: 0.4433 - val_acc: 0.8007\n",
      "Epoch 935/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4234 - acc: 0.8110 - val_loss: 0.4461 - val_acc: 0.8009\n",
      "Epoch 936/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4230 - acc: 0.8128 - val_loss: 0.4502 - val_acc: 0.7976\n",
      "Epoch 937/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4224 - acc: 0.8126 - val_loss: 0.4446 - val_acc: 0.8015\n",
      "Epoch 938/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4236 - acc: 0.8121 - val_loss: 0.4582 - val_acc: 0.7921\n",
      "Epoch 939/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4242 - acc: 0.8121 - val_loss: 0.4452 - val_acc: 0.7998\n",
      "Epoch 940/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4229 - acc: 0.8127 - val_loss: 0.4436 - val_acc: 0.8020\n",
      "Epoch 941/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4232 - acc: 0.8107 - val_loss: 0.4469 - val_acc: 0.8013\n",
      "Epoch 942/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4225 - acc: 0.8116 - val_loss: 0.4456 - val_acc: 0.8007\n",
      "Epoch 943/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4239 - acc: 0.8125 - val_loss: 0.4431 - val_acc: 0.8025\n",
      "Epoch 944/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4234 - acc: 0.8126 - val_loss: 0.4462 - val_acc: 0.8020\n",
      "Epoch 945/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4234 - acc: 0.8133 - val_loss: 0.4458 - val_acc: 0.8024\n",
      "Epoch 946/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4229 - acc: 0.8112 - val_loss: 0.4487 - val_acc: 0.7980\n",
      "Epoch 947/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8109 - val_loss: 0.4522 - val_acc: 0.7996\n",
      "Epoch 948/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4233 - acc: 0.8109 - val_loss: 0.4457 - val_acc: 0.8012\n",
      "Epoch 949/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4231 - acc: 0.8134 - val_loss: 0.4469 - val_acc: 0.8015\n",
      "Epoch 950/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8123 - val_loss: 0.4461 - val_acc: 0.8028\n",
      "Epoch 951/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4229 - acc: 0.8130 - val_loss: 0.4477 - val_acc: 0.8019\n",
      "Epoch 952/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4227 - acc: 0.8113 - val_loss: 0.4472 - val_acc: 0.8026\n",
      "Epoch 953/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4231 - acc: 0.8123 - val_loss: 0.4490 - val_acc: 0.7978\n",
      "Epoch 954/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8124 - val_loss: 0.4471 - val_acc: 0.7985\n",
      "Epoch 955/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4232 - acc: 0.8106 - val_loss: 0.4470 - val_acc: 0.7996\n",
      "Epoch 956/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4230 - acc: 0.8108 - val_loss: 0.4449 - val_acc: 0.7974\n",
      "Epoch 957/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4230 - acc: 0.8136 - val_loss: 0.4471 - val_acc: 0.7969\n",
      "Epoch 958/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4246 - acc: 0.8116 - val_loss: 0.4494 - val_acc: 0.8022\n",
      "Epoch 959/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8111 - val_loss: 0.4443 - val_acc: 0.8027\n",
      "Epoch 960/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4230 - acc: 0.8135 - val_loss: 0.4440 - val_acc: 0.8001\n",
      "Epoch 961/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4243 - acc: 0.8111 - val_loss: 0.4485 - val_acc: 0.8005\n",
      "Epoch 962/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4236 - acc: 0.8115 - val_loss: 0.4474 - val_acc: 0.8014\n",
      "Epoch 963/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4229 - acc: 0.8119 - val_loss: 0.4448 - val_acc: 0.7998\n",
      "Epoch 964/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4242 - acc: 0.8108 - val_loss: 0.4443 - val_acc: 0.8015\n",
      "Epoch 965/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8095 - val_loss: 0.4449 - val_acc: 0.8004\n",
      "Epoch 966/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4229 - acc: 0.8118 - val_loss: 0.4450 - val_acc: 0.8026\n",
      "Epoch 967/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4228 - acc: 0.8116 - val_loss: 0.4456 - val_acc: 0.7998\n",
      "Epoch 968/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4226 - acc: 0.8125 - val_loss: 0.4482 - val_acc: 0.7972\n",
      "Epoch 969/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4224 - acc: 0.8131 - val_loss: 0.4493 - val_acc: 0.7987\n",
      "Epoch 970/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4229 - acc: 0.8130 - val_loss: 0.4490 - val_acc: 0.7989\n",
      "Epoch 971/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4227 - acc: 0.8123 - val_loss: 0.4453 - val_acc: 0.8003\n",
      "Epoch 972/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4237 - acc: 0.8101 - val_loss: 0.4461 - val_acc: 0.8016\n",
      "Epoch 973/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4227 - acc: 0.8125 - val_loss: 0.4455 - val_acc: 0.7992\n",
      "Epoch 974/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4225 - acc: 0.8119 - val_loss: 0.4462 - val_acc: 0.8020\n",
      "Epoch 975/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4237 - acc: 0.8117 - val_loss: 0.4455 - val_acc: 0.8011\n",
      "Epoch 976/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4231 - acc: 0.8119 - val_loss: 0.4441 - val_acc: 0.8004\n",
      "Epoch 977/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4232 - acc: 0.8136 - val_loss: 0.4543 - val_acc: 0.7940\n",
      "Epoch 978/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4233 - acc: 0.8118 - val_loss: 0.4451 - val_acc: 0.8010\n",
      "Epoch 979/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4227 - acc: 0.8119 - val_loss: 0.4439 - val_acc: 0.8009\n",
      "Epoch 980/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4239 - acc: 0.8117 - val_loss: 0.4456 - val_acc: 0.7985\n",
      "Epoch 981/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4230 - acc: 0.8123 - val_loss: 0.4443 - val_acc: 0.8044\n",
      "Epoch 982/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4225 - acc: 0.8125 - val_loss: 0.4440 - val_acc: 0.7999\n",
      "Epoch 983/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4238 - acc: 0.8103 - val_loss: 0.4439 - val_acc: 0.8026\n",
      "Epoch 984/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8119 - val_loss: 0.4476 - val_acc: 0.8016\n",
      "Epoch 985/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4225 - acc: 0.8123 - val_loss: 0.4432 - val_acc: 0.8009\n",
      "Epoch 986/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4239 - acc: 0.8114 - val_loss: 0.4434 - val_acc: 0.8000\n",
      "Epoch 987/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8120 - val_loss: 0.4452 - val_acc: 0.8037\n",
      "Epoch 988/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4227 - acc: 0.8126 - val_loss: 0.4461 - val_acc: 0.8016\n",
      "Epoch 989/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4234 - acc: 0.8118 - val_loss: 0.4450 - val_acc: 0.8035\n",
      "Epoch 990/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4237 - acc: 0.8122 - val_loss: 0.4440 - val_acc: 0.8018\n",
      "Epoch 991/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8139 - val_loss: 0.4448 - val_acc: 0.8002\n",
      "Epoch 992/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4232 - acc: 0.8133 - val_loss: 0.4495 - val_acc: 0.8003\n",
      "Epoch 993/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4231 - acc: 0.8125 - val_loss: 0.4508 - val_acc: 0.7991\n",
      "Epoch 994/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4228 - acc: 0.8109 - val_loss: 0.4468 - val_acc: 0.7991\n",
      "Epoch 995/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4229 - acc: 0.8135 - val_loss: 0.4461 - val_acc: 0.7992\n",
      "Epoch 996/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8120 - val_loss: 0.4431 - val_acc: 0.8026\n",
      "Epoch 997/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8136 - val_loss: 0.4447 - val_acc: 0.8004\n",
      "Epoch 998/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8109 - val_loss: 0.4489 - val_acc: 0.7995\n",
      "Epoch 999/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8140 - val_loss: 0.4442 - val_acc: 0.8026\n",
      "Epoch 1000/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8128 - val_loss: 0.4454 - val_acc: 0.8013\n",
      "Epoch 1001/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4234 - acc: 0.8142 - val_loss: 0.4430 - val_acc: 0.8039\n",
      "Epoch 1002/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4226 - acc: 0.8129 - val_loss: 0.4441 - val_acc: 0.8001\n",
      "Epoch 1003/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8134 - val_loss: 0.4439 - val_acc: 0.8004\n",
      "Epoch 1004/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4237 - acc: 0.8122 - val_loss: 0.4447 - val_acc: 0.8018\n",
      "Epoch 1005/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4225 - acc: 0.8132 - val_loss: 0.4439 - val_acc: 0.8007\n",
      "Epoch 1006/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8120 - val_loss: 0.4441 - val_acc: 0.8034\n",
      "Epoch 1007/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4233 - acc: 0.8126 - val_loss: 0.4452 - val_acc: 0.8031\n",
      "Epoch 1008/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8120 - val_loss: 0.4452 - val_acc: 0.8018\n",
      "Epoch 1009/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4226 - acc: 0.8122 - val_loss: 0.4446 - val_acc: 0.7993\n",
      "Epoch 1010/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4231 - acc: 0.8130 - val_loss: 0.4437 - val_acc: 0.8005\n",
      "Epoch 1011/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8116 - val_loss: 0.4443 - val_acc: 0.8000\n",
      "Epoch 1012/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4212 - acc: 0.8137 - val_loss: 0.4448 - val_acc: 0.8011\n",
      "Epoch 1013/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4229 - acc: 0.8125 - val_loss: 0.4456 - val_acc: 0.8007\n",
      "Epoch 1014/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8114 - val_loss: 0.4454 - val_acc: 0.8013\n",
      "Epoch 1015/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8125 - val_loss: 0.4475 - val_acc: 0.8011\n",
      "Epoch 1016/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8142 - val_loss: 0.4457 - val_acc: 0.7993\n",
      "Epoch 1017/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4231 - acc: 0.8112 - val_loss: 0.4448 - val_acc: 0.8002\n",
      "Epoch 1018/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8136 - val_loss: 0.4480 - val_acc: 0.7993\n",
      "Epoch 1019/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8120 - val_loss: 0.4438 - val_acc: 0.8050\n",
      "Epoch 1020/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4234 - acc: 0.8123 - val_loss: 0.4459 - val_acc: 0.8039\n",
      "Epoch 1021/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4228 - acc: 0.8113 - val_loss: 0.4448 - val_acc: 0.8014\n",
      "Epoch 1022/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8124 - val_loss: 0.4440 - val_acc: 0.8028\n",
      "Epoch 1023/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4231 - acc: 0.8104 - val_loss: 0.4436 - val_acc: 0.8015\n",
      "Epoch 1024/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4220 - acc: 0.8128 - val_loss: 0.4441 - val_acc: 0.8004\n",
      "Epoch 1025/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4234 - acc: 0.8133 - val_loss: 0.4443 - val_acc: 0.8003\n",
      "Epoch 1026/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4231 - acc: 0.8134 - val_loss: 0.4446 - val_acc: 0.8037\n",
      "Epoch 1027/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8138 - val_loss: 0.4483 - val_acc: 0.7974\n",
      "Epoch 1028/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8113 - val_loss: 0.4467 - val_acc: 0.7996\n",
      "Epoch 1029/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4229 - acc: 0.8137 - val_loss: 0.4436 - val_acc: 0.8007\n",
      "Epoch 1030/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8115 - val_loss: 0.4436 - val_acc: 0.7996\n",
      "Epoch 1031/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4219 - acc: 0.8140 - val_loss: 0.4433 - val_acc: 0.8012\n",
      "Epoch 1032/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8122 - val_loss: 0.4437 - val_acc: 0.8011\n",
      "Epoch 1033/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4220 - acc: 0.8132 - val_loss: 0.4437 - val_acc: 0.8013\n",
      "Epoch 1034/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8153 - val_loss: 0.4445 - val_acc: 0.8002\n",
      "Epoch 1035/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8138 - val_loss: 0.4461 - val_acc: 0.7992\n",
      "Epoch 1036/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8134 - val_loss: 0.4427 - val_acc: 0.8019\n",
      "Epoch 1037/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4222 - acc: 0.8120 - val_loss: 0.4470 - val_acc: 0.8023\n",
      "Epoch 1038/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4235 - acc: 0.8118 - val_loss: 0.4448 - val_acc: 0.8013\n",
      "Epoch 1039/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4220 - acc: 0.8104 - val_loss: 0.4441 - val_acc: 0.8022\n",
      "Epoch 1040/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4233 - acc: 0.8115 - val_loss: 0.4450 - val_acc: 0.7980\n",
      "Epoch 1041/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4224 - acc: 0.8122 - val_loss: 0.4437 - val_acc: 0.8022\n",
      "Epoch 1042/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4230 - acc: 0.8128 - val_loss: 0.4445 - val_acc: 0.8020\n",
      "Epoch 1043/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4227 - acc: 0.8123 - val_loss: 0.4438 - val_acc: 0.7989\n",
      "Epoch 1044/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8114 - val_loss: 0.4476 - val_acc: 0.8024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1045/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4239 - acc: 0.8112 - val_loss: 0.4436 - val_acc: 0.8022\n",
      "Epoch 1046/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4234 - acc: 0.8092 - val_loss: 0.4515 - val_acc: 0.8007\n",
      "Epoch 1047/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8123 - val_loss: 0.4449 - val_acc: 0.7998\n",
      "Epoch 1048/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4228 - acc: 0.8118 - val_loss: 0.4438 - val_acc: 0.7986\n",
      "Epoch 1049/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4228 - acc: 0.8115 - val_loss: 0.4453 - val_acc: 0.7999\n",
      "Epoch 1050/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8117 - val_loss: 0.4455 - val_acc: 0.8007\n",
      "Epoch 1051/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8120 - val_loss: 0.4433 - val_acc: 0.8013\n",
      "Epoch 1052/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8121 - val_loss: 0.4481 - val_acc: 0.7980\n",
      "Epoch 1053/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8121 - val_loss: 0.4424 - val_acc: 0.8018\n",
      "Epoch 1054/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8127 - val_loss: 0.4438 - val_acc: 0.8022\n",
      "Epoch 1055/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4230 - acc: 0.8134 - val_loss: 0.4453 - val_acc: 0.8002\n",
      "Epoch 1056/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4227 - acc: 0.8117 - val_loss: 0.4435 - val_acc: 0.8018\n",
      "Epoch 1057/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8110 - val_loss: 0.4434 - val_acc: 0.8015\n",
      "Epoch 1058/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4232 - acc: 0.8104 - val_loss: 0.4449 - val_acc: 0.8022\n",
      "Epoch 1059/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8121 - val_loss: 0.4463 - val_acc: 0.7989\n",
      "Epoch 1060/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4229 - acc: 0.8142 - val_loss: 0.4470 - val_acc: 0.8000\n",
      "Epoch 1061/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4228 - acc: 0.8130 - val_loss: 0.4455 - val_acc: 0.7991\n",
      "Epoch 1062/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4228 - acc: 0.8119 - val_loss: 0.4468 - val_acc: 0.8002\n",
      "Epoch 1063/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8109 - val_loss: 0.4477 - val_acc: 0.7987\n",
      "Epoch 1064/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4227 - acc: 0.8132 - val_loss: 0.4447 - val_acc: 0.8016\n",
      "Epoch 1065/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8123 - val_loss: 0.4465 - val_acc: 0.7998\n",
      "Epoch 1066/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8117 - val_loss: 0.4461 - val_acc: 0.8011\n",
      "Epoch 1067/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4230 - acc: 0.8103 - val_loss: 0.4477 - val_acc: 0.7993\n",
      "Epoch 1068/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8125 - val_loss: 0.4449 - val_acc: 0.8009\n",
      "Epoch 1069/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8108 - val_loss: 0.4489 - val_acc: 0.7978\n",
      "Epoch 1070/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4241 - acc: 0.8109 - val_loss: 0.4471 - val_acc: 0.8018\n",
      "Epoch 1071/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4227 - acc: 0.8108 - val_loss: 0.4514 - val_acc: 0.7973\n",
      "Epoch 1072/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4234 - acc: 0.8124 - val_loss: 0.4447 - val_acc: 0.8025\n",
      "Epoch 1073/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8140 - val_loss: 0.4495 - val_acc: 0.8001\n",
      "Epoch 1074/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8120 - val_loss: 0.4451 - val_acc: 0.8004\n",
      "Epoch 1075/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8116 - val_loss: 0.4442 - val_acc: 0.8022\n",
      "Epoch 1076/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4231 - acc: 0.8120 - val_loss: 0.4440 - val_acc: 0.7985\n",
      "Epoch 1077/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4232 - acc: 0.8121 - val_loss: 0.4514 - val_acc: 0.7974\n",
      "Epoch 1078/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4220 - acc: 0.8133 - val_loss: 0.4441 - val_acc: 0.8018\n",
      "Epoch 1079/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4214 - acc: 0.8113 - val_loss: 0.4529 - val_acc: 0.8000\n",
      "Epoch 1080/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8123 - val_loss: 0.4471 - val_acc: 0.8022\n",
      "Epoch 1081/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4229 - acc: 0.8111 - val_loss: 0.4492 - val_acc: 0.8004\n",
      "Epoch 1082/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4214 - acc: 0.8123 - val_loss: 0.4426 - val_acc: 0.8002\n",
      "Epoch 1083/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8126 - val_loss: 0.4449 - val_acc: 0.8022\n",
      "Epoch 1084/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4220 - acc: 0.8126 - val_loss: 0.4437 - val_acc: 0.8033\n",
      "Epoch 1085/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8123 - val_loss: 0.4433 - val_acc: 0.8009\n",
      "Epoch 1086/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8129 - val_loss: 0.4460 - val_acc: 0.8027\n",
      "Epoch 1087/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4227 - acc: 0.8135 - val_loss: 0.4432 - val_acc: 0.8009\n",
      "Epoch 1088/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8113 - val_loss: 0.4477 - val_acc: 0.8033\n",
      "Epoch 1089/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4220 - acc: 0.8128 - val_loss: 0.4459 - val_acc: 0.8013\n",
      "Epoch 1090/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8116 - val_loss: 0.4470 - val_acc: 0.8024\n",
      "Epoch 1091/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4222 - acc: 0.8140 - val_loss: 0.4481 - val_acc: 0.8007\n",
      "Epoch 1092/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4229 - acc: 0.8120 - val_loss: 0.4430 - val_acc: 0.8000\n",
      "Epoch 1093/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4228 - acc: 0.8125 - val_loss: 0.4446 - val_acc: 0.8028\n",
      "Epoch 1094/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8104 - val_loss: 0.4470 - val_acc: 0.8018\n",
      "Epoch 1095/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4221 - acc: 0.8129 - val_loss: 0.4460 - val_acc: 0.8007\n",
      "Epoch 1096/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4229 - acc: 0.8101 - val_loss: 0.4466 - val_acc: 0.8002\n",
      "Epoch 1097/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4216 - acc: 0.8129 - val_loss: 0.4442 - val_acc: 0.7999\n",
      "Epoch 1098/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8128 - val_loss: 0.4450 - val_acc: 0.8009\n",
      "Epoch 1099/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8144 - val_loss: 0.4445 - val_acc: 0.8018\n",
      "Epoch 1100/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8116 - val_loss: 0.4453 - val_acc: 0.7996\n",
      "Epoch 1101/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4222 - acc: 0.8105 - val_loss: 0.4448 - val_acc: 0.8034\n",
      "Epoch 1102/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4228 - acc: 0.8140 - val_loss: 0.4529 - val_acc: 0.7967\n",
      "Epoch 1103/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4218 - acc: 0.8128 - val_loss: 0.4451 - val_acc: 0.8011\n",
      "Epoch 1104/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8131 - val_loss: 0.4460 - val_acc: 0.7991\n",
      "Epoch 1105/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8130 - val_loss: 0.4449 - val_acc: 0.8024\n",
      "Epoch 1106/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8125 - val_loss: 0.4452 - val_acc: 0.8003\n",
      "Epoch 1107/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8113 - val_loss: 0.4455 - val_acc: 0.8004\n",
      "Epoch 1108/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8118 - val_loss: 0.4451 - val_acc: 0.8033\n",
      "Epoch 1109/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4218 - acc: 0.8120 - val_loss: 0.4423 - val_acc: 0.7998\n",
      "Epoch 1110/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4222 - acc: 0.8125 - val_loss: 0.4460 - val_acc: 0.7981\n",
      "Epoch 1111/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8124 - val_loss: 0.4541 - val_acc: 0.7956\n",
      "Epoch 1112/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8114 - val_loss: 0.4468 - val_acc: 0.8007\n",
      "Epoch 1113/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8135 - val_loss: 0.4435 - val_acc: 0.8008\n",
      "Epoch 1114/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8131 - val_loss: 0.4497 - val_acc: 0.7987\n",
      "Epoch 1115/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4215 - acc: 0.8118 - val_loss: 0.4476 - val_acc: 0.7984\n",
      "Epoch 1116/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4227 - acc: 0.8121 - val_loss: 0.4472 - val_acc: 0.8009\n",
      "Epoch 1117/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8134 - val_loss: 0.4454 - val_acc: 0.8026\n",
      "Epoch 1118/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8144 - val_loss: 0.4490 - val_acc: 0.8007\n",
      "Epoch 1119/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8123 - val_loss: 0.4441 - val_acc: 0.8033\n",
      "Epoch 1120/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4210 - acc: 0.8116 - val_loss: 0.4462 - val_acc: 0.8020\n",
      "Epoch 1121/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4225 - acc: 0.8122 - val_loss: 0.4457 - val_acc: 0.8018\n",
      "Epoch 1122/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8138 - val_loss: 0.4444 - val_acc: 0.8013\n",
      "Epoch 1123/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4209 - acc: 0.8125 - val_loss: 0.4467 - val_acc: 0.7996\n",
      "Epoch 1124/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8131 - val_loss: 0.4456 - val_acc: 0.8024\n",
      "Epoch 1125/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4212 - acc: 0.8121 - val_loss: 0.4458 - val_acc: 0.7987\n",
      "Epoch 1126/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4211 - acc: 0.8126 - val_loss: 0.4450 - val_acc: 0.8015\n",
      "Epoch 1127/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4216 - acc: 0.8144 - val_loss: 0.4437 - val_acc: 0.8009\n",
      "Epoch 1128/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8143 - val_loss: 0.4457 - val_acc: 0.7998\n",
      "Epoch 1129/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8127 - val_loss: 0.4446 - val_acc: 0.8022\n",
      "Epoch 1130/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4218 - acc: 0.8139 - val_loss: 0.4485 - val_acc: 0.7997\n",
      "Epoch 1131/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4221 - acc: 0.8149 - val_loss: 0.4644 - val_acc: 0.7905\n",
      "Epoch 1132/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4228 - acc: 0.8122 - val_loss: 0.4462 - val_acc: 0.7995\n",
      "Epoch 1133/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4226 - acc: 0.8123 - val_loss: 0.4455 - val_acc: 0.7991\n",
      "Epoch 1134/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4220 - acc: 0.8125 - val_loss: 0.4471 - val_acc: 0.8000\n",
      "Epoch 1135/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4216 - acc: 0.8139 - val_loss: 0.4443 - val_acc: 0.7987\n",
      "Epoch 1136/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8129 - val_loss: 0.4440 - val_acc: 0.8019\n",
      "Epoch 1137/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8116 - val_loss: 0.4451 - val_acc: 0.8022\n",
      "Epoch 1138/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4230 - acc: 0.8116 - val_loss: 0.4437 - val_acc: 0.8013\n",
      "Epoch 1139/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4231 - acc: 0.8121 - val_loss: 0.4440 - val_acc: 0.8011\n",
      "Epoch 1140/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8136 - val_loss: 0.4445 - val_acc: 0.8022\n",
      "Epoch 1141/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4229 - acc: 0.8126 - val_loss: 0.4445 - val_acc: 0.8020\n",
      "Epoch 1142/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4229 - acc: 0.8126 - val_loss: 0.4492 - val_acc: 0.7962\n",
      "Epoch 1143/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4231 - acc: 0.8123 - val_loss: 0.4434 - val_acc: 0.8009\n",
      "Epoch 1144/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8112 - val_loss: 0.4444 - val_acc: 0.8037\n",
      "Epoch 1145/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8134 - val_loss: 0.4440 - val_acc: 0.7991\n",
      "Epoch 1146/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8138 - val_loss: 0.4496 - val_acc: 0.7965\n",
      "Epoch 1147/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4210 - acc: 0.8137 - val_loss: 0.4465 - val_acc: 0.7993\n",
      "Epoch 1148/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8124 - val_loss: 0.4481 - val_acc: 0.8000\n",
      "Epoch 1149/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4224 - acc: 0.8142 - val_loss: 0.4449 - val_acc: 0.8002\n",
      "Epoch 1150/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8126 - val_loss: 0.4429 - val_acc: 0.8031\n",
      "Epoch 1151/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8150 - val_loss: 0.4434 - val_acc: 0.7991\n",
      "Epoch 1152/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8122 - val_loss: 0.4420 - val_acc: 0.8020\n",
      "Epoch 1153/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8118 - val_loss: 0.4443 - val_acc: 0.8039\n",
      "Epoch 1154/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8121 - val_loss: 0.4434 - val_acc: 0.7991\n",
      "Epoch 1155/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4233 - acc: 0.8129 - val_loss: 0.4444 - val_acc: 0.8004\n",
      "Epoch 1156/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8119 - val_loss: 0.4491 - val_acc: 0.7980\n",
      "Epoch 1157/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8147 - val_loss: 0.4484 - val_acc: 0.7989\n",
      "Epoch 1158/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8136 - val_loss: 0.4445 - val_acc: 0.8028\n",
      "Epoch 1159/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4207 - acc: 0.8128 - val_loss: 0.4454 - val_acc: 0.7976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1160/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4212 - acc: 0.8132 - val_loss: 0.4466 - val_acc: 0.8007\n",
      "Epoch 1161/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8113 - val_loss: 0.4449 - val_acc: 0.8007\n",
      "Epoch 1162/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4234 - acc: 0.8122 - val_loss: 0.4431 - val_acc: 0.8015\n",
      "Epoch 1163/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8121 - val_loss: 0.4483 - val_acc: 0.7985\n",
      "Epoch 1164/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8120 - val_loss: 0.4453 - val_acc: 0.8013\n",
      "Epoch 1165/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8114 - val_loss: 0.4443 - val_acc: 0.8015\n",
      "Epoch 1166/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8132 - val_loss: 0.4490 - val_acc: 0.7993\n",
      "Epoch 1167/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8145 - val_loss: 0.4454 - val_acc: 0.7999\n",
      "Epoch 1168/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8116 - val_loss: 0.4456 - val_acc: 0.7989\n",
      "Epoch 1169/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4221 - acc: 0.8134 - val_loss: 0.4453 - val_acc: 0.8000\n",
      "Epoch 1170/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4221 - acc: 0.8135 - val_loss: 0.4437 - val_acc: 0.8020\n",
      "Epoch 1171/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8135 - val_loss: 0.4502 - val_acc: 0.7993\n",
      "Epoch 1172/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8121 - val_loss: 0.4447 - val_acc: 0.7987\n",
      "Epoch 1173/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8123 - val_loss: 0.4436 - val_acc: 0.8009\n",
      "Epoch 1174/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8119 - val_loss: 0.4437 - val_acc: 0.7982\n",
      "Epoch 1175/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8126 - val_loss: 0.4453 - val_acc: 0.8009\n",
      "Epoch 1176/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4223 - acc: 0.8127 - val_loss: 0.4439 - val_acc: 0.8000\n",
      "Epoch 1177/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8134 - val_loss: 0.4436 - val_acc: 0.8009\n",
      "Epoch 1178/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8129 - val_loss: 0.4425 - val_acc: 0.8015\n",
      "Epoch 1179/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4214 - acc: 0.8132 - val_loss: 0.4439 - val_acc: 0.8004\n",
      "Epoch 1180/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4220 - acc: 0.8127 - val_loss: 0.4441 - val_acc: 0.8018\n",
      "Epoch 1181/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8124 - val_loss: 0.4445 - val_acc: 0.7976\n",
      "Epoch 1182/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8113 - val_loss: 0.4535 - val_acc: 0.7946\n",
      "Epoch 1183/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4221 - acc: 0.8136 - val_loss: 0.4431 - val_acc: 0.7985\n",
      "Epoch 1184/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4215 - acc: 0.8126 - val_loss: 0.4509 - val_acc: 0.7978\n",
      "Epoch 1185/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4230 - acc: 0.8121 - val_loss: 0.4468 - val_acc: 0.7987\n",
      "Epoch 1186/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4213 - acc: 0.8136 - val_loss: 0.4457 - val_acc: 0.8031\n",
      "Epoch 1187/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8122 - val_loss: 0.4450 - val_acc: 0.8000\n",
      "Epoch 1188/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8121 - val_loss: 0.4479 - val_acc: 0.7978\n",
      "Epoch 1189/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8101 - val_loss: 0.4466 - val_acc: 0.8002\n",
      "Epoch 1190/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4209 - acc: 0.8126 - val_loss: 0.4448 - val_acc: 0.8044\n",
      "Epoch 1191/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4227 - acc: 0.8122 - val_loss: 0.4468 - val_acc: 0.8002\n",
      "Epoch 1192/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8108 - val_loss: 0.4459 - val_acc: 0.8009\n",
      "Epoch 1193/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8143 - val_loss: 0.4446 - val_acc: 0.8031\n",
      "Epoch 1194/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8130 - val_loss: 0.4454 - val_acc: 0.7984\n",
      "Epoch 1195/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8126 - val_loss: 0.4443 - val_acc: 0.8028\n",
      "Epoch 1196/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8128 - val_loss: 0.4434 - val_acc: 0.8022\n",
      "Epoch 1197/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8142 - val_loss: 0.4428 - val_acc: 0.8013\n",
      "Epoch 1198/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8134 - val_loss: 0.4488 - val_acc: 0.7998\n",
      "Epoch 1199/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8122 - val_loss: 0.4448 - val_acc: 0.8009\n",
      "Epoch 1200/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8123 - val_loss: 0.4439 - val_acc: 0.8002\n",
      "Epoch 1201/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8136 - val_loss: 0.4455 - val_acc: 0.8031\n",
      "Epoch 1202/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8107 - val_loss: 0.4453 - val_acc: 0.8028\n",
      "Epoch 1203/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8146 - val_loss: 0.4436 - val_acc: 0.8013\n",
      "Epoch 1204/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4230 - acc: 0.8116 - val_loss: 0.4444 - val_acc: 0.8013\n",
      "Epoch 1205/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8136 - val_loss: 0.4456 - val_acc: 0.8004\n",
      "Epoch 1206/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4220 - acc: 0.8129 - val_loss: 0.4473 - val_acc: 0.7989\n",
      "Epoch 1207/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8142 - val_loss: 0.4451 - val_acc: 0.8004\n",
      "Epoch 1208/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8109 - val_loss: 0.4442 - val_acc: 0.8007\n",
      "Epoch 1209/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4228 - acc: 0.8122 - val_loss: 0.4449 - val_acc: 0.8002\n",
      "Epoch 1210/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8138 - val_loss: 0.4450 - val_acc: 0.8013\n",
      "Epoch 1211/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8123 - val_loss: 0.4448 - val_acc: 0.8013\n",
      "Epoch 1212/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4218 - acc: 0.8134 - val_loss: 0.4473 - val_acc: 0.8018\n",
      "Epoch 1213/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8117 - val_loss: 0.4459 - val_acc: 0.7985\n",
      "Epoch 1214/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4209 - acc: 0.8146 - val_loss: 0.4458 - val_acc: 0.7998\n",
      "Epoch 1215/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8125 - val_loss: 0.4450 - val_acc: 0.8015\n",
      "Epoch 1216/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8136 - val_loss: 0.4452 - val_acc: 0.7978\n",
      "Epoch 1217/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8138 - val_loss: 0.4447 - val_acc: 0.8002\n",
      "Epoch 1218/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8116 - val_loss: 0.4449 - val_acc: 0.7998\n",
      "Epoch 1219/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8128 - val_loss: 0.4433 - val_acc: 0.8020\n",
      "Epoch 1220/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8126 - val_loss: 0.4458 - val_acc: 0.7989\n",
      "Epoch 1221/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8126 - val_loss: 0.4461 - val_acc: 0.7952\n",
      "Epoch 1222/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4226 - acc: 0.8114 - val_loss: 0.4437 - val_acc: 0.8002\n",
      "Epoch 1223/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4217 - acc: 0.8123 - val_loss: 0.4443 - val_acc: 0.7991\n",
      "Epoch 1224/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8137 - val_loss: 0.4457 - val_acc: 0.8018\n",
      "Epoch 1225/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4220 - acc: 0.8113 - val_loss: 0.4460 - val_acc: 0.8013\n",
      "Epoch 1226/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4215 - acc: 0.8137 - val_loss: 0.4441 - val_acc: 0.8007\n",
      "Epoch 1227/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8121 - val_loss: 0.4461 - val_acc: 0.8004\n",
      "Epoch 1228/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8131 - val_loss: 0.4456 - val_acc: 0.8007\n",
      "Epoch 1229/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8104 - val_loss: 0.4480 - val_acc: 0.8001\n",
      "Epoch 1230/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4216 - acc: 0.8122 - val_loss: 0.4450 - val_acc: 0.8009\n",
      "Epoch 1231/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4218 - acc: 0.8121 - val_loss: 0.4441 - val_acc: 0.8026\n",
      "Epoch 1232/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4214 - acc: 0.8135 - val_loss: 0.4446 - val_acc: 0.8009\n",
      "Epoch 1233/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4220 - acc: 0.8113 - val_loss: 0.4471 - val_acc: 0.8009\n",
      "Epoch 1234/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4210 - acc: 0.8142 - val_loss: 0.4452 - val_acc: 0.8013\n",
      "Epoch 1235/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4213 - acc: 0.8139 - val_loss: 0.4453 - val_acc: 0.7985\n",
      "Epoch 1236/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4223 - acc: 0.8134 - val_loss: 0.4442 - val_acc: 0.8031\n",
      "Epoch 1237/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8126 - val_loss: 0.4456 - val_acc: 0.8039\n",
      "Epoch 1238/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8131 - val_loss: 0.4430 - val_acc: 0.8013\n",
      "Epoch 1239/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8112 - val_loss: 0.4420 - val_acc: 0.7989\n",
      "Epoch 1240/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4211 - acc: 0.8124 - val_loss: 0.4427 - val_acc: 0.8039\n",
      "Epoch 1241/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8130 - val_loss: 0.4439 - val_acc: 0.8022\n",
      "Epoch 1242/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8123 - val_loss: 0.4424 - val_acc: 0.8024\n",
      "Epoch 1243/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8138 - val_loss: 0.4490 - val_acc: 0.7956\n",
      "Epoch 1244/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8111 - val_loss: 0.4449 - val_acc: 0.8002\n",
      "Epoch 1245/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8138 - val_loss: 0.4442 - val_acc: 0.7982\n",
      "Epoch 1246/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4221 - acc: 0.8131 - val_loss: 0.4464 - val_acc: 0.8001\n",
      "Epoch 1247/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4223 - acc: 0.8145 - val_loss: 0.4462 - val_acc: 0.7996\n",
      "Epoch 1248/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4223 - acc: 0.8134 - val_loss: 0.4455 - val_acc: 0.8015\n",
      "Epoch 1249/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8142 - val_loss: 0.4437 - val_acc: 0.7993\n",
      "Epoch 1250/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8109 - val_loss: 0.4443 - val_acc: 0.8020\n",
      "Epoch 1251/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8113 - val_loss: 0.4444 - val_acc: 0.7990\n",
      "Epoch 1252/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8096 - val_loss: 0.4467 - val_acc: 0.7998\n",
      "Epoch 1253/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4221 - acc: 0.8097 - val_loss: 0.4448 - val_acc: 0.7982\n",
      "Epoch 1254/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8116 - val_loss: 0.4461 - val_acc: 0.8007\n",
      "Epoch 1255/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8155 - val_loss: 0.4465 - val_acc: 0.8000\n",
      "Epoch 1256/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4225 - acc: 0.8131 - val_loss: 0.4451 - val_acc: 0.7996\n",
      "Epoch 1257/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8117 - val_loss: 0.4430 - val_acc: 0.8013\n",
      "Epoch 1258/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4228 - acc: 0.8116 - val_loss: 0.4427 - val_acc: 0.8000\n",
      "Epoch 1259/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4232 - acc: 0.8124 - val_loss: 0.4448 - val_acc: 0.7987\n",
      "Epoch 1260/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8131 - val_loss: 0.4472 - val_acc: 0.8004\n",
      "Epoch 1261/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4234 - acc: 0.8138 - val_loss: 0.4444 - val_acc: 0.7996\n",
      "Epoch 1262/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8133 - val_loss: 0.4458 - val_acc: 0.8007\n",
      "Epoch 1263/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4222 - acc: 0.8134 - val_loss: 0.4435 - val_acc: 0.8026\n",
      "Epoch 1264/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4222 - acc: 0.8121 - val_loss: 0.4435 - val_acc: 0.8004\n",
      "Epoch 1265/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8139 - val_loss: 0.4438 - val_acc: 0.8026\n",
      "Epoch 1266/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8127 - val_loss: 0.4440 - val_acc: 0.7993\n",
      "Epoch 1267/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8129 - val_loss: 0.4445 - val_acc: 0.8026\n",
      "Epoch 1268/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4222 - acc: 0.8123 - val_loss: 0.4452 - val_acc: 0.7993\n",
      "Epoch 1269/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4214 - acc: 0.8120 - val_loss: 0.4454 - val_acc: 0.7987\n",
      "Epoch 1270/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4212 - acc: 0.8139 - val_loss: 0.4460 - val_acc: 0.7998\n",
      "Epoch 1271/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4225 - acc: 0.8107 - val_loss: 0.4430 - val_acc: 0.8026\n",
      "Epoch 1272/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4225 - acc: 0.8120 - val_loss: 0.4439 - val_acc: 0.8016\n",
      "Epoch 1273/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8125 - val_loss: 0.4436 - val_acc: 0.8033\n",
      "Epoch 1274/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8129 - val_loss: 0.4443 - val_acc: 0.8015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1275/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4224 - acc: 0.8116 - val_loss: 0.4436 - val_acc: 0.7993\n",
      "Epoch 1276/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4227 - acc: 0.8113 - val_loss: 0.4421 - val_acc: 0.8013\n",
      "Epoch 1277/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8136 - val_loss: 0.4444 - val_acc: 0.7978\n",
      "Epoch 1278/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8134 - val_loss: 0.4439 - val_acc: 0.8026\n",
      "Epoch 1279/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8123 - val_loss: 0.4441 - val_acc: 0.7996\n",
      "Epoch 1280/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8129 - val_loss: 0.4443 - val_acc: 0.8000\n",
      "Epoch 1281/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4226 - acc: 0.8119 - val_loss: 0.4438 - val_acc: 0.8002\n",
      "Epoch 1282/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8150 - val_loss: 0.4422 - val_acc: 0.8000\n",
      "Epoch 1283/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8132 - val_loss: 0.4433 - val_acc: 0.7989\n",
      "Epoch 1284/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4221 - acc: 0.8125 - val_loss: 0.4417 - val_acc: 0.8011\n",
      "Epoch 1285/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8129 - val_loss: 0.4486 - val_acc: 0.7996\n",
      "Epoch 1286/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4225 - acc: 0.8127 - val_loss: 0.4437 - val_acc: 0.8002\n",
      "Epoch 1287/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8136 - val_loss: 0.4445 - val_acc: 0.8035\n",
      "Epoch 1288/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4211 - acc: 0.8134 - val_loss: 0.4428 - val_acc: 0.7996\n",
      "Epoch 1289/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4210 - acc: 0.8103 - val_loss: 0.4453 - val_acc: 0.7998\n",
      "Epoch 1290/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4219 - acc: 0.8129 - val_loss: 0.4435 - val_acc: 0.8028\n",
      "Epoch 1291/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4207 - acc: 0.8141 - val_loss: 0.4448 - val_acc: 0.8004\n",
      "Epoch 1292/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4219 - acc: 0.8141 - val_loss: 0.4446 - val_acc: 0.8031\n",
      "Epoch 1293/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4222 - acc: 0.8123 - val_loss: 0.4453 - val_acc: 0.7993\n",
      "Epoch 1294/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4222 - acc: 0.8142 - val_loss: 0.4444 - val_acc: 0.7993\n",
      "Epoch 1295/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4224 - acc: 0.8109 - val_loss: 0.4446 - val_acc: 0.7980\n",
      "Epoch 1296/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4223 - acc: 0.8129 - val_loss: 0.4423 - val_acc: 0.8015\n",
      "Epoch 1297/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8140 - val_loss: 0.4444 - val_acc: 0.8011\n",
      "Epoch 1298/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4226 - acc: 0.8112 - val_loss: 0.4461 - val_acc: 0.7985\n",
      "Epoch 1299/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4221 - acc: 0.8129 - val_loss: 0.4443 - val_acc: 0.8011\n",
      "Epoch 1300/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8138 - val_loss: 0.4517 - val_acc: 0.7965\n",
      "Epoch 1301/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8132 - val_loss: 0.4452 - val_acc: 0.7989\n",
      "Epoch 1302/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8134 - val_loss: 0.4467 - val_acc: 0.7982\n",
      "Epoch 1303/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8135 - val_loss: 0.4439 - val_acc: 0.8013\n",
      "Epoch 1304/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4224 - acc: 0.8124 - val_loss: 0.4420 - val_acc: 0.8002\n",
      "Epoch 1305/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8133 - val_loss: 0.4475 - val_acc: 0.8013\n",
      "Epoch 1306/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8142 - val_loss: 0.4444 - val_acc: 0.8009\n",
      "Epoch 1307/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8131 - val_loss: 0.4471 - val_acc: 0.8009\n",
      "Epoch 1308/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8134 - val_loss: 0.4431 - val_acc: 0.8011\n",
      "Epoch 1309/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8133 - val_loss: 0.4451 - val_acc: 0.7990\n",
      "Epoch 1310/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8114 - val_loss: 0.4454 - val_acc: 0.8037\n",
      "Epoch 1311/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8131 - val_loss: 0.4456 - val_acc: 0.8009\n",
      "Epoch 1312/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8122 - val_loss: 0.4441 - val_acc: 0.8011\n",
      "Epoch 1313/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4208 - acc: 0.8121 - val_loss: 0.4436 - val_acc: 0.8004\n",
      "Epoch 1314/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8141 - val_loss: 0.4446 - val_acc: 0.8009\n",
      "Epoch 1315/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8146 - val_loss: 0.4432 - val_acc: 0.8028\n",
      "Epoch 1316/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8144 - val_loss: 0.4436 - val_acc: 0.8000\n",
      "Epoch 1317/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8131 - val_loss: 0.4421 - val_acc: 0.8000\n",
      "Epoch 1318/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8118 - val_loss: 0.4469 - val_acc: 0.8013\n",
      "Epoch 1319/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4207 - acc: 0.8118 - val_loss: 0.4442 - val_acc: 0.7998\n",
      "Epoch 1320/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8119 - val_loss: 0.4497 - val_acc: 0.7974\n",
      "Epoch 1321/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8143 - val_loss: 0.4501 - val_acc: 0.7972\n",
      "Epoch 1322/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8136 - val_loss: 0.4430 - val_acc: 0.8011\n",
      "Epoch 1323/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8131 - val_loss: 0.4446 - val_acc: 0.8000\n",
      "Epoch 1324/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8116 - val_loss: 0.4448 - val_acc: 0.7991\n",
      "Epoch 1325/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4213 - acc: 0.8151 - val_loss: 0.4467 - val_acc: 0.7982\n",
      "Epoch 1326/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8114 - val_loss: 0.4454 - val_acc: 0.8000\n",
      "Epoch 1327/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8135 - val_loss: 0.4481 - val_acc: 0.7993\n",
      "Epoch 1328/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8126 - val_loss: 0.4460 - val_acc: 0.7998\n",
      "Epoch 1329/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4235 - acc: 0.8113 - val_loss: 0.4443 - val_acc: 0.8020\n",
      "Epoch 1330/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8122 - val_loss: 0.4482 - val_acc: 0.7974\n",
      "Epoch 1331/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4222 - acc: 0.8117 - val_loss: 0.4480 - val_acc: 0.7996\n",
      "Epoch 1332/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4223 - acc: 0.8141 - val_loss: 0.4432 - val_acc: 0.8024\n",
      "Epoch 1333/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8136 - val_loss: 0.4435 - val_acc: 0.8013\n",
      "Epoch 1334/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8138 - val_loss: 0.4419 - val_acc: 0.7985\n",
      "Epoch 1335/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8136 - val_loss: 0.4453 - val_acc: 0.8033\n",
      "Epoch 1336/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4227 - acc: 0.8112 - val_loss: 0.4442 - val_acc: 0.8024\n",
      "Epoch 1337/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8140 - val_loss: 0.4455 - val_acc: 0.8023\n",
      "Epoch 1338/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8116 - val_loss: 0.4449 - val_acc: 0.8009\n",
      "Epoch 1339/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8126 - val_loss: 0.4492 - val_acc: 0.7982\n",
      "Epoch 1340/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8137 - val_loss: 0.4447 - val_acc: 0.8035\n",
      "Epoch 1341/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8123 - val_loss: 0.4458 - val_acc: 0.7987\n",
      "Epoch 1342/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8138 - val_loss: 0.4518 - val_acc: 0.7991\n",
      "Epoch 1343/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8124 - val_loss: 0.4469 - val_acc: 0.8000\n",
      "Epoch 1344/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4226 - acc: 0.8105 - val_loss: 0.4450 - val_acc: 0.8009\n",
      "Epoch 1345/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8129 - val_loss: 0.4449 - val_acc: 0.8022\n",
      "Epoch 1346/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8139 - val_loss: 0.4439 - val_acc: 0.8020\n",
      "Epoch 1347/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8139 - val_loss: 0.4434 - val_acc: 0.8000\n",
      "Epoch 1348/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8134 - val_loss: 0.4434 - val_acc: 0.8018\n",
      "Epoch 1349/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8133 - val_loss: 0.4453 - val_acc: 0.7998\n",
      "Epoch 1350/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8122 - val_loss: 0.4437 - val_acc: 0.8000\n",
      "Epoch 1351/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8129 - val_loss: 0.4477 - val_acc: 0.8028\n",
      "Epoch 1352/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8126 - val_loss: 0.4436 - val_acc: 0.8037\n",
      "Epoch 1353/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8123 - val_loss: 0.4441 - val_acc: 0.8004\n",
      "Epoch 1354/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8116 - val_loss: 0.4467 - val_acc: 0.7998\n",
      "Epoch 1355/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8140 - val_loss: 0.4421 - val_acc: 0.8002\n",
      "Epoch 1356/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4212 - acc: 0.8132 - val_loss: 0.4447 - val_acc: 0.8032\n",
      "Epoch 1357/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8138 - val_loss: 0.4445 - val_acc: 0.8000\n",
      "Epoch 1358/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8132 - val_loss: 0.4415 - val_acc: 0.8023\n",
      "Epoch 1359/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8144 - val_loss: 0.4444 - val_acc: 0.8009\n",
      "Epoch 1360/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8151 - val_loss: 0.4444 - val_acc: 0.7996\n",
      "Epoch 1361/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8139 - val_loss: 0.4433 - val_acc: 0.8024\n",
      "Epoch 1362/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8122 - val_loss: 0.4451 - val_acc: 0.8023\n",
      "Epoch 1363/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8124 - val_loss: 0.4510 - val_acc: 0.7979\n",
      "Epoch 1364/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8118 - val_loss: 0.4501 - val_acc: 0.7985\n",
      "Epoch 1365/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8138 - val_loss: 0.4447 - val_acc: 0.8022\n",
      "Epoch 1366/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4223 - acc: 0.8127 - val_loss: 0.4442 - val_acc: 0.7993\n",
      "Epoch 1367/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8129 - val_loss: 0.4428 - val_acc: 0.8020\n",
      "Epoch 1368/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8130 - val_loss: 0.4428 - val_acc: 0.8022\n",
      "Epoch 1369/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8126 - val_loss: 0.4473 - val_acc: 0.7989\n",
      "Epoch 1370/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8124 - val_loss: 0.4542 - val_acc: 0.7965\n",
      "Epoch 1371/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8130 - val_loss: 0.4456 - val_acc: 0.8028\n",
      "Epoch 1372/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8142 - val_loss: 0.4498 - val_acc: 0.7980\n",
      "Epoch 1373/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8126 - val_loss: 0.4477 - val_acc: 0.8015\n",
      "Epoch 1374/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8115 - val_loss: 0.4431 - val_acc: 0.8035\n",
      "Epoch 1375/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8136 - val_loss: 0.4516 - val_acc: 0.7976\n",
      "Epoch 1376/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8120 - val_loss: 0.4461 - val_acc: 0.8020\n",
      "Epoch 1377/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8135 - val_loss: 0.4446 - val_acc: 0.7987\n",
      "Epoch 1378/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8129 - val_loss: 0.4426 - val_acc: 0.8028\n",
      "Epoch 1379/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8133 - val_loss: 0.4448 - val_acc: 0.7991\n",
      "Epoch 1380/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8119 - val_loss: 0.4478 - val_acc: 0.7987\n",
      "Epoch 1381/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4219 - acc: 0.8123 - val_loss: 0.4444 - val_acc: 0.8013\n",
      "Epoch 1382/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8131 - val_loss: 0.4452 - val_acc: 0.8013\n",
      "Epoch 1383/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4221 - acc: 0.8113 - val_loss: 0.4433 - val_acc: 0.8022\n",
      "Epoch 1384/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4223 - acc: 0.8131 - val_loss: 0.4445 - val_acc: 0.7996\n",
      "Epoch 1385/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8149 - val_loss: 0.4464 - val_acc: 0.7985\n",
      "Epoch 1386/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8136 - val_loss: 0.4512 - val_acc: 0.7980\n",
      "Epoch 1387/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4210 - acc: 0.8131 - val_loss: 0.4479 - val_acc: 0.8026\n",
      "Epoch 1388/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8139 - val_loss: 0.4459 - val_acc: 0.8039\n",
      "Epoch 1389/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4216 - acc: 0.8132 - val_loss: 0.4443 - val_acc: 0.8022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1390/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4214 - acc: 0.8139 - val_loss: 0.4453 - val_acc: 0.8018\n",
      "Epoch 1391/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4211 - acc: 0.8128 - val_loss: 0.4466 - val_acc: 0.8011\n",
      "Epoch 1392/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4213 - acc: 0.8136 - val_loss: 0.4442 - val_acc: 0.8000\n",
      "Epoch 1393/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4211 - acc: 0.8140 - val_loss: 0.4435 - val_acc: 0.8007\n",
      "Epoch 1394/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8132 - val_loss: 0.4495 - val_acc: 0.7963\n",
      "Epoch 1395/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4218 - acc: 0.8134 - val_loss: 0.4430 - val_acc: 0.8057\n",
      "Epoch 1396/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4222 - acc: 0.8127 - val_loss: 0.4433 - val_acc: 0.8037\n",
      "Epoch 1397/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4211 - acc: 0.8140 - val_loss: 0.4481 - val_acc: 0.7990\n",
      "Epoch 1398/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4206 - acc: 0.8139 - val_loss: 0.4431 - val_acc: 0.8039\n",
      "Epoch 1399/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4214 - acc: 0.8127 - val_loss: 0.4468 - val_acc: 0.8009\n",
      "Epoch 1400/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4221 - acc: 0.8110 - val_loss: 0.4441 - val_acc: 0.8002\n",
      "Epoch 1401/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4217 - acc: 0.8140 - val_loss: 0.4497 - val_acc: 0.8026\n",
      "Epoch 1402/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4233 - acc: 0.8134 - val_loss: 0.4441 - val_acc: 0.7993\n",
      "Epoch 1403/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4215 - acc: 0.8139 - val_loss: 0.4439 - val_acc: 0.7979\n",
      "Epoch 1404/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4209 - acc: 0.8131 - val_loss: 0.4446 - val_acc: 0.8000\n",
      "Epoch 1405/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4209 - acc: 0.8131 - val_loss: 0.4462 - val_acc: 0.7993\n",
      "Epoch 1406/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8126 - val_loss: 0.4445 - val_acc: 0.8050\n",
      "Epoch 1407/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8147 - val_loss: 0.4438 - val_acc: 0.8026\n",
      "Epoch 1408/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8121 - val_loss: 0.4447 - val_acc: 0.8037\n",
      "Epoch 1409/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8137 - val_loss: 0.4442 - val_acc: 0.8009\n",
      "Epoch 1410/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4207 - acc: 0.8140 - val_loss: 0.4434 - val_acc: 0.8007\n",
      "Epoch 1411/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4213 - acc: 0.8142 - val_loss: 0.4428 - val_acc: 0.8037\n",
      "Epoch 1412/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4218 - acc: 0.8119 - val_loss: 0.4438 - val_acc: 0.8042\n",
      "Epoch 1413/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4216 - acc: 0.8136 - val_loss: 0.4439 - val_acc: 0.8022\n",
      "Epoch 1414/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4217 - acc: 0.8131 - val_loss: 0.4449 - val_acc: 0.8015\n",
      "Epoch 1415/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8135 - val_loss: 0.4448 - val_acc: 0.8011\n",
      "Epoch 1416/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8152 - val_loss: 0.4468 - val_acc: 0.8009\n",
      "Epoch 1417/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4220 - acc: 0.8123 - val_loss: 0.4436 - val_acc: 0.8013\n",
      "Epoch 1418/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8123 - val_loss: 0.4435 - val_acc: 0.8011\n",
      "Epoch 1419/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4207 - acc: 0.8143 - val_loss: 0.4461 - val_acc: 0.8015\n",
      "Epoch 1420/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4209 - acc: 0.8144 - val_loss: 0.4429 - val_acc: 0.8028\n",
      "Epoch 1421/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4216 - acc: 0.8141 - val_loss: 0.4436 - val_acc: 0.8024\n",
      "Epoch 1422/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4222 - acc: 0.8129 - val_loss: 0.4447 - val_acc: 0.8026\n",
      "Epoch 1423/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4218 - acc: 0.8144 - val_loss: 0.4462 - val_acc: 0.8009\n",
      "Epoch 1424/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8132 - val_loss: 0.4439 - val_acc: 0.8033\n",
      "Epoch 1425/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8118 - val_loss: 0.4461 - val_acc: 0.8004\n",
      "Epoch 1426/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8131 - val_loss: 0.4481 - val_acc: 0.8020\n",
      "Epoch 1427/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8143 - val_loss: 0.4451 - val_acc: 0.8004\n",
      "Epoch 1428/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8142 - val_loss: 0.4445 - val_acc: 0.8013\n",
      "Epoch 1429/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8126 - val_loss: 0.4446 - val_acc: 0.8015\n",
      "Epoch 1430/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8129 - val_loss: 0.4433 - val_acc: 0.8002\n",
      "Epoch 1431/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4216 - acc: 0.8141 - val_loss: 0.4433 - val_acc: 0.8018\n",
      "Epoch 1432/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4214 - acc: 0.8117 - val_loss: 0.4432 - val_acc: 0.8007\n",
      "Epoch 1433/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4217 - acc: 0.8127 - val_loss: 0.4451 - val_acc: 0.8009\n",
      "Epoch 1434/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8134 - val_loss: 0.4435 - val_acc: 0.8011\n",
      "Epoch 1435/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8148 - val_loss: 0.4442 - val_acc: 0.8031\n",
      "Epoch 1436/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8132 - val_loss: 0.4477 - val_acc: 0.8000\n",
      "Epoch 1437/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8142 - val_loss: 0.4452 - val_acc: 0.8007\n",
      "Epoch 1438/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4211 - acc: 0.8137 - val_loss: 0.4451 - val_acc: 0.8022\n",
      "Epoch 1439/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8135 - val_loss: 0.4447 - val_acc: 0.8015\n",
      "Epoch 1440/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4204 - acc: 0.8144 - val_loss: 0.4438 - val_acc: 0.8035\n",
      "Epoch 1441/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8131 - val_loss: 0.4443 - val_acc: 0.8015\n",
      "Epoch 1442/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8128 - val_loss: 0.4474 - val_acc: 0.7998\n",
      "Epoch 1443/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4224 - acc: 0.8131 - val_loss: 0.4446 - val_acc: 0.8015\n",
      "Epoch 1444/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4220 - acc: 0.8118 - val_loss: 0.4431 - val_acc: 0.8026\n",
      "Epoch 1445/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4206 - acc: 0.8134 - val_loss: 0.4462 - val_acc: 0.7982\n",
      "Epoch 1446/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8131 - val_loss: 0.4463 - val_acc: 0.7991\n",
      "Epoch 1447/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4214 - acc: 0.8141 - val_loss: 0.4430 - val_acc: 0.8028\n",
      "Epoch 1448/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8135 - val_loss: 0.4433 - val_acc: 0.8007\n",
      "Epoch 1449/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8113 - val_loss: 0.4433 - val_acc: 0.8018\n",
      "Epoch 1450/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4215 - acc: 0.8122 - val_loss: 0.4444 - val_acc: 0.8020\n",
      "Epoch 1451/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4209 - acc: 0.8145 - val_loss: 0.4436 - val_acc: 0.8011\n",
      "Epoch 1452/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4214 - acc: 0.8126 - val_loss: 0.4438 - val_acc: 0.8007\n",
      "Epoch 1453/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4223 - acc: 0.8143 - val_loss: 0.4433 - val_acc: 0.8031\n",
      "Epoch 1454/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8133 - val_loss: 0.4429 - val_acc: 0.8022\n",
      "Epoch 1455/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4216 - acc: 0.8131 - val_loss: 0.4467 - val_acc: 0.7996\n",
      "Epoch 1456/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4221 - acc: 0.8129 - val_loss: 0.4459 - val_acc: 0.7993\n",
      "Epoch 1457/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4222 - acc: 0.8122 - val_loss: 0.4431 - val_acc: 0.8035\n",
      "Epoch 1458/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4208 - acc: 0.8157 - val_loss: 0.4438 - val_acc: 0.8000\n",
      "Epoch 1459/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4208 - acc: 0.8123 - val_loss: 0.4439 - val_acc: 0.8002\n",
      "Epoch 1460/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4216 - acc: 0.8126 - val_loss: 0.4450 - val_acc: 0.8037\n",
      "Epoch 1461/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4221 - acc: 0.8123 - val_loss: 0.4434 - val_acc: 0.7996\n",
      "Epoch 1462/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4215 - acc: 0.8129 - val_loss: 0.4443 - val_acc: 0.8026\n",
      "Epoch 1463/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8131 - val_loss: 0.4432 - val_acc: 0.8020\n",
      "Epoch 1464/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4220 - acc: 0.8121 - val_loss: 0.4439 - val_acc: 0.8007\n",
      "Epoch 1465/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4214 - acc: 0.8136 - val_loss: 0.4462 - val_acc: 0.8019\n",
      "Epoch 1466/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4215 - acc: 0.8131 - val_loss: 0.4493 - val_acc: 0.8001\n",
      "Epoch 1467/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4224 - acc: 0.8143 - val_loss: 0.4451 - val_acc: 0.8002\n",
      "Epoch 1468/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8126 - val_loss: 0.4475 - val_acc: 0.7978\n",
      "Epoch 1469/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4211 - acc: 0.8131 - val_loss: 0.4458 - val_acc: 0.7958\n",
      "Epoch 1470/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8144 - val_loss: 0.4472 - val_acc: 0.8009\n",
      "Epoch 1471/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8137 - val_loss: 0.4456 - val_acc: 0.8026\n",
      "Epoch 1472/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8134 - val_loss: 0.4466 - val_acc: 0.7991\n",
      "Epoch 1473/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8142 - val_loss: 0.4439 - val_acc: 0.8002\n",
      "Epoch 1474/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8148 - val_loss: 0.4467 - val_acc: 0.7985\n",
      "Epoch 1475/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8137 - val_loss: 0.4479 - val_acc: 0.7945\n",
      "Epoch 1476/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4206 - acc: 0.8123 - val_loss: 0.4443 - val_acc: 0.8028\n",
      "Epoch 1477/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8137 - val_loss: 0.4445 - val_acc: 0.8018\n",
      "Epoch 1478/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8127 - val_loss: 0.4449 - val_acc: 0.8013\n",
      "Epoch 1479/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8125 - val_loss: 0.4469 - val_acc: 0.8015\n",
      "Epoch 1480/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8135 - val_loss: 0.4454 - val_acc: 0.8024\n",
      "Epoch 1481/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8136 - val_loss: 0.4435 - val_acc: 0.8046\n",
      "Epoch 1482/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8136 - val_loss: 0.4448 - val_acc: 0.8022\n",
      "Epoch 1483/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4209 - acc: 0.8134 - val_loss: 0.4450 - val_acc: 0.8028\n",
      "Epoch 1484/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8130 - val_loss: 0.4504 - val_acc: 0.7996\n",
      "Epoch 1485/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8116 - val_loss: 0.4438 - val_acc: 0.8015\n",
      "Epoch 1486/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4212 - acc: 0.8138 - val_loss: 0.4443 - val_acc: 0.8015\n",
      "Epoch 1487/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8136 - val_loss: 0.4452 - val_acc: 0.8011\n",
      "Epoch 1488/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4208 - acc: 0.8139 - val_loss: 0.4432 - val_acc: 0.8022\n",
      "Epoch 1489/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4211 - acc: 0.8138 - val_loss: 0.4443 - val_acc: 0.8020\n",
      "Epoch 1490/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4210 - acc: 0.8151 - val_loss: 0.4437 - val_acc: 0.8015\n",
      "Epoch 1491/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4208 - acc: 0.8128 - val_loss: 0.4488 - val_acc: 0.7997\n",
      "Epoch 1492/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4213 - acc: 0.8123 - val_loss: 0.4479 - val_acc: 0.7993\n",
      "Epoch 1493/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8118 - val_loss: 0.4443 - val_acc: 0.8002\n",
      "Epoch 1494/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8130 - val_loss: 0.4438 - val_acc: 0.8024\n",
      "Epoch 1495/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4209 - acc: 0.8140 - val_loss: 0.4447 - val_acc: 0.8007\n",
      "Epoch 1496/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4214 - acc: 0.8140 - val_loss: 0.4437 - val_acc: 0.8031\n",
      "Epoch 1497/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4210 - acc: 0.8130 - val_loss: 0.4458 - val_acc: 0.7996\n",
      "Epoch 1498/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4201 - acc: 0.8122 - val_loss: 0.4462 - val_acc: 0.8028\n",
      "Epoch 1499/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4207 - acc: 0.8114 - val_loss: 0.4547 - val_acc: 0.7932\n",
      "Epoch 1500/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8125 - val_loss: 0.4450 - val_acc: 0.8026\n",
      "Epoch 1501/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4222 - acc: 0.8113 - val_loss: 0.4435 - val_acc: 0.8022\n",
      "Epoch 1502/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8135 - val_loss: 0.4477 - val_acc: 0.7974\n",
      "Epoch 1503/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8131 - val_loss: 0.4472 - val_acc: 0.7996\n",
      "Epoch 1504/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8129 - val_loss: 0.4441 - val_acc: 0.8011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1505/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8123 - val_loss: 0.4500 - val_acc: 0.7952\n",
      "Epoch 1506/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4211 - acc: 0.8134 - val_loss: 0.4418 - val_acc: 0.8033\n",
      "Epoch 1507/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4214 - acc: 0.8158 - val_loss: 0.4438 - val_acc: 0.8015\n",
      "Epoch 1508/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8130 - val_loss: 0.4457 - val_acc: 0.8020\n",
      "Epoch 1509/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8131 - val_loss: 0.4443 - val_acc: 0.8013\n",
      "Epoch 1510/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8130 - val_loss: 0.4433 - val_acc: 0.8018\n",
      "Epoch 1511/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8132 - val_loss: 0.4448 - val_acc: 0.8023\n",
      "Epoch 1512/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8126 - val_loss: 0.4427 - val_acc: 0.8022\n",
      "Epoch 1513/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8139 - val_loss: 0.4432 - val_acc: 0.8031\n",
      "Epoch 1514/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4209 - acc: 0.8130 - val_loss: 0.4455 - val_acc: 0.8031\n",
      "Epoch 1515/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4211 - acc: 0.8125 - val_loss: 0.4484 - val_acc: 0.8000\n",
      "Epoch 1516/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8139 - val_loss: 0.4431 - val_acc: 0.8039\n",
      "Epoch 1517/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4213 - acc: 0.8150 - val_loss: 0.4445 - val_acc: 0.8022\n",
      "Epoch 1518/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4210 - acc: 0.8136 - val_loss: 0.4464 - val_acc: 0.8004\n",
      "Epoch 1519/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4205 - acc: 0.8144 - val_loss: 0.4458 - val_acc: 0.8053\n",
      "Epoch 1520/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8130 - val_loss: 0.4488 - val_acc: 0.7963\n",
      "Epoch 1521/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4217 - acc: 0.8126 - val_loss: 0.4461 - val_acc: 0.7985\n",
      "Epoch 1522/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8136 - val_loss: 0.4464 - val_acc: 0.8018\n",
      "Epoch 1523/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8145 - val_loss: 0.4433 - val_acc: 0.8018\n",
      "Epoch 1524/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8121 - val_loss: 0.4426 - val_acc: 0.8007\n",
      "Epoch 1525/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8118 - val_loss: 0.4446 - val_acc: 0.8022\n",
      "Epoch 1526/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8134 - val_loss: 0.4444 - val_acc: 0.7989\n",
      "Epoch 1527/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4213 - acc: 0.8134 - val_loss: 0.4427 - val_acc: 0.8013\n",
      "Epoch 1528/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8124 - val_loss: 0.4454 - val_acc: 0.8018\n",
      "Epoch 1529/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4209 - acc: 0.8145 - val_loss: 0.4445 - val_acc: 0.8009\n",
      "Epoch 1530/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8156 - val_loss: 0.4443 - val_acc: 0.7980\n",
      "Epoch 1531/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4214 - acc: 0.8125 - val_loss: 0.4462 - val_acc: 0.7993\n",
      "Epoch 1532/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4216 - acc: 0.8136 - val_loss: 0.4444 - val_acc: 0.8020\n",
      "Epoch 1533/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8141 - val_loss: 0.4440 - val_acc: 0.8044\n",
      "Epoch 1534/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8134 - val_loss: 0.4440 - val_acc: 0.7998\n",
      "Epoch 1535/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4199 - acc: 0.8134 - val_loss: 0.4436 - val_acc: 0.8013\n",
      "Epoch 1536/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4211 - acc: 0.8148 - val_loss: 0.4447 - val_acc: 0.7996\n",
      "Epoch 1537/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4206 - acc: 0.8130 - val_loss: 0.4460 - val_acc: 0.8015\n",
      "Epoch 1538/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4210 - acc: 0.8145 - val_loss: 0.4430 - val_acc: 0.7989\n",
      "Epoch 1539/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4210 - acc: 0.8135 - val_loss: 0.4432 - val_acc: 0.8028\n",
      "Epoch 1540/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8123 - val_loss: 0.4435 - val_acc: 0.8022\n",
      "Epoch 1541/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4208 - acc: 0.8139 - val_loss: 0.4456 - val_acc: 0.8004\n",
      "Epoch 1542/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8136 - val_loss: 0.4439 - val_acc: 0.8039\n",
      "Epoch 1543/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8151 - val_loss: 0.4463 - val_acc: 0.8009\n",
      "Epoch 1544/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4209 - acc: 0.8129 - val_loss: 0.4450 - val_acc: 0.8018\n",
      "Epoch 1545/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4208 - acc: 0.8133 - val_loss: 0.4439 - val_acc: 0.8004\n",
      "Epoch 1546/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4204 - acc: 0.8145 - val_loss: 0.4456 - val_acc: 0.8007\n",
      "Epoch 1547/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8144 - val_loss: 0.4451 - val_acc: 0.7989\n",
      "Epoch 1548/2000\n",
      "13834/13834 [==============================] - 0s 23us/step - loss: 0.4212 - acc: 0.8139 - val_loss: 0.4452 - val_acc: 0.8020\n",
      "Epoch 1549/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8152 - val_loss: 0.4472 - val_acc: 0.7998\n",
      "Epoch 1550/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8129 - val_loss: 0.4445 - val_acc: 0.7996\n",
      "Epoch 1551/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8134 - val_loss: 0.4473 - val_acc: 0.8002\n",
      "Epoch 1552/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8143 - val_loss: 0.4432 - val_acc: 0.8013\n",
      "Epoch 1553/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8161 - val_loss: 0.4460 - val_acc: 0.7995\n",
      "Epoch 1554/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8135 - val_loss: 0.4469 - val_acc: 0.7982\n",
      "Epoch 1555/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8129 - val_loss: 0.4449 - val_acc: 0.8039\n",
      "Epoch 1556/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8141 - val_loss: 0.4458 - val_acc: 0.8015\n",
      "Epoch 1557/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8137 - val_loss: 0.4433 - val_acc: 0.8004\n",
      "Epoch 1558/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8130 - val_loss: 0.4430 - val_acc: 0.8018\n",
      "Epoch 1559/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8139 - val_loss: 0.4482 - val_acc: 0.7974\n",
      "Epoch 1560/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8151 - val_loss: 0.4463 - val_acc: 0.8000\n",
      "Epoch 1561/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8129 - val_loss: 0.4508 - val_acc: 0.7954\n",
      "Epoch 1562/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4200 - acc: 0.8138 - val_loss: 0.4440 - val_acc: 0.8046\n",
      "Epoch 1563/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8128 - val_loss: 0.4438 - val_acc: 0.8007\n",
      "Epoch 1564/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8124 - val_loss: 0.4425 - val_acc: 0.8024\n",
      "Epoch 1565/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8136 - val_loss: 0.4444 - val_acc: 0.7998\n",
      "Epoch 1566/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8136 - val_loss: 0.4449 - val_acc: 0.7996\n",
      "Epoch 1567/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8141 - val_loss: 0.4424 - val_acc: 0.8026\n",
      "Epoch 1568/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8134 - val_loss: 0.4450 - val_acc: 0.8024\n",
      "Epoch 1569/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8138 - val_loss: 0.4478 - val_acc: 0.7976\n",
      "Epoch 1570/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4215 - acc: 0.8139 - val_loss: 0.4502 - val_acc: 0.7998\n",
      "Epoch 1571/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8135 - val_loss: 0.4473 - val_acc: 0.8028\n",
      "Epoch 1572/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8126 - val_loss: 0.4451 - val_acc: 0.8020\n",
      "Epoch 1573/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4197 - acc: 0.8126 - val_loss: 0.4491 - val_acc: 0.7972\n",
      "Epoch 1574/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8155 - val_loss: 0.4453 - val_acc: 0.7980\n",
      "Epoch 1575/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8158 - val_loss: 0.4448 - val_acc: 0.8009\n",
      "Epoch 1576/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8131 - val_loss: 0.4450 - val_acc: 0.8007\n",
      "Epoch 1577/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4204 - acc: 0.8115 - val_loss: 0.4465 - val_acc: 0.8018\n",
      "Epoch 1578/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4195 - acc: 0.8154 - val_loss: 0.4461 - val_acc: 0.7980\n",
      "Epoch 1579/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4192 - acc: 0.8136 - val_loss: 0.4446 - val_acc: 0.8009\n",
      "Epoch 1580/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8120 - val_loss: 0.4452 - val_acc: 0.8022\n",
      "Epoch 1581/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8136 - val_loss: 0.4462 - val_acc: 0.8002\n",
      "Epoch 1582/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8141 - val_loss: 0.4456 - val_acc: 0.8000\n",
      "Epoch 1583/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8144 - val_loss: 0.4470 - val_acc: 0.8020\n",
      "Epoch 1584/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4209 - acc: 0.8123 - val_loss: 0.4431 - val_acc: 0.8024\n",
      "Epoch 1585/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4197 - acc: 0.8149 - val_loss: 0.4480 - val_acc: 0.7963\n",
      "Epoch 1586/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8148 - val_loss: 0.4456 - val_acc: 0.8009\n",
      "Epoch 1587/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8137 - val_loss: 0.4455 - val_acc: 0.8044\n",
      "Epoch 1588/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8136 - val_loss: 0.4444 - val_acc: 0.8004\n",
      "Epoch 1589/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8143 - val_loss: 0.4466 - val_acc: 0.7996\n",
      "Epoch 1590/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8124 - val_loss: 0.4454 - val_acc: 0.8048\n",
      "Epoch 1591/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4212 - acc: 0.8140 - val_loss: 0.4450 - val_acc: 0.8013\n",
      "Epoch 1592/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8143 - val_loss: 0.4465 - val_acc: 0.8011\n",
      "Epoch 1593/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8134 - val_loss: 0.4446 - val_acc: 0.8018\n",
      "Epoch 1594/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8153 - val_loss: 0.4458 - val_acc: 0.8015\n",
      "Epoch 1595/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8134 - val_loss: 0.4444 - val_acc: 0.8000\n",
      "Epoch 1596/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8162 - val_loss: 0.4488 - val_acc: 0.7980\n",
      "Epoch 1597/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8137 - val_loss: 0.4419 - val_acc: 0.8011\n",
      "Epoch 1598/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8128 - val_loss: 0.4459 - val_acc: 0.7998\n",
      "Epoch 1599/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8134 - val_loss: 0.4442 - val_acc: 0.7998\n",
      "Epoch 1600/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4200 - acc: 0.8142 - val_loss: 0.4457 - val_acc: 0.7996\n",
      "Epoch 1601/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8137 - val_loss: 0.4469 - val_acc: 0.7978\n",
      "Epoch 1602/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8144 - val_loss: 0.4460 - val_acc: 0.7987\n",
      "Epoch 1603/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8132 - val_loss: 0.4444 - val_acc: 0.7980\n",
      "Epoch 1604/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4199 - acc: 0.8136 - val_loss: 0.4443 - val_acc: 0.7998\n",
      "Epoch 1605/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4199 - acc: 0.8139 - val_loss: 0.4442 - val_acc: 0.8018\n",
      "Epoch 1606/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8134 - val_loss: 0.4444 - val_acc: 0.8024\n",
      "Epoch 1607/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4197 - acc: 0.8136 - val_loss: 0.4486 - val_acc: 0.7978\n",
      "Epoch 1608/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8160 - val_loss: 0.4473 - val_acc: 0.7993\n",
      "Epoch 1609/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8142 - val_loss: 0.4450 - val_acc: 0.8007\n",
      "Epoch 1610/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8162 - val_loss: 0.4450 - val_acc: 0.8011\n",
      "Epoch 1611/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8140 - val_loss: 0.4443 - val_acc: 0.8011\n",
      "Epoch 1612/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8148 - val_loss: 0.4437 - val_acc: 0.8004\n",
      "Epoch 1613/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4216 - acc: 0.8127 - val_loss: 0.4529 - val_acc: 0.7978\n",
      "Epoch 1614/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4213 - acc: 0.8126 - val_loss: 0.4430 - val_acc: 0.8022\n",
      "Epoch 1615/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4207 - acc: 0.8146 - val_loss: 0.4439 - val_acc: 0.8022\n",
      "Epoch 1616/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8126 - val_loss: 0.4444 - val_acc: 0.8009\n",
      "Epoch 1617/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8159 - val_loss: 0.4434 - val_acc: 0.8011\n",
      "Epoch 1618/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8138 - val_loss: 0.4441 - val_acc: 0.8018\n",
      "Epoch 1619/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4207 - acc: 0.8133 - val_loss: 0.4437 - val_acc: 0.8011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1620/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8134 - val_loss: 0.4474 - val_acc: 0.8002\n",
      "Epoch 1621/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4211 - acc: 0.8131 - val_loss: 0.4467 - val_acc: 0.8015\n",
      "Epoch 1622/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4211 - acc: 0.8136 - val_loss: 0.4451 - val_acc: 0.8022\n",
      "Epoch 1623/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8139 - val_loss: 0.4450 - val_acc: 0.7982\n",
      "Epoch 1624/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8142 - val_loss: 0.4438 - val_acc: 0.8009\n",
      "Epoch 1625/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8126 - val_loss: 0.4467 - val_acc: 0.8000\n",
      "Epoch 1626/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8126 - val_loss: 0.4453 - val_acc: 0.8002\n",
      "Epoch 1627/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4207 - acc: 0.8147 - val_loss: 0.4462 - val_acc: 0.8015\n",
      "Epoch 1628/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4208 - acc: 0.8140 - val_loss: 0.4447 - val_acc: 0.8002\n",
      "Epoch 1629/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8139 - val_loss: 0.4470 - val_acc: 0.7980\n",
      "Epoch 1630/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8132 - val_loss: 0.4465 - val_acc: 0.8007\n",
      "Epoch 1631/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8122 - val_loss: 0.4487 - val_acc: 0.7982\n",
      "Epoch 1632/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8152 - val_loss: 0.4459 - val_acc: 0.7998\n",
      "Epoch 1633/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4204 - acc: 0.8127 - val_loss: 0.4437 - val_acc: 0.8022\n",
      "Epoch 1634/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4211 - acc: 0.8136 - val_loss: 0.4457 - val_acc: 0.8033\n",
      "Epoch 1635/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8130 - val_loss: 0.4430 - val_acc: 0.8031\n",
      "Epoch 1636/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8139 - val_loss: 0.4449 - val_acc: 0.8004\n",
      "Epoch 1637/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4209 - acc: 0.8142 - val_loss: 0.4457 - val_acc: 0.7993\n",
      "Epoch 1638/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4204 - acc: 0.8142 - val_loss: 0.4458 - val_acc: 0.8007\n",
      "Epoch 1639/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8146 - val_loss: 0.4442 - val_acc: 0.8018\n",
      "Epoch 1640/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8136 - val_loss: 0.4435 - val_acc: 0.8018\n",
      "Epoch 1641/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8160 - val_loss: 0.4475 - val_acc: 0.8022\n",
      "Epoch 1642/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8134 - val_loss: 0.4459 - val_acc: 0.8031\n",
      "Epoch 1643/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4200 - acc: 0.8140 - val_loss: 0.4468 - val_acc: 0.7978\n",
      "Epoch 1644/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8136 - val_loss: 0.4458 - val_acc: 0.8020\n",
      "Epoch 1645/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8132 - val_loss: 0.4463 - val_acc: 0.7996\n",
      "Epoch 1646/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4204 - acc: 0.8144 - val_loss: 0.4454 - val_acc: 0.8007\n",
      "Epoch 1647/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8158 - val_loss: 0.4457 - val_acc: 0.8009\n",
      "Epoch 1648/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8134 - val_loss: 0.4506 - val_acc: 0.7958\n",
      "Epoch 1649/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8137 - val_loss: 0.4460 - val_acc: 0.8013\n",
      "Epoch 1650/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4199 - acc: 0.8139 - val_loss: 0.4453 - val_acc: 0.8004\n",
      "Epoch 1651/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4194 - acc: 0.8142 - val_loss: 0.4457 - val_acc: 0.7984\n",
      "Epoch 1652/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8129 - val_loss: 0.4493 - val_acc: 0.7965\n",
      "Epoch 1653/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8142 - val_loss: 0.4461 - val_acc: 0.7996\n",
      "Epoch 1654/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8141 - val_loss: 0.4453 - val_acc: 0.7996\n",
      "Epoch 1655/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4200 - acc: 0.8137 - val_loss: 0.4447 - val_acc: 0.8013\n",
      "Epoch 1656/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8145 - val_loss: 0.4463 - val_acc: 0.7987\n",
      "Epoch 1657/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4196 - acc: 0.8134 - val_loss: 0.4447 - val_acc: 0.7980\n",
      "Epoch 1658/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4193 - acc: 0.8144 - val_loss: 0.4441 - val_acc: 0.8009\n",
      "Epoch 1659/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8144 - val_loss: 0.4462 - val_acc: 0.7989\n",
      "Epoch 1660/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8142 - val_loss: 0.4442 - val_acc: 0.8028\n",
      "Epoch 1661/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8139 - val_loss: 0.4470 - val_acc: 0.8009\n",
      "Epoch 1662/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4199 - acc: 0.8145 - val_loss: 0.4453 - val_acc: 0.8046\n",
      "Epoch 1663/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4198 - acc: 0.8130 - val_loss: 0.4473 - val_acc: 0.7999\n",
      "Epoch 1664/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8138 - val_loss: 0.4449 - val_acc: 0.8018\n",
      "Epoch 1665/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4194 - acc: 0.8159 - val_loss: 0.4537 - val_acc: 0.7978\n",
      "Epoch 1666/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8147 - val_loss: 0.4459 - val_acc: 0.8015\n",
      "Epoch 1667/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8132 - val_loss: 0.4457 - val_acc: 0.8031\n",
      "Epoch 1668/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8140 - val_loss: 0.4446 - val_acc: 0.8018\n",
      "Epoch 1669/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4199 - acc: 0.8153 - val_loss: 0.4440 - val_acc: 0.8024\n",
      "Epoch 1670/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4200 - acc: 0.8149 - val_loss: 0.4465 - val_acc: 0.8009\n",
      "Epoch 1671/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8145 - val_loss: 0.4500 - val_acc: 0.8007\n",
      "Epoch 1672/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4191 - acc: 0.8129 - val_loss: 0.4523 - val_acc: 0.7989\n",
      "Epoch 1673/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8139 - val_loss: 0.4444 - val_acc: 0.8009\n",
      "Epoch 1674/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8141 - val_loss: 0.4446 - val_acc: 0.8009\n",
      "Epoch 1675/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4199 - acc: 0.8137 - val_loss: 0.4473 - val_acc: 0.8024\n",
      "Epoch 1676/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4193 - acc: 0.8131 - val_loss: 0.4548 - val_acc: 0.7958\n",
      "Epoch 1677/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8139 - val_loss: 0.4464 - val_acc: 0.8007\n",
      "Epoch 1678/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4195 - acc: 0.8151 - val_loss: 0.4445 - val_acc: 0.8020\n",
      "Epoch 1679/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8140 - val_loss: 0.4436 - val_acc: 0.8020\n",
      "Epoch 1680/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4190 - acc: 0.8131 - val_loss: 0.4426 - val_acc: 0.8022\n",
      "Epoch 1681/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4198 - acc: 0.8142 - val_loss: 0.4428 - val_acc: 0.8022\n",
      "Epoch 1682/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4193 - acc: 0.8152 - val_loss: 0.4454 - val_acc: 0.8002\n",
      "Epoch 1683/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4200 - acc: 0.8146 - val_loss: 0.4461 - val_acc: 0.8024\n",
      "Epoch 1684/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8155 - val_loss: 0.4469 - val_acc: 0.8009\n",
      "Epoch 1685/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8136 - val_loss: 0.4470 - val_acc: 0.8022\n",
      "Epoch 1686/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4209 - acc: 0.8136 - val_loss: 0.4447 - val_acc: 0.8009\n",
      "Epoch 1687/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4196 - acc: 0.8138 - val_loss: 0.4464 - val_acc: 0.8011\n",
      "Epoch 1688/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4196 - acc: 0.8142 - val_loss: 0.4437 - val_acc: 0.8002\n",
      "Epoch 1689/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4198 - acc: 0.8150 - val_loss: 0.4465 - val_acc: 0.8015\n",
      "Epoch 1690/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8136 - val_loss: 0.4448 - val_acc: 0.8004\n",
      "Epoch 1691/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4199 - acc: 0.8127 - val_loss: 0.4458 - val_acc: 0.8000\n",
      "Epoch 1692/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8133 - val_loss: 0.4438 - val_acc: 0.8024\n",
      "Epoch 1693/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4189 - acc: 0.8135 - val_loss: 0.4438 - val_acc: 0.8028\n",
      "Epoch 1694/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4195 - acc: 0.8155 - val_loss: 0.4521 - val_acc: 0.7958\n",
      "Epoch 1695/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4199 - acc: 0.8146 - val_loss: 0.4447 - val_acc: 0.8007\n",
      "Epoch 1696/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8144 - val_loss: 0.4473 - val_acc: 0.8020\n",
      "Epoch 1697/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8139 - val_loss: 0.4447 - val_acc: 0.8023\n",
      "Epoch 1698/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4195 - acc: 0.8147 - val_loss: 0.4453 - val_acc: 0.8031\n",
      "Epoch 1699/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4190 - acc: 0.8149 - val_loss: 0.4456 - val_acc: 0.7993\n",
      "Epoch 1700/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8130 - val_loss: 0.4434 - val_acc: 0.8022\n",
      "Epoch 1701/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4200 - acc: 0.8140 - val_loss: 0.4443 - val_acc: 0.8018\n",
      "Epoch 1702/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8126 - val_loss: 0.4464 - val_acc: 0.8011\n",
      "Epoch 1703/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4209 - acc: 0.8139 - val_loss: 0.4487 - val_acc: 0.8011\n",
      "Epoch 1704/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8153 - val_loss: 0.4429 - val_acc: 0.8031\n",
      "Epoch 1705/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8154 - val_loss: 0.4448 - val_acc: 0.8013\n",
      "Epoch 1706/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8147 - val_loss: 0.4446 - val_acc: 0.8002\n",
      "Epoch 1707/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4206 - acc: 0.8136 - val_loss: 0.4451 - val_acc: 0.7987\n",
      "Epoch 1708/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4209 - acc: 0.8145 - val_loss: 0.4440 - val_acc: 0.8015\n",
      "Epoch 1709/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4202 - acc: 0.8152 - val_loss: 0.4455 - val_acc: 0.8024\n",
      "Epoch 1710/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4211 - acc: 0.8141 - val_loss: 0.4448 - val_acc: 0.8020\n",
      "Epoch 1711/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4216 - acc: 0.8129 - val_loss: 0.4455 - val_acc: 0.8011\n",
      "Epoch 1712/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8138 - val_loss: 0.4453 - val_acc: 0.8026\n",
      "Epoch 1713/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4199 - acc: 0.8135 - val_loss: 0.4450 - val_acc: 0.8000\n",
      "Epoch 1714/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4207 - acc: 0.8126 - val_loss: 0.4443 - val_acc: 0.8026\n",
      "Epoch 1715/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4211 - acc: 0.8140 - val_loss: 0.4463 - val_acc: 0.8002\n",
      "Epoch 1716/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4207 - acc: 0.8135 - val_loss: 0.4439 - val_acc: 0.8020\n",
      "Epoch 1717/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4209 - acc: 0.8129 - val_loss: 0.4462 - val_acc: 0.8028\n",
      "Epoch 1718/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4206 - acc: 0.8134 - val_loss: 0.4450 - val_acc: 0.7991\n",
      "Epoch 1719/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4211 - acc: 0.8129 - val_loss: 0.4459 - val_acc: 0.8028\n",
      "Epoch 1720/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4204 - acc: 0.8162 - val_loss: 0.4466 - val_acc: 0.7993\n",
      "Epoch 1721/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4201 - acc: 0.8143 - val_loss: 0.4457 - val_acc: 0.8044\n",
      "Epoch 1722/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8157 - val_loss: 0.4487 - val_acc: 0.8013\n",
      "Epoch 1723/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4202 - acc: 0.8139 - val_loss: 0.4475 - val_acc: 0.7998\n",
      "Epoch 1724/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8144 - val_loss: 0.4473 - val_acc: 0.8000\n",
      "Epoch 1725/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4205 - acc: 0.8152 - val_loss: 0.4440 - val_acc: 0.8020\n",
      "Epoch 1726/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4202 - acc: 0.8134 - val_loss: 0.4441 - val_acc: 0.8020\n",
      "Epoch 1727/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4201 - acc: 0.8134 - val_loss: 0.4472 - val_acc: 0.7982\n",
      "Epoch 1728/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4199 - acc: 0.8135 - val_loss: 0.4446 - val_acc: 0.8022\n",
      "Epoch 1729/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8135 - val_loss: 0.4450 - val_acc: 0.7998\n",
      "Epoch 1730/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8142 - val_loss: 0.4441 - val_acc: 0.8015\n",
      "Epoch 1731/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8118 - val_loss: 0.4459 - val_acc: 0.7978\n",
      "Epoch 1732/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8144 - val_loss: 0.4491 - val_acc: 0.7985\n",
      "Epoch 1733/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8149 - val_loss: 0.4435 - val_acc: 0.8037\n",
      "Epoch 1734/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8162 - val_loss: 0.4444 - val_acc: 0.8007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1735/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8149 - val_loss: 0.4446 - val_acc: 0.8039\n",
      "Epoch 1736/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4202 - acc: 0.8136 - val_loss: 0.4455 - val_acc: 0.8028\n",
      "Epoch 1737/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8149 - val_loss: 0.4452 - val_acc: 0.8018\n",
      "Epoch 1738/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4199 - acc: 0.8147 - val_loss: 0.4464 - val_acc: 0.7974\n",
      "Epoch 1739/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4203 - acc: 0.8136 - val_loss: 0.4459 - val_acc: 0.8007\n",
      "Epoch 1740/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4202 - acc: 0.8135 - val_loss: 0.4505 - val_acc: 0.7987\n",
      "Epoch 1741/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4191 - acc: 0.8133 - val_loss: 0.4453 - val_acc: 0.8028\n",
      "Epoch 1742/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8139 - val_loss: 0.4479 - val_acc: 0.8000\n",
      "Epoch 1743/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8147 - val_loss: 0.4504 - val_acc: 0.8002\n",
      "Epoch 1744/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4204 - acc: 0.8143 - val_loss: 0.4455 - val_acc: 0.8002\n",
      "Epoch 1745/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8136 - val_loss: 0.4485 - val_acc: 0.8004\n",
      "Epoch 1746/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8126 - val_loss: 0.4480 - val_acc: 0.8013\n",
      "Epoch 1747/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4207 - acc: 0.8134 - val_loss: 0.4467 - val_acc: 0.8000\n",
      "Epoch 1748/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4204 - acc: 0.8133 - val_loss: 0.4453 - val_acc: 0.8022\n",
      "Epoch 1749/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8145 - val_loss: 0.4458 - val_acc: 0.8000\n",
      "Epoch 1750/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8157 - val_loss: 0.4457 - val_acc: 0.8018\n",
      "Epoch 1751/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4191 - acc: 0.8143 - val_loss: 0.4450 - val_acc: 0.8000\n",
      "Epoch 1752/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4201 - acc: 0.8139 - val_loss: 0.4460 - val_acc: 0.8007\n",
      "Epoch 1753/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4203 - acc: 0.8148 - val_loss: 0.4468 - val_acc: 0.8000\n",
      "Epoch 1754/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8159 - val_loss: 0.4454 - val_acc: 0.8033\n",
      "Epoch 1755/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4199 - acc: 0.8149 - val_loss: 0.4452 - val_acc: 0.7993\n",
      "Epoch 1756/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8146 - val_loss: 0.4438 - val_acc: 0.8011\n",
      "Epoch 1757/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8151 - val_loss: 0.4440 - val_acc: 0.8024\n",
      "Epoch 1758/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8152 - val_loss: 0.4498 - val_acc: 0.7993\n",
      "Epoch 1759/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8118 - val_loss: 0.4441 - val_acc: 0.8009\n",
      "Epoch 1760/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4208 - acc: 0.8140 - val_loss: 0.4458 - val_acc: 0.8024\n",
      "Epoch 1761/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.8146 - val_loss: 0.4443 - val_acc: 0.8007\n",
      "Epoch 1762/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.8124 - val_loss: 0.4486 - val_acc: 0.7978\n",
      "Epoch 1763/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8152 - val_loss: 0.4438 - val_acc: 0.8039\n",
      "Epoch 1764/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4199 - acc: 0.8152 - val_loss: 0.4461 - val_acc: 0.8009\n",
      "Epoch 1765/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4199 - acc: 0.8136 - val_loss: 0.4463 - val_acc: 0.8000\n",
      "Epoch 1766/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8152 - val_loss: 0.4520 - val_acc: 0.7958\n",
      "Epoch 1767/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4205 - acc: 0.8123 - val_loss: 0.4442 - val_acc: 0.8042\n",
      "Epoch 1768/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8144 - val_loss: 0.4445 - val_acc: 0.8015\n",
      "Epoch 1769/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8154 - val_loss: 0.4447 - val_acc: 0.8018\n",
      "Epoch 1770/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8135 - val_loss: 0.4449 - val_acc: 0.8020\n",
      "Epoch 1771/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8128 - val_loss: 0.4495 - val_acc: 0.8004\n",
      "Epoch 1772/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8138 - val_loss: 0.4470 - val_acc: 0.8004\n",
      "Epoch 1773/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4195 - acc: 0.8139 - val_loss: 0.4463 - val_acc: 0.8002\n",
      "Epoch 1774/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4193 - acc: 0.8142 - val_loss: 0.4473 - val_acc: 0.8053\n",
      "Epoch 1775/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8146 - val_loss: 0.4470 - val_acc: 0.8031\n",
      "Epoch 1776/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8136 - val_loss: 0.4447 - val_acc: 0.8031\n",
      "Epoch 1777/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4199 - acc: 0.8135 - val_loss: 0.4569 - val_acc: 0.7947\n",
      "Epoch 1778/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4204 - acc: 0.8141 - val_loss: 0.4444 - val_acc: 0.8031\n",
      "Epoch 1779/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4205 - acc: 0.8147 - val_loss: 0.4489 - val_acc: 0.7978\n",
      "Epoch 1780/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8136 - val_loss: 0.4507 - val_acc: 0.7965\n",
      "Epoch 1781/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4204 - acc: 0.8152 - val_loss: 0.4454 - val_acc: 0.8009\n",
      "Epoch 1782/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4200 - acc: 0.8147 - val_loss: 0.4460 - val_acc: 0.8028\n",
      "Epoch 1783/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4199 - acc: 0.8138 - val_loss: 0.4443 - val_acc: 0.8000\n",
      "Epoch 1784/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8150 - val_loss: 0.4446 - val_acc: 0.8020\n",
      "Epoch 1785/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4201 - acc: 0.8162 - val_loss: 0.4458 - val_acc: 0.8002\n",
      "Epoch 1786/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4192 - acc: 0.8151 - val_loss: 0.4447 - val_acc: 0.8024\n",
      "Epoch 1787/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4199 - acc: 0.8142 - val_loss: 0.4482 - val_acc: 0.8013\n",
      "Epoch 1788/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8157 - val_loss: 0.4434 - val_acc: 0.8033\n",
      "Epoch 1789/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8118 - val_loss: 0.4477 - val_acc: 0.7996\n",
      "Epoch 1790/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4207 - acc: 0.8142 - val_loss: 0.4489 - val_acc: 0.7985\n",
      "Epoch 1791/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4193 - acc: 0.8167 - val_loss: 0.4470 - val_acc: 0.8011\n",
      "Epoch 1792/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4202 - acc: 0.8144 - val_loss: 0.4446 - val_acc: 0.8024\n",
      "Epoch 1793/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4193 - acc: 0.8166 - val_loss: 0.4475 - val_acc: 0.8015\n",
      "Epoch 1794/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8135 - val_loss: 0.4467 - val_acc: 0.7991\n",
      "Epoch 1795/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4206 - acc: 0.8129 - val_loss: 0.4450 - val_acc: 0.8018\n",
      "Epoch 1796/2000\n",
      "13834/13834 [==============================] - 0s 28us/step - loss: 0.4189 - acc: 0.8142 - val_loss: 0.4453 - val_acc: 0.8028\n",
      "Epoch 1797/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4192 - acc: 0.8150 - val_loss: 0.4434 - val_acc: 0.8035\n",
      "Epoch 1798/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4194 - acc: 0.8163 - val_loss: 0.4484 - val_acc: 0.7998\n",
      "Epoch 1799/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8149 - val_loss: 0.4448 - val_acc: 0.8015\n",
      "Epoch 1800/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4201 - acc: 0.8160 - val_loss: 0.4470 - val_acc: 0.8024\n",
      "Epoch 1801/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4201 - acc: 0.8139 - val_loss: 0.4456 - val_acc: 0.8015\n",
      "Epoch 1802/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8155 - val_loss: 0.4438 - val_acc: 0.8035\n",
      "Epoch 1803/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4188 - acc: 0.8155 - val_loss: 0.4465 - val_acc: 0.8018\n",
      "Epoch 1804/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8138 - val_loss: 0.4462 - val_acc: 0.8000\n",
      "Epoch 1805/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4199 - acc: 0.8144 - val_loss: 0.4438 - val_acc: 0.8039\n",
      "Epoch 1806/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8142 - val_loss: 0.4446 - val_acc: 0.8042\n",
      "Epoch 1807/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4198 - acc: 0.8165 - val_loss: 0.4470 - val_acc: 0.8024\n",
      "Epoch 1808/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4191 - acc: 0.8160 - val_loss: 0.4437 - val_acc: 0.8028\n",
      "Epoch 1809/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8132 - val_loss: 0.4447 - val_acc: 0.8022\n",
      "Epoch 1810/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8134 - val_loss: 0.4432 - val_acc: 0.8031\n",
      "Epoch 1811/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8143 - val_loss: 0.4428 - val_acc: 0.8022\n",
      "Epoch 1812/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4197 - acc: 0.8147 - val_loss: 0.4455 - val_acc: 0.8011\n",
      "Epoch 1813/2000\n",
      "13834/13834 [==============================] - 0s 29us/step - loss: 0.4191 - acc: 0.8143 - val_loss: 0.4432 - val_acc: 0.8039\n",
      "Epoch 1814/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4187 - acc: 0.8161 - val_loss: 0.4458 - val_acc: 0.8020\n",
      "Epoch 1815/2000\n",
      "13834/13834 [==============================] - 0s 29us/step - loss: 0.4201 - acc: 0.8139 - val_loss: 0.4457 - val_acc: 0.8013\n",
      "Epoch 1816/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4205 - acc: 0.8140 - val_loss: 0.4466 - val_acc: 0.8013\n",
      "Epoch 1817/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4200 - acc: 0.8149 - val_loss: 0.4466 - val_acc: 0.8000\n",
      "Epoch 1818/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8147 - val_loss: 0.4463 - val_acc: 0.8015\n",
      "Epoch 1819/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4204 - acc: 0.8144 - val_loss: 0.4454 - val_acc: 0.8031\n",
      "Epoch 1820/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8150 - val_loss: 0.4438 - val_acc: 0.8042\n",
      "Epoch 1821/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4191 - acc: 0.8144 - val_loss: 0.4480 - val_acc: 0.8013\n",
      "Epoch 1822/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8140 - val_loss: 0.4455 - val_acc: 0.7996\n",
      "Epoch 1823/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4189 - acc: 0.8144 - val_loss: 0.4448 - val_acc: 0.8031\n",
      "Epoch 1824/2000\n",
      "13834/13834 [==============================] - 0s 28us/step - loss: 0.4196 - acc: 0.8140 - val_loss: 0.4472 - val_acc: 0.8028\n",
      "Epoch 1825/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4207 - acc: 0.8148 - val_loss: 0.4432 - val_acc: 0.8028\n",
      "Epoch 1826/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4195 - acc: 0.8154 - val_loss: 0.4458 - val_acc: 0.8035\n",
      "Epoch 1827/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4191 - acc: 0.8149 - val_loss: 0.4474 - val_acc: 0.8024\n",
      "Epoch 1828/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4202 - acc: 0.8145 - val_loss: 0.4458 - val_acc: 0.8031\n",
      "Epoch 1829/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4200 - acc: 0.8144 - val_loss: 0.4471 - val_acc: 0.7996\n",
      "Epoch 1830/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8170 - val_loss: 0.4463 - val_acc: 0.8044\n",
      "Epoch 1831/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8136 - val_loss: 0.4442 - val_acc: 0.8004\n",
      "Epoch 1832/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4209 - acc: 0.8147 - val_loss: 0.4446 - val_acc: 0.8031\n",
      "Epoch 1833/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4202 - acc: 0.8142 - val_loss: 0.4503 - val_acc: 0.8018\n",
      "Epoch 1834/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8142 - val_loss: 0.4472 - val_acc: 0.8004\n",
      "Epoch 1835/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8154 - val_loss: 0.4525 - val_acc: 0.8007\n",
      "Epoch 1836/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4199 - acc: 0.8141 - val_loss: 0.4464 - val_acc: 0.8028\n",
      "Epoch 1837/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8144 - val_loss: 0.4452 - val_acc: 0.8013\n",
      "Epoch 1838/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4192 - acc: 0.8166 - val_loss: 0.4509 - val_acc: 0.8022\n",
      "Epoch 1839/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4199 - acc: 0.8126 - val_loss: 0.4475 - val_acc: 0.8033\n",
      "Epoch 1840/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4202 - acc: 0.8138 - val_loss: 0.4461 - val_acc: 0.8033\n",
      "Epoch 1841/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4201 - acc: 0.8131 - val_loss: 0.4462 - val_acc: 0.8024\n",
      "Epoch 1842/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4197 - acc: 0.8139 - val_loss: 0.4473 - val_acc: 0.8015\n",
      "Epoch 1843/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8148 - val_loss: 0.4458 - val_acc: 0.8018\n",
      "Epoch 1844/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4203 - acc: 0.8136 - val_loss: 0.4462 - val_acc: 0.8020\n",
      "Epoch 1845/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8157 - val_loss: 0.4453 - val_acc: 0.8011\n",
      "Epoch 1846/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4209 - acc: 0.8132 - val_loss: 0.4453 - val_acc: 0.8015\n",
      "Epoch 1847/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4196 - acc: 0.8148 - val_loss: 0.4482 - val_acc: 0.7985\n",
      "Epoch 1848/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4196 - acc: 0.8147 - val_loss: 0.4458 - val_acc: 0.8031\n",
      "Epoch 1849/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4205 - acc: 0.8138 - val_loss: 0.4457 - val_acc: 0.8013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1850/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4201 - acc: 0.8151 - val_loss: 0.4465 - val_acc: 0.8020\n",
      "Epoch 1851/2000\n",
      "13834/13834 [==============================] - 0s 28us/step - loss: 0.4191 - acc: 0.8130 - val_loss: 0.4524 - val_acc: 0.8020\n",
      "Epoch 1852/2000\n",
      "13834/13834 [==============================] - 0s 28us/step - loss: 0.4190 - acc: 0.8138 - val_loss: 0.4530 - val_acc: 0.7996\n",
      "Epoch 1853/2000\n",
      "13834/13834 [==============================] - 0s 28us/step - loss: 0.4200 - acc: 0.8145 - val_loss: 0.4445 - val_acc: 0.8020\n",
      "Epoch 1854/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4193 - acc: 0.8141 - val_loss: 0.4442 - val_acc: 0.8022\n",
      "Epoch 1855/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4195 - acc: 0.8154 - val_loss: 0.4461 - val_acc: 0.8018\n",
      "Epoch 1856/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4211 - acc: 0.8116 - val_loss: 0.4454 - val_acc: 0.8026\n",
      "Epoch 1857/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4192 - acc: 0.8157 - val_loss: 0.4459 - val_acc: 0.8039\n",
      "Epoch 1858/2000\n",
      "13834/13834 [==============================] - 0s 29us/step - loss: 0.4199 - acc: 0.8134 - val_loss: 0.4468 - val_acc: 0.7998\n",
      "Epoch 1859/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4195 - acc: 0.8144 - val_loss: 0.4510 - val_acc: 0.8007\n",
      "Epoch 1860/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4203 - acc: 0.8129 - val_loss: 0.4514 - val_acc: 0.7963\n",
      "Epoch 1861/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8147 - val_loss: 0.4452 - val_acc: 0.8031\n",
      "Epoch 1862/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4190 - acc: 0.8141 - val_loss: 0.4497 - val_acc: 0.8013\n",
      "Epoch 1863/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8132 - val_loss: 0.4453 - val_acc: 0.8039\n",
      "Epoch 1864/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4196 - acc: 0.8150 - val_loss: 0.4435 - val_acc: 0.8026\n",
      "Epoch 1865/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4189 - acc: 0.8157 - val_loss: 0.4462 - val_acc: 0.8024\n",
      "Epoch 1866/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4191 - acc: 0.8149 - val_loss: 0.4451 - val_acc: 0.8028\n",
      "Epoch 1867/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4199 - acc: 0.8149 - val_loss: 0.4462 - val_acc: 0.8018\n",
      "Epoch 1868/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4188 - acc: 0.8146 - val_loss: 0.4477 - val_acc: 0.8020\n",
      "Epoch 1869/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8150 - val_loss: 0.4469 - val_acc: 0.8037\n",
      "Epoch 1870/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4197 - acc: 0.8138 - val_loss: 0.4457 - val_acc: 0.8011\n",
      "Epoch 1871/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8147 - val_loss: 0.4445 - val_acc: 0.7996\n",
      "Epoch 1872/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4191 - acc: 0.8143 - val_loss: 0.4466 - val_acc: 0.8024\n",
      "Epoch 1873/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8155 - val_loss: 0.4467 - val_acc: 0.8033\n",
      "Epoch 1874/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8148 - val_loss: 0.4517 - val_acc: 0.8007\n",
      "Epoch 1875/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4201 - acc: 0.8126 - val_loss: 0.4478 - val_acc: 0.7998\n",
      "Epoch 1876/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4194 - acc: 0.8150 - val_loss: 0.4521 - val_acc: 0.7982\n",
      "Epoch 1877/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4203 - acc: 0.8137 - val_loss: 0.4470 - val_acc: 0.8018\n",
      "Epoch 1878/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4203 - acc: 0.8147 - val_loss: 0.4454 - val_acc: 0.8024\n",
      "Epoch 1879/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4196 - acc: 0.8172 - val_loss: 0.4467 - val_acc: 0.8037\n",
      "Epoch 1880/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8144 - val_loss: 0.4442 - val_acc: 0.8031\n",
      "Epoch 1881/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4191 - acc: 0.8141 - val_loss: 0.4483 - val_acc: 0.8009\n",
      "Epoch 1882/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8141 - val_loss: 0.4466 - val_acc: 0.8037\n",
      "Epoch 1883/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4199 - acc: 0.8142 - val_loss: 0.4473 - val_acc: 0.8022\n",
      "Epoch 1884/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8135 - val_loss: 0.4449 - val_acc: 0.8037\n",
      "Epoch 1885/2000\n",
      "13834/13834 [==============================] - 0s 27us/step - loss: 0.4193 - acc: 0.8147 - val_loss: 0.4462 - val_acc: 0.8031\n",
      "Epoch 1886/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8151 - val_loss: 0.4519 - val_acc: 0.7961\n",
      "Epoch 1887/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4204 - acc: 0.8139 - val_loss: 0.4471 - val_acc: 0.8050\n",
      "Epoch 1888/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4192 - acc: 0.8142 - val_loss: 0.4480 - val_acc: 0.8011\n",
      "Epoch 1889/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4195 - acc: 0.8168 - val_loss: 0.4479 - val_acc: 0.8011\n",
      "Epoch 1890/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4200 - acc: 0.8147 - val_loss: 0.4455 - val_acc: 0.8007\n",
      "Epoch 1891/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4191 - acc: 0.8145 - val_loss: 0.4456 - val_acc: 0.8039\n",
      "Epoch 1892/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4195 - acc: 0.8135 - val_loss: 0.4476 - val_acc: 0.8018\n",
      "Epoch 1893/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8158 - val_loss: 0.4472 - val_acc: 0.8004\n",
      "Epoch 1894/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8149 - val_loss: 0.4467 - val_acc: 0.8011\n",
      "Epoch 1895/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8144 - val_loss: 0.4461 - val_acc: 0.8031\n",
      "Epoch 1896/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8138 - val_loss: 0.4475 - val_acc: 0.7982\n",
      "Epoch 1897/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8124 - val_loss: 0.4464 - val_acc: 0.8020\n",
      "Epoch 1898/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4187 - acc: 0.8151 - val_loss: 0.4476 - val_acc: 0.8024\n",
      "Epoch 1899/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.8150 - val_loss: 0.4471 - val_acc: 0.8013\n",
      "Epoch 1900/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4190 - acc: 0.8152 - val_loss: 0.4485 - val_acc: 0.8007\n",
      "Epoch 1901/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8157 - val_loss: 0.4466 - val_acc: 0.8037\n",
      "Epoch 1902/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4186 - acc: 0.8138 - val_loss: 0.4540 - val_acc: 0.7985\n",
      "Epoch 1903/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4192 - acc: 0.8153 - val_loss: 0.4463 - val_acc: 0.8002\n",
      "Epoch 1904/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8144 - val_loss: 0.4471 - val_acc: 0.8007\n",
      "Epoch 1905/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4195 - acc: 0.8151 - val_loss: 0.4465 - val_acc: 0.8020\n",
      "Epoch 1906/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4192 - acc: 0.8156 - val_loss: 0.4484 - val_acc: 0.8000\n",
      "Epoch 1907/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4190 - acc: 0.8146 - val_loss: 0.4469 - val_acc: 0.8037\n",
      "Epoch 1908/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4197 - acc: 0.8157 - val_loss: 0.4470 - val_acc: 0.8009\n",
      "Epoch 1909/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8144 - val_loss: 0.4485 - val_acc: 0.8037\n",
      "Epoch 1910/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4209 - acc: 0.8129 - val_loss: 0.4455 - val_acc: 0.8004\n",
      "Epoch 1911/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4201 - acc: 0.8132 - val_loss: 0.4465 - val_acc: 0.8015\n",
      "Epoch 1912/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4200 - acc: 0.8137 - val_loss: 0.4473 - val_acc: 0.8046\n",
      "Epoch 1913/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8144 - val_loss: 0.4492 - val_acc: 0.8028\n",
      "Epoch 1914/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4200 - acc: 0.8143 - val_loss: 0.4467 - val_acc: 0.8011\n",
      "Epoch 1915/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8136 - val_loss: 0.4464 - val_acc: 0.7998\n",
      "Epoch 1916/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4188 - acc: 0.8138 - val_loss: 0.4469 - val_acc: 0.8018\n",
      "Epoch 1917/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4192 - acc: 0.8132 - val_loss: 0.4468 - val_acc: 0.8024\n",
      "Epoch 1918/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4187 - acc: 0.8153 - val_loss: 0.4460 - val_acc: 0.8033\n",
      "Epoch 1919/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4187 - acc: 0.8145 - val_loss: 0.4471 - val_acc: 0.7998\n",
      "Epoch 1920/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4186 - acc: 0.8144 - val_loss: 0.4485 - val_acc: 0.7998\n",
      "Epoch 1921/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4185 - acc: 0.8144 - val_loss: 0.4458 - val_acc: 0.8020\n",
      "Epoch 1922/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4190 - acc: 0.8137 - val_loss: 0.4497 - val_acc: 0.8007\n",
      "Epoch 1923/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4188 - acc: 0.8141 - val_loss: 0.4467 - val_acc: 0.7996\n",
      "Epoch 1924/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4190 - acc: 0.8160 - val_loss: 0.4464 - val_acc: 0.8020\n",
      "Epoch 1925/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4198 - acc: 0.8149 - val_loss: 0.4473 - val_acc: 0.8011\n",
      "Epoch 1926/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8147 - val_loss: 0.4485 - val_acc: 0.7987\n",
      "Epoch 1927/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4190 - acc: 0.8148 - val_loss: 0.4465 - val_acc: 0.8020\n",
      "Epoch 1928/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8139 - val_loss: 0.4469 - val_acc: 0.8000\n",
      "Epoch 1929/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8158 - val_loss: 0.4480 - val_acc: 0.8039\n",
      "Epoch 1930/2000\n",
      "13834/13834 [==============================] - 0s 24us/step - loss: 0.4200 - acc: 0.8129 - val_loss: 0.4452 - val_acc: 0.8011\n",
      "Epoch 1931/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4191 - acc: 0.8139 - val_loss: 0.4501 - val_acc: 0.7987\n",
      "Epoch 1932/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4206 - acc: 0.8162 - val_loss: 0.4481 - val_acc: 0.7987\n",
      "Epoch 1933/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8150 - val_loss: 0.4497 - val_acc: 0.7998\n",
      "Epoch 1934/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8143 - val_loss: 0.4524 - val_acc: 0.7993\n",
      "Epoch 1935/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4211 - acc: 0.8127 - val_loss: 0.4492 - val_acc: 0.8007\n",
      "Epoch 1936/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.8154 - val_loss: 0.4454 - val_acc: 0.8002\n",
      "Epoch 1937/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4191 - acc: 0.8160 - val_loss: 0.4473 - val_acc: 0.7996\n",
      "Epoch 1938/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4190 - acc: 0.8167 - val_loss: 0.4478 - val_acc: 0.7985\n",
      "Epoch 1939/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8151 - val_loss: 0.4463 - val_acc: 0.8013\n",
      "Epoch 1940/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4188 - acc: 0.8149 - val_loss: 0.4469 - val_acc: 0.8011\n",
      "Epoch 1941/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8151 - val_loss: 0.4461 - val_acc: 0.8024\n",
      "Epoch 1942/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4188 - acc: 0.8152 - val_loss: 0.4470 - val_acc: 0.8028\n",
      "Epoch 1943/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4183 - acc: 0.8150 - val_loss: 0.4488 - val_acc: 0.8004\n",
      "Epoch 1944/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4191 - acc: 0.8142 - val_loss: 0.4451 - val_acc: 0.8013\n",
      "Epoch 1945/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8138 - val_loss: 0.4472 - val_acc: 0.7998\n",
      "Epoch 1946/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8139 - val_loss: 0.4459 - val_acc: 0.8013\n",
      "Epoch 1947/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4193 - acc: 0.8157 - val_loss: 0.4466 - val_acc: 0.8013\n",
      "Epoch 1948/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4191 - acc: 0.8143 - val_loss: 0.4476 - val_acc: 0.7985\n",
      "Epoch 1949/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8147 - val_loss: 0.4449 - val_acc: 0.8031\n",
      "Epoch 1950/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4186 - acc: 0.8136 - val_loss: 0.4467 - val_acc: 0.8011\n",
      "Epoch 1951/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4189 - acc: 0.8138 - val_loss: 0.4459 - val_acc: 0.8013\n",
      "Epoch 1952/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4188 - acc: 0.8157 - val_loss: 0.4462 - val_acc: 0.8028\n",
      "Epoch 1953/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4192 - acc: 0.8157 - val_loss: 0.4462 - val_acc: 0.8018\n",
      "Epoch 1954/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4185 - acc: 0.8151 - val_loss: 0.4470 - val_acc: 0.8013\n",
      "Epoch 1955/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.8137 - val_loss: 0.4492 - val_acc: 0.7969\n",
      "Epoch 1956/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4200 - acc: 0.8144 - val_loss: 0.4477 - val_acc: 0.8018\n",
      "Epoch 1957/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8142 - val_loss: 0.4461 - val_acc: 0.8018\n",
      "Epoch 1958/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4187 - acc: 0.8169 - val_loss: 0.4507 - val_acc: 0.8000\n",
      "Epoch 1959/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8146 - val_loss: 0.4467 - val_acc: 0.8004\n",
      "Epoch 1960/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8144 - val_loss: 0.4451 - val_acc: 0.8007\n",
      "Epoch 1961/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8149 - val_loss: 0.4463 - val_acc: 0.8022\n",
      "Epoch 1962/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8142 - val_loss: 0.4477 - val_acc: 0.7991\n",
      "Epoch 1963/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8128 - val_loss: 0.4468 - val_acc: 0.8000\n",
      "Epoch 1964/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4184 - acc: 0.8149 - val_loss: 0.4468 - val_acc: 0.8011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1965/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4190 - acc: 0.8154 - val_loss: 0.4482 - val_acc: 0.8002\n",
      "Epoch 1966/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.8143 - val_loss: 0.4493 - val_acc: 0.8015\n",
      "Epoch 1967/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.8156 - val_loss: 0.4471 - val_acc: 0.8022\n",
      "Epoch 1968/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4187 - acc: 0.8147 - val_loss: 0.4495 - val_acc: 0.7978\n",
      "Epoch 1969/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4189 - acc: 0.8152 - val_loss: 0.4477 - val_acc: 0.8022\n",
      "Epoch 1970/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4187 - acc: 0.8130 - val_loss: 0.4478 - val_acc: 0.8000\n",
      "Epoch 1971/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4187 - acc: 0.8155 - val_loss: 0.4483 - val_acc: 0.7993\n",
      "Epoch 1972/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4194 - acc: 0.8143 - val_loss: 0.4465 - val_acc: 0.7982\n",
      "Epoch 1973/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8139 - val_loss: 0.4455 - val_acc: 0.8009\n",
      "Epoch 1974/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8129 - val_loss: 0.4461 - val_acc: 0.8031\n",
      "Epoch 1975/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.8144 - val_loss: 0.4447 - val_acc: 0.8028\n",
      "Epoch 1976/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4188 - acc: 0.8155 - val_loss: 0.4470 - val_acc: 0.8028\n",
      "Epoch 1977/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4190 - acc: 0.8152 - val_loss: 0.4460 - val_acc: 0.7987\n",
      "Epoch 1978/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4193 - acc: 0.8135 - val_loss: 0.4464 - val_acc: 0.7989\n",
      "Epoch 1979/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4191 - acc: 0.8154 - val_loss: 0.4485 - val_acc: 0.7993\n",
      "Epoch 1980/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4184 - acc: 0.8145 - val_loss: 0.4454 - val_acc: 0.8028\n",
      "Epoch 1981/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.8158 - val_loss: 0.4467 - val_acc: 0.8020\n",
      "Epoch 1982/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8168 - val_loss: 0.4448 - val_acc: 0.8013\n",
      "Epoch 1983/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4184 - acc: 0.8139 - val_loss: 0.4459 - val_acc: 0.8004\n",
      "Epoch 1984/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4188 - acc: 0.8146 - val_loss: 0.4456 - val_acc: 0.8018\n",
      "Epoch 1985/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.8143 - val_loss: 0.4475 - val_acc: 0.8033\n",
      "Epoch 1986/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4192 - acc: 0.8160 - val_loss: 0.4469 - val_acc: 0.8046\n",
      "Epoch 1987/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4192 - acc: 0.8152 - val_loss: 0.4472 - val_acc: 0.8009\n",
      "Epoch 1988/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8140 - val_loss: 0.4479 - val_acc: 0.7991\n",
      "Epoch 1989/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8149 - val_loss: 0.4469 - val_acc: 0.8011\n",
      "Epoch 1990/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4188 - acc: 0.8130 - val_loss: 0.4460 - val_acc: 0.8007\n",
      "Epoch 1991/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4187 - acc: 0.8159 - val_loss: 0.4453 - val_acc: 0.8004\n",
      "Epoch 1992/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4193 - acc: 0.8144 - val_loss: 0.4496 - val_acc: 0.7991\n",
      "Epoch 1993/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4198 - acc: 0.8133 - val_loss: 0.4467 - val_acc: 0.8000\n",
      "Epoch 1994/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8146 - val_loss: 0.4465 - val_acc: 0.8018\n",
      "Epoch 1995/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4188 - acc: 0.8149 - val_loss: 0.4490 - val_acc: 0.8031\n",
      "Epoch 1996/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8136 - val_loss: 0.4503 - val_acc: 0.8000\n",
      "Epoch 1997/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8155 - val_loss: 0.4460 - val_acc: 0.8028\n",
      "Epoch 1998/2000\n",
      "13834/13834 [==============================] - 0s 25us/step - loss: 0.4191 - acc: 0.8149 - val_loss: 0.4473 - val_acc: 0.7991\n",
      "Epoch 1999/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8151 - val_loss: 0.4465 - val_acc: 0.8004\n",
      "Epoch 2000/2000\n",
      "13834/13834 [==============================] - 0s 26us/step - loss: 0.4194 - acc: 0.8139 - val_loss: 0.4464 - val_acc: 0.8004\n"
     ]
    }
   ],
   "source": [
    "h = model_TP.fit(train_X_TP[:], train_Y_TP[:], \n",
    "          epochs=2000, \n",
    "          batch_size=32, \n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          #validation_split=0.1)\n",
    "          validation_data=([test_X_TP, test_Y_TP]))\n",
    "\n",
    "history_TP = {k : history_TP[k] + h.history[k] for k in hist_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcdd8ae01d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('URZ_model_TP.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4570/4570 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4463778110119133, 0.8004376368136583]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_TP.evaluate(test_X_TP, test_Y_TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1796  446]\n",
      " [ 466 1862]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = numpy.reshape(numpy.argmax(model_TP.predict(test_X_TP), axis=1), (test_X_TP.shape[0],1))\n",
    "\n",
    "# calculate confusion matrix\n",
    "conf_mat = confusion_matrix(test_Y_TP_, Y_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cascade of all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NTPS = load_model('URZ_model_NTPS.h5')\n",
    "model_STP = load_model('URZ_model_TPS.h5')\n",
    "model_PT = load_model('URZ_model_TP.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_iwt(X, stage=0):\n",
    "    \"\"\"\n",
    "    predicts initial wave type for given featrue vectors\n",
    "    Class encoding generated by sklearn Label Encoder\n",
    "    0 - noise\n",
    "    2 - regS \n",
    "    1 - regP\n",
    "    3 - T\n",
    "    \"\"\"\n",
    "    Y = numpy.arange(X.shape[0])\n",
    "    \n",
    "    N_indices = None\n",
    "    S_indices = None \n",
    "    \n",
    "    if stage >= 1:\n",
    "        N_indices = [False] * X.shape[0]\n",
    "        X_PTS = X\n",
    "        Y_NPTS = numpy.ones(X.shape[0])\n",
    "    if stage >= 2:\n",
    "        S_indices =  [False] * X.shape[0]  # numpy.array([])\n",
    "        X_PT = X\n",
    "        Y_PTS = numpy.ones(X.shape[0])\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    N vs regS, regP, T\n",
    "    \"\"\"\n",
    "    if N_indices is None:\n",
    "        #predict N vs T,regP,regS\n",
    "        Y_NPTS = numpy.argmax(model_NTPS.predict(X), axis=1)\n",
    "        #set which are noise\n",
    "        N_indices = Y[Y_NPTS == 0]  #  = 0\n",
    "        #get candidates for TPS\n",
    "        X_PTS = X[Y_NPTS > 0]\n",
    "    else:\n",
    "        print('Skipping N, classifying TPS only')\n",
    "\n",
    "    \"\"\"\n",
    "    regS vs regP, T\n",
    "    \"\"\"\n",
    "    if S_indices is None:    \n",
    "        #predict regS vs T,regP\n",
    "        Y_PTS = numpy.argmax(model_TPS.predict(X_PTS), axis=1)\n",
    "        #set which are regS\n",
    "        S_indices = Y[Y_NPTS > 0][Y_PTS == 0]  # = 2\n",
    "        #get candidates for regP,T\n",
    "        X_PT = X_PTS[Y_PTS > 0]\n",
    "    else:\n",
    "        print('Skipping N, regS, classifying TP only')\n",
    "\n",
    "    \"\"\"\n",
    "    regP vs T\n",
    "    \"\"\"\n",
    "    #predict regP vs T\n",
    "    Y_PT = numpy.argmax(model_TP.predict(X_PT), axis=1)\n",
    "    #set which are regP\n",
    "    P_indices = Y[Y_NPTS > 0][Y_PTS > 0][Y_PT == 0]  # = 1    \n",
    "    #set which are T\n",
    "    T_indices = Y[Y_NPTS > 0][Y_PTS > 0][Y_PT > 0]   # = 3\n",
    "    #get those which are T\n",
    "    X_T = X_PT[Y_PT > 0]\n",
    "    \n",
    "    Y[N_indices] = 0 # N\n",
    "    Y[S_indices] = 2 # regS\n",
    "    Y[P_indices] = 1 # regP \n",
    "    Y[T_indices] = 3 # tele\n",
    "    \n",
    "    return Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = predict_iwt(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall confusion matrix for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13804, 15), (13804,), (13804,))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape, Y.shape, test_Y_GT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5697  180  541  244]\n",
      " [ 375 1671   16  410]\n",
      " [ 599   20 1665  425]\n",
      " [ 231  371  110 1249]]\n"
     ]
    }
   ],
   "source": [
    "C = confusion_matrix(Y, test_Y_GT)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.49%\n"
     ]
    }
   ],
   "source": [
    "diagsum = numpy.diag(C).sum()\n",
    "accuracy = diagsum/C.sum()\n",
    "print('Accuracy: %3.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ..on train data just to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17184   576  1487   710]\n",
      " [ 1147  5313    31  1207]\n",
      " [ 1769    27  5116  1057]\n",
      " [  604  1044   236  3900]]\n",
      "Accuracy: 76.10%\n"
     ]
    }
   ],
   "source": [
    "Y = predict_iwt(train_X)\n",
    "C = confusion_matrix(Y, train_Y_GT)\n",
    "print(C)\n",
    "diagsum = numpy.diag(C).sum()\n",
    "accuracy = diagsum/C.sum()\n",
    "print('Accuracy: %3.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall confusion matrix for all manual associations (no Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping N, classifying TPS only\n",
      "[[1375   63  447]\n",
      " [ 236 1822  747]\n",
      " [ 391  117  808]]\n"
     ]
    }
   ],
   "source": [
    "C = confusion_matrix(predict_iwt(manual_X, stage=1), manual_Y_GT)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.68%\n"
     ]
    }
   ],
   "source": [
    "diagsum = numpy.diag(C).sum()\n",
    "accuracy = diagsum/C.sum()\n",
    "print('Accuracy: %3.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with the current state - accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select * from ml_features where sta='URZ' and class_iphase != 'N' and source != 'M'\"\"\"\n",
    "df_TPS_all = pd.read_sql(query, con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40435, 25), (41408, 25))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TPS_all.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping N, classifying TPS only\n"
     ]
    }
   ],
   "source": [
    "all_TPS_X = df_TPS_all[x_indices]\n",
    "all_TPS_true_Y = le.transform(df_TPS_all['CLASS_PHASE'])\n",
    "all_TPS_iphase_Y = le.transform(df_TPS_all['CLASS_IPHASE'])\n",
    "all_TPS_pred_Y = predict_iwt(all_TPS_X, stage=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n",
      "1 3\n",
      "1 3\n"
     ]
    }
   ],
   "source": [
    "print(all_TPS_true_Y.min(), all_TPS_true_Y.max())\n",
    "print(all_TPS_iphase_Y.min(), all_TPS_iphase_Y.max())\n",
    "print(all_TPS_pred_Y.min(), all_TPS_pred_Y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6967   212   894]\n",
      " [  643  5147   151]\n",
      " [ 7340  5033 14048]]\n",
      "Accuracy: 64.70%\n"
     ]
    }
   ],
   "source": [
    "# current iphase for TPS\n",
    "C = confusion_matrix(all_TPS_true_Y, all_TPS_iphase_Y)\n",
    "print(C)\n",
    "diagsum = numpy.diag(C).sum()\n",
    "accuracy = diagsum/C.sum()\n",
    "print('Accuracy: %3.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6517    55  1501]\n",
      " [   43  5601   297]\n",
      " [ 5224  4189 17008]]\n",
      "Accuracy: 72.03%\n"
     ]
    }
   ],
   "source": [
    "# newly trained iphase for TPS\n",
    "C = confusion_matrix(all_TPS_true_Y, all_TPS_pred_Y)\n",
    "print(C)\n",
    "diagsum = numpy.diag(C).sum()\n",
    "accuracy = diagsum/C.sum()\n",
    "print('Accuracy: %3.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems that newly trained network is by 8% better withnout aby special treatment ^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping N, classifying TPS only\n"
     ]
    }
   ],
   "source": [
    "manual_pred = predict_iwt(manual_X, stage=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1375   63  447]\n",
      " [ 236 1822  747]\n",
      " [ 391  117  808]]\n",
      "Accuracy: 66.68%\n"
     ]
    }
   ],
   "source": [
    "C = confusion_matrix(manual_pred, manual_Y_GT)\n",
    "print(C)\n",
    "diagsum = numpy.diag(C).sum()\n",
    "accuracy = diagsum/C.sum()\n",
    "print('Accuracy: %3.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### just for fun to see what it does on LPAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select * from ml_features where sta='LPAZ' and class_iphase != 'N' and source != 'M'\"\"\"\n",
    "df_LPAZ_all = pd.read_sql(query, con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping N, classifying TPS only\n"
     ]
    }
   ],
   "source": [
    "all_TPS_X = df_LPAZ_all[x_indices]\n",
    "all_TPS_true_Y = le.transform(df_LPAZ_all['CLASS_PHASE'])\n",
    "all_TPS_iphase_Y = le.transform(df_LPAZ_all['CLASS_IPHASE'])\n",
    "all_TPS_pred_Y = predict_iwt(all_TPS_X, stage=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n",
      "1 3\n",
      "1 3\n"
     ]
    }
   ],
   "source": [
    "print(all_TPS_true_Y.min(), all_TPS_true_Y.max())\n",
    "print(all_TPS_iphase_Y.min(), all_TPS_iphase_Y.max())\n",
    "print(all_TPS_pred_Y.min(), all_TPS_pred_Y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2565     8  3984]\n",
      " [   97   222   109]\n",
      " [11238  1595 61359]]\n",
      "Accuracy: 79.02%\n"
     ]
    }
   ],
   "source": [
    "# current iphase for TPS\n",
    "C = confusion_matrix(all_TPS_true_Y, all_TPS_iphase_Y)\n",
    "print(C)\n",
    "diagsum = numpy.diag(C).sum()\n",
    "accuracy = diagsum/C.sum()\n",
    "print('Accuracy: %3.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3657    44  2856]\n",
      " [   27   314    87]\n",
      " [12883  2148 59161]]\n",
      "Accuracy: 77.77%\n"
     ]
    }
   ],
   "source": [
    "# newly trained iphase for TPS\n",
    "C = confusion_matrix(all_TPS_true_Y, all_TPS_pred_Y)\n",
    "print(C)\n",
    "diagsum = numpy.diag(C).sum()\n",
    "accuracy = diagsum/C.sum()\n",
    "print('Accuracy: %3.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
